{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lending Club Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Content__ <br>\n",
    "3.1 Data Import <br>\n",
    "3.2 Train-Test-Split for Training Data <br>\n",
    "3.3 SMOTE <br>\n",
    "3.4 Baseline Model: Dummy Classifier <br>\n",
    "3.5 Feature Selection <br>\n",
    "3.6 Logistic Regression (5 Features)<br>\n",
    "3.7 Logistic Regression (10 Features)<br>\n",
    "3.8 KNN (5 Features)<br>\n",
    "3.9 KNN (10 Features)<br>\n",
    "3.10 Ensemble: AdaBoost <br>\n",
    "3.11 Ensemble: Stacking <br>\n",
    "3.12 Decision Tree (5 Features) <br>\n",
    "3.13 Decision Tree (10 Features) <br>\n",
    "3.14 Random Forest (5 Features) <br>\n",
    "3.15 Random Forest (10 Features) <br>\n",
    "3.16 Ensemble: Adaboost II (10 Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the code was run several times when the models of both partners were combined. Since we used randomized search which leads to slightly different results every time, the best models shown in the output and the best models used in the prediction inconclusively match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "import re \n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>term</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "      <th>emp_length_unknown</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>addr_state_AL</th>\n",
       "      <th>addr_state_AR</th>\n",
       "      <th>addr_state_AZ</th>\n",
       "      <th>addr_state_CA</th>\n",
       "      <th>addr_state_CO</th>\n",
       "      <th>addr_state_CT</th>\n",
       "      <th>addr_state_DC</th>\n",
       "      <th>addr_state_DE</th>\n",
       "      <th>addr_state_FL</th>\n",
       "      <th>addr_state_GA</th>\n",
       "      <th>addr_state_HI</th>\n",
       "      <th>addr_state_IA</th>\n",
       "      <th>addr_state_IL</th>\n",
       "      <th>addr_state_KS</th>\n",
       "      <th>addr_state_KY</th>\n",
       "      <th>addr_state_LA</th>\n",
       "      <th>addr_state_MA</th>\n",
       "      <th>addr_state_MD</th>\n",
       "      <th>addr_state_MI</th>\n",
       "      <th>addr_state_MN</th>\n",
       "      <th>addr_state_MO</th>\n",
       "      <th>addr_state_MS</th>\n",
       "      <th>addr_state_MT</th>\n",
       "      <th>addr_state_NC</th>\n",
       "      <th>addr_state_NH</th>\n",
       "      <th>addr_state_NJ</th>\n",
       "      <th>addr_state_NM</th>\n",
       "      <th>addr_state_NV</th>\n",
       "      <th>addr_state_NY</th>\n",
       "      <th>addr_state_OH</th>\n",
       "      <th>addr_state_OK</th>\n",
       "      <th>addr_state_OR</th>\n",
       "      <th>addr_state_PA</th>\n",
       "      <th>addr_state_RI</th>\n",
       "      <th>addr_state_SC</th>\n",
       "      <th>addr_state_SD</th>\n",
       "      <th>addr_state_TN</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.403061</td>\n",
       "      <td>-0.367347</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>-0.361449</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.7899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.546581</td>\n",
       "      <td>-0.123932</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.673469</td>\n",
       "      <td>0.894928</td>\n",
       "      <td>-0.663813</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.1799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.478905</td>\n",
       "      <td>1.057692</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.158163</td>\n",
       "      <td>-0.122449</td>\n",
       "      <td>-1.050725</td>\n",
       "      <td>-0.089012</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.566346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121236</td>\n",
       "      <td>-0.732906</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.124841</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6498</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.291346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.672444</td>\n",
       "      <td>-1.051282</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.505102</td>\n",
       "      <td>-0.469388</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>-0.412665</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0299</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.535577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393115</td>\n",
       "      <td>0.950855</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  loan_amnt  funded_amnt  int_rate  installment  grade  \\\n",
       "0           0  -0.403061    -0.367347 -0.891304    -0.361449   -0.5   \n",
       "1           1  -0.709184    -0.673469  0.894928    -0.663813    1.5   \n",
       "2           2  -0.158163    -0.122449 -1.050725    -0.089012   -0.5   \n",
       "3           3   0.005102     0.040816 -0.782609     0.124841   -0.5   \n",
       "4           4  -0.505102    -0.469388  0.456522    -0.412665    0.5   \n",
       "\n",
       "   annual_inc  issue_d       dti  delinq_2yrs  inq_last_6mths  open_acc  \\\n",
       "0     -0.7899      0.0 -0.400000          0.0            -1.0 -1.000000   \n",
       "1     -1.1799      0.0 -0.436538          0.0             0.0 -1.000000   \n",
       "2     -0.1999      0.0 -0.566346          0.0            -1.0  0.000000   \n",
       "3     -0.6498     -1.0 -1.291346          0.0            -1.0 -0.166667   \n",
       "4     -1.0299     -1.0 -0.535577          0.0             0.0 -0.833333   \n",
       "\n",
       "   pub_rec  revol_bal  revol_util  total_acc  term  emp_length_10+ years  \\\n",
       "0      0.0  -0.546581   -0.123932  -0.733333   0.0                     0   \n",
       "1      0.0  -0.478905    1.057692  -1.066667   0.0                     0   \n",
       "2      0.0  -0.121236   -0.732906  -0.266667   0.0                     1   \n",
       "3      0.0  -0.672444   -1.051282  -0.466667   0.0                     0   \n",
       "4      0.0  -0.393115    0.950855  -0.666667   0.0                     0   \n",
       "\n",
       "   emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "0                   0                   1                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    1   \n",
       "2                   0                   0                    0   \n",
       "3                   0                   1                    0   \n",
       "4                   0                   0                    1   \n",
       "\n",
       "   emp_length_unknown  home_ownership_OTHER  home_ownership_OWN  \\\n",
       "0                   0                     0                   0   \n",
       "1                   0                     0                   0   \n",
       "2                   0                     0                   0   \n",
       "3                   0                     0                   0   \n",
       "4                   0                     0                   0   \n",
       "\n",
       "   home_ownership_RENT  verification_status_Source Verified  \\\n",
       "0                    0                                    0   \n",
       "1                    1                                    0   \n",
       "2                    0                                    0   \n",
       "3                    0                                    0   \n",
       "4                    1                                    1   \n",
       "\n",
       "   verification_status_Verified  purpose_credit_card  \\\n",
       "0                             1                    0   \n",
       "1                             1                    0   \n",
       "2                             0                    0   \n",
       "3                             1                    0   \n",
       "4                             0                    0   \n",
       "\n",
       "   purpose_debt_consolidation  purpose_educational  purpose_home_improvement  \\\n",
       "0                           1                    0                         0   \n",
       "1                           1                    0                         0   \n",
       "2                           1                    0                         0   \n",
       "3                           0                    0                         0   \n",
       "4                           1                    0                         0   \n",
       "\n",
       "   purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  \\\n",
       "0              0                       0                0               0   \n",
       "1              0                       0                0               0   \n",
       "2              0                       0                0               0   \n",
       "3              0                       0                0               0   \n",
       "4              0                       0                0               0   \n",
       "\n",
       "   purpose_other  purpose_renewable_energy  purpose_small_business  \\\n",
       "0              0                         0                       0   \n",
       "1              0                         0                       0   \n",
       "2              0                         0                       0   \n",
       "3              1                         0                       0   \n",
       "4              0                         0                       0   \n",
       "\n",
       "   purpose_vacation  purpose_wedding  addr_state_AL  addr_state_AR  \\\n",
       "0                 0                0              0              0   \n",
       "1                 0                0              0              0   \n",
       "2                 0                0              0              0   \n",
       "3                 0                0              0              0   \n",
       "4                 0                0              0              0   \n",
       "\n",
       "   addr_state_AZ  addr_state_CA  addr_state_CO  addr_state_CT  addr_state_DC  \\\n",
       "0              0              1              0              0              0   \n",
       "1              0              1              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              1              0              0              0              0   \n",
       "4              0              1              0              0              0   \n",
       "\n",
       "   addr_state_DE  addr_state_FL  addr_state_GA  addr_state_HI  addr_state_IA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_IL  addr_state_KS  addr_state_KY  addr_state_LA  addr_state_MA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_MD  addr_state_MI  addr_state_MN  addr_state_MO  addr_state_MS  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_MT  addr_state_NC  addr_state_NH  addr_state_NJ  addr_state_NM  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_NV  addr_state_NY  addr_state_OH  addr_state_OK  addr_state_OR  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_PA  addr_state_RI  addr_state_SC  addr_state_SD  addr_state_TN  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_TX  addr_state_UT  addr_state_VA  addr_state_VT  addr_state_WA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              1              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_WI  addr_state_WV  addr_state_WY  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('train_data_rescaled.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Unnamed: 0'], inplace = True, axis = 1)\n",
    "y_train.drop('Unnamed: 0', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train-Test-Split for Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a large data set, the train data is split once again to have an evaluation dataset for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(X_train, y_train, test_size = .2, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very imbalanced so we use the SMOTE (Synthetic Minority Oversampling Technique) method to address this issue. SMOTE synthesizes new datasets from the existing examples, oversampling the minority class (0 = charged off). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 16227\n",
      "Before OverSampling, counts of label '0': 2698 \n",
      "\n",
      "After OverSampling, the shape of train_X: (32454, 90)\n",
      "After OverSampling, the shape of train_y: (32454,) \n",
      "\n",
      "After OverSampling, counts of label '1': 16227\n",
      "After OverSampling, counts of label '0': 16227\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(ye_train.loan_status==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(ye_train.loan_status==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_smo, y_smo = sm.fit_sample(Xe_train, ye_train.values.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_smo.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_smo.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_smo==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_smo==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Baseline Model: Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier uses simple classification rules and is therefore useful as a simple baseline to compare with other (real) classifiers. It is not used for 'real' modelling. Since it is a baseline model, the original data wihtout SMOTE are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.14      0.14       675\n",
      "         1.0       0.86      0.86      0.86      4057\n",
      "\n",
      "    accuracy                           0.76      4732\n",
      "   macro avg       0.50      0.50      0.50      4732\n",
      "weighted avg       0.76      0.76      0.76      4732\n",
      "\n",
      "F beta Score for both classes:\n",
      "0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "#Define the Classifier and fit it to the train data\n",
    "dummy_clf = DummyClassifier(random_state = 2, strategy = 'stratified')\n",
    "dummy_clf.fit(Xe_train, ye_train)\n",
    "cv_results = cross_validate(dummy_clf, Xe_train, ye_train, cv=5, return_estimator = True)\n",
    "\n",
    "\n",
    "#Make predictions using cross-validation\n",
    "ye_pred = cross_val_predict(dummy_clf, Xe_test, ye_test, cv = 5)\n",
    "\n",
    "# Printing evaluation scores for the Dummy Classifier \n",
    "print(classification_report(ye_test, ye_pred))\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .2, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is imbalanced, it does not make sense to interpret accuracy but to focus recall and precision (or the f1 score). Here one can see that the model is good at predicting whether a person will pay back. But, since this class is underrepresented, the model fails to predict incomplete paybacks which is bad since for an investor for he will lose his money. This results in a bad overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the best 5 resp. 10 features by using the SelectKBest tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit selector\n",
    "best_features = SelectKBest(mutual_info_classif, k=5)\n",
    "X_smo_5 = best_features.fit_transform(X_smo, np.array(y_smo).ravel())\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = best_features.get_support(indices=True)\n",
    "X_smo_5 = X_smo.iloc[:,cols]\n",
    "X_smo_5 = pd.DataFrame(X_smo_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.607143</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.688034</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.025510</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>-0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198980</td>\n",
       "      <td>-0.262681</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>-1.094203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.914530</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  open_acc  revol_util  total_acc\n",
       "0  -0.607143 -0.213768  0.833333    0.688034   0.466667\n",
       "1   1.025510 -0.891304  0.500000   -0.241453   0.666667\n",
       "2  -0.709184 -0.125000 -1.000000    0.108974  -0.533333\n",
       "3  -0.198980 -0.262681 -0.333333    0.230769  -0.600000\n",
       "4   0.387755 -1.094203  1.000000   -0.914530   1.066667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit selector\n",
    "best_features = SelectKBest(mutual_info_classif, k=12)\n",
    "X_smo_10 = best_features.fit_transform(X_smo, np.array(y_smo).ravel())\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = best_features.get_support(indices=True)\n",
    "X_smo_10 = X_smo.iloc[:,cols]\n",
    "X_smo_10 = pd.DataFrame(X_smo_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.607143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>-0.572486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.371154</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.688034</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.025510</td>\n",
       "      <td>1.061224</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>0.449072</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.2999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.131731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.673469</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.695438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7749</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>-0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198980</td>\n",
       "      <td>-0.163265</td>\n",
       "      <td>-0.262681</td>\n",
       "      <td>-0.073933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6749</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.423469</td>\n",
       "      <td>-1.094203</td>\n",
       "      <td>0.533225</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.2501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.914530</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  int_rate  installment  grade  annual_inc  issue_d  \\\n",
       "0  -0.607143    -0.571429 -0.213768    -0.572486    0.0      0.8001      0.0   \n",
       "1   1.025510     1.061224 -0.891304     0.449072   -0.5     -0.2999     -1.0   \n",
       "2  -0.709184    -0.673469 -0.125000    -0.695438    0.0     -0.7749     -2.0   \n",
       "3  -0.198980    -0.163265 -0.262681    -0.073933    0.0     -0.6749     -1.0   \n",
       "4   0.387755     0.423469 -1.094203     0.533225   -0.5      1.2501      0.0   \n",
       "\n",
       "        dti  inq_last_6mths  open_acc  revol_util  total_acc  \n",
       "0 -0.371154            -1.0  0.833333    0.688034   0.466667  \n",
       "1 -1.131731             0.0  0.500000   -0.241453   0.666667  \n",
       "2  0.119231            -1.0 -1.000000    0.108974  -0.533333  \n",
       "3  0.975000             1.0 -0.333333    0.230769  -0.600000  \n",
       "4  0.604808             1.0  1.000000   -0.914530   1.066667  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue_d is dropped because it has no predictive value for the target taking into account that an investor will only know the current year a borrower begs for money.\n",
    "loan_amnt is dropped because it's redundant to funded_amnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smo_10.drop(['issue_d', 'loan_amnt'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amnt', 'int_rate', 'installment', 'grade', 'annual_inc', 'dti',\n",
       "       'inq_last_6mths', 'open_acc', 'revol_util', 'total_acc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_10.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt the test data with the corresponding variables\n",
    "X_test_5 = Xe_test[['int_rate', 'loan_amnt', 'open_acc', 'revol_util', 'total_acc']]\n",
    "X_test_10 = Xe_test[['funded_amnt', 'int_rate', 'installment', 'grade', 'annual_inc', 'dti',\n",
    "       'inq_last_6mths', 'open_acc', 'revol_util', 'total_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smo_5.to_csv('X_smo_5.csv')\n",
    "X_smo_10.to_csv('X_smo_10.csv')\n",
    "pd.DataFrame(y_smo).to_csv('y_smo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Logistic Regression Model 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(penalty = 'elasticnet', solver = 'saga', n_jobs = -1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use RandomizedSearchCV to identify the best logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.545, total=   1.1s\n",
      "[CV] max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.539, total=   0.6s\n",
      "[CV] max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.545, total=   0.1s\n",
      "[CV] max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.542, total=   0.1s\n",
      "[CV] max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=1791, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.540, total=   0.1s\n",
      "[CV] max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.5s\n",
      "[CV] max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2522, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.505, total=   0.1s\n",
      "[CV] max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.501, total=   0.1s\n",
      "[CV] max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1372, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.502, total=   0.1s\n",
      "[CV] max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.620, total=   0.1s\n",
      "[CV] max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.618, total=   0.1s\n",
      "[CV] max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.622, total=   0.1s\n",
      "[CV] max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.617, total=   0.1s\n",
      "[CV] max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=3193, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.620, total=   0.1s\n",
      "[CV] max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.603, total=   0.1s\n",
      "[CV] max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.612, total=   0.1s\n",
      "[CV] max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.607, total=   0.1s\n",
      "[CV] max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.605, total=   0.1s\n",
      "[CV] max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=8061, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.605, total=   0.1s\n",
      "[CV] max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.505, total=   0.1s\n",
      "[CV] max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.501, total=   0.5s\n",
      "[CV] max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1088, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.502, total=   0.1s\n",
      "[CV] max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.576, total=   0.1s\n",
      "[CV] max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.581, total=   0.1s\n",
      "[CV] max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.576, total=   0.1s\n",
      "[CV] max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.578, total=   0.1s\n",
      "[CV] max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=1404, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.577, total=   0.1s\n",
      "[CV] max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=2007, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.506, total=   0.1s\n",
      "[CV] max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.504, total=   0.1s\n",
      "[CV] max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.504, total=   0.1s\n",
      "[CV] max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=9954, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.502, total=   0.1s\n",
      "[CV] max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.599, total=   0.1s\n",
      "[CV] max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.591, total=   0.1s\n",
      "[CV] max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.597, total=   0.1s\n",
      "[CV] max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.594, total=   0.1s\n",
      "[CV] max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=9887, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.589, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                                random_state=0, solver='saga'),\n",
       "                   param_distributions={'C': array([0.1]),\n",
       "                                        'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'l1_ratio': array([0]),\n",
       "                                        'max_iter': array([1000, 1001, 1002, ..., 9997, 9998, 9999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'C': np.arange(0.1,1),\n",
    "             'max_iter': np.arange(1000, 10000),\n",
    "             'l1_ratio': np.arange(0, 1), \n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid = RandomizedSearchCV(log_clf, param_grid, cv = 5, verbose = 5)\n",
    "grid.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 3193, 'l1_ratio': 0, 'class_weight': {0: 0.5, 1: 0.5}, 'C': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_5 = grid.best_params_\n",
    "best_log_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the best model to the data with 5 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_5 = LogisticRegression(C=0.1, class_weight= {0: 0.3, 1: 0.7}, l1_ratio=0, max_iter=3193,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')\n",
    "best_log_5.fit(X_smo_5, y_smo)\n",
    "ye_pred1 = best_log_5.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred1), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Logistic Regression Model 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=7751, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.540, total=   0.2s\n",
      "[CV] max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.538, total=   0.2s\n",
      "[CV] max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.537, total=   0.2s\n",
      "[CV] max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.539, total=   0.2s\n",
      "[CV] max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1 .\n",
      "[CV]  max_iter=4575, l1_ratio=0, class_weight={0: 0.8, 1: 0.2}, C=0.1, score=0.539, total=   0.2s\n",
      "[CV] max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=7437, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.516, total=   0.2s\n",
      "[CV] max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.516, total=   0.2s\n",
      "[CV] max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.515, total=   0.2s\n",
      "[CV] max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.513, total=   0.2s\n",
      "[CV] max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=4250, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.515, total=   0.2s\n",
      "[CV] max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.623, total=   0.2s\n",
      "[CV] max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.621, total=   0.2s\n",
      "[CV] max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.623, total=   0.2s\n",
      "[CV] max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.619, total=   0.2s\n",
      "[CV] max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=7111, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.617, total=   0.2s\n",
      "[CV] max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.628, total=   0.2s\n",
      "[CV] max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.642, total=   0.2s\n",
      "[CV] max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.640, total=   0.2s\n",
      "[CV] max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.634, total=   0.2s\n",
      "[CV] max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=6109, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.633, total=   0.2s\n",
      "[CV] max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.574, total=   0.2s\n",
      "[CV] max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.572, total=   0.2s\n",
      "[CV] max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.578, total=   0.2s\n",
      "[CV] max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.574, total=   0.2s\n",
      "[CV] max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8911, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.569, total=   0.2s\n",
      "[CV] max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.640, total=   0.2s\n",
      "[CV] max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.654, total=   0.2s\n",
      "[CV] max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.648, total=   0.2s\n",
      "[CV] max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=7639, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1179, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.516, total=   0.1s\n",
      "[CV] max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.516, total=   0.2s\n",
      "[CV] max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.515, total=   0.2s\n",
      "[CV] max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.513, total=   0.2s\n",
      "[CV] max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1 \n",
      "[CV]  max_iter=7492, l1_ratio=0, class_weight={0: 0.85, 1: 0.15}, C=0.1, score=0.515, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                                random_state=0, solver='saga'),\n",
       "                   param_distributions={'C': array([0.1]),\n",
       "                                        'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'l1_ratio': array([0]),\n",
       "                                        'max_iter': array([1000, 1001, 1002, ..., 9997, 9998, 9999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid2 = {'C': np.arange(0.1,1),\n",
    "             'max_iter': np.arange(1000, 10000),\n",
    "             'l1_ratio': np.arange(0, 1), \n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid2 = RandomizedSearchCV(log_clf, param_grid2, cv = 5, verbose = 5)\n",
    "grid2.fit(X_smo_10, y_smo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 7639, 'l1_ratio': 0, 'class_weight': {0: 0.5, 1: 0.5}, 'C': 0.1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_10 = grid2.best_params_\n",
    "best_log_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_10 = LogisticRegression(C=0.1, class_weight={0: 0.5, 1: 0.5}, l1_ratio=0, max_iter=7639,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')\n",
    "best_log_10.fit(X_smo_10, y_smo)\n",
    "ye_pred2 = best_log_10.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred2, beta = .1, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with more features is better. Next, we'll try a KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 K-Nearest-Neighbours 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use RandomizedSearchCV to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.756, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.727, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.733, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.692, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.704, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.696, total=   0.5s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.703, total=   0.5s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.713, total=   0.4s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.730, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.713, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.715, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.709, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.712, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.697, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.697, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.696, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.695, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.710, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.770, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.755, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.756, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.750, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.758, total=   0.1s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.694, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.690, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.689, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.685, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.692, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.694, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.690, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.689, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.685, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.692, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.640, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.653, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.668, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=5, metric=manhattan ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=manhattan, score=0.781, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=manhattan ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=manhattan, score=0.764, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=manhattan ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=manhattan, score=0.758, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=manhattan ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=manhattan, score=0.756, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=manhattan ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=manhattan, score=0.761, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.756, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.727, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.733, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(n_jobs=-1),\n",
       "                   param_distributions={'metric': ['euclidean', 'manhattan',\n",
       "                                                   'minkowski'],\n",
       "                                        'n_neighbors': [5, 10, 50, 100],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid3 = {\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "             'weights': ['uniform','distance'],\n",
    "            'n_neighbors': [5, 10, 50, 100],}\n",
    "\n",
    "grid3 = RandomizedSearchCV(knn_clf, param_grid3, cv = 5, verbose = 5)\n",
    "grid3.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5, 'metric': 'manhattan'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_5 = grid3.best_params_\n",
    "best_knn_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_5 = KNeighborsClassifier(n_jobs = -1, n_neighbors = 5, metric = 'manhattan', weights = 'distance')\n",
    "best_knn_5.fit(X_smo_5, y_smo)\n",
    "ye_pred3 = best_knn_5.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred3, beta = .2, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's not better than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 K-Nearest-Neighbours 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] weights=distance, n_neighbors=50, metric=minkowski ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=50, metric=minkowski, score=0.723, total=   2.6s\n",
      "[CV] weights=distance, n_neighbors=50, metric=minkowski ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=50, metric=minkowski, score=0.746, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=50, metric=minkowski ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=50, metric=minkowski, score=0.729, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=50, metric=minkowski ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=50, metric=minkowski, score=0.739, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=50, metric=minkowski ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=50, metric=minkowski, score=0.731, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=manhattan ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=manhattan, score=0.800, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=manhattan ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=manhattan, score=0.815, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=manhattan ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=manhattan, score=0.800, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=manhattan ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=manhattan, score=0.811, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=manhattan ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=manhattan, score=0.803, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.790, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.800, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.788, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.792, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=10, metric=minkowski ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=minkowski, score=0.784, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=100, metric=euclidean .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=euclidean, score=0.699, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=100, metric=euclidean .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=euclidean, score=0.718, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=100, metric=euclidean .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=euclidean, score=0.705, total=   0.8s\n",
      "[CV] weights=distance, n_neighbors=100, metric=euclidean .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=euclidean, score=0.711, total=   0.8s\n",
      "[CV] weights=distance, n_neighbors=100, metric=euclidean .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=euclidean, score=0.709, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.657, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.701, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.689, total=   1.3s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.691, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.691, total=   1.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.730, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.746, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.733, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.739, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.738, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.730, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.746, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.733, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.739, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=euclidean, score=0.738, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.658, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.693, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.680, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.686, total=   1.0s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.682, total=   0.7s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.805, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.809, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.796, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.806, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.794, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.782, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.793, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.786, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.793, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.782, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'weights': 'uniform', 'n_neighbors': 5, 'metric': 'manhattan'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid4 = {\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "             'weights': ['uniform','distance'],\n",
    "            'n_neighbors': [5, 10, 50, 100],}\n",
    "\n",
    "grid4 = RandomizedSearchCV(knn_clf, param_grid4, cv = 5, verbose= 5)\n",
    "grid4.fit(X_smo_10, y_smo)\n",
    "best_knn_10 = grid4.best_params_\n",
    "best_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'uniform', 'n_neighbors': 5, 'metric': 'manhattan'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_10 = grid4.best_params_\n",
    "best_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_10 = KNeighborsClassifier(n_jobs = -1, n_neighbors = 50, metric = 'manhattan', weights = 'uniform')\n",
    "best_knn_10.fit(X_smo_10, y_smo)\n",
    "ye_pred4 = best_knn_10.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred4, beta = .1, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is better than the KNN with 5 features but worse than the best logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Ensemble: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best of the simple models above, the logistic regression with 10 features, is now boosted in the hope that this improves performance. Again, randomized search is used to find th ebest hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log = LogisticRegression(C=0.1, class_weight={0: 0.5, 1: 0.5}, l1_ratio=0, max_iter=7812,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=146, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=146, learning_rate=0.1, score=0.631, total=  41.6s\n",
      "[CV] n_estimators=146, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   41.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=146, learning_rate=0.1, score=0.644, total=  41.8s\n",
      "[CV] n_estimators=146, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=146, learning_rate=0.1, score=0.633, total=  40.8s\n",
      "[CV] n_estimators=146, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=146, learning_rate=0.1, score=0.630, total=  41.2s\n",
      "[CV] n_estimators=146, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=146, learning_rate=0.1, score=0.630, total=  41.3s\n",
      "[CV] n_estimators=108, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=108, learning_rate=0.1, score=0.630, total=  29.6s\n",
      "[CV] n_estimators=108, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=108, learning_rate=0.1, score=0.641, total=  30.3s\n",
      "[CV] n_estimators=108, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=108, learning_rate=0.1, score=0.634, total=  30.1s\n",
      "[CV] n_estimators=108, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=108, learning_rate=0.1, score=0.631, total=  29.9s\n",
      "[CV] n_estimators=108, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=108, learning_rate=0.1, score=0.630, total=  30.2s\n",
      "[CV] n_estimators=52, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=52, learning_rate=0.1, score=0.629, total=  16.0s\n",
      "[CV] n_estimators=52, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=52, learning_rate=0.1, score=0.642, total=  15.8s\n",
      "[CV] n_estimators=52, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=52, learning_rate=0.1, score=0.633, total=  14.6s\n",
      "[CV] n_estimators=52, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=52, learning_rate=0.1, score=0.635, total=  15.2s\n",
      "[CV] n_estimators=52, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=52, learning_rate=0.1, score=0.629, total=  18.9s\n",
      "[CV] n_estimators=43, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=43, learning_rate=0.1, score=0.628, total=  12.2s\n",
      "[CV] n_estimators=43, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=43, learning_rate=0.1, score=0.642, total=  11.9s\n",
      "[CV] n_estimators=43, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=43, learning_rate=0.1, score=0.633, total=  12.3s\n",
      "[CV] n_estimators=43, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=43, learning_rate=0.1, score=0.635, total=  16.1s\n",
      "[CV] n_estimators=43, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=43, learning_rate=0.1, score=0.628, total=  12.3s\n",
      "[CV] n_estimators=144, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=144, learning_rate=0.1, score=0.631, total=  40.1s\n",
      "[CV] n_estimators=144, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=144, learning_rate=0.1, score=0.643, total=  41.6s\n",
      "[CV] n_estimators=144, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=144, learning_rate=0.1, score=0.633, total=  42.0s\n",
      "[CV] n_estimators=144, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=144, learning_rate=0.1, score=0.630, total=  45.0s\n",
      "[CV] n_estimators=144, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=144, learning_rate=0.1, score=0.631, total=  41.8s\n",
      "[CV] n_estimators=65, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=65, learning_rate=0.1, score=0.629, total=  18.4s\n",
      "[CV] n_estimators=65, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=65, learning_rate=0.1, score=0.642, total=  18.4s\n",
      "[CV] n_estimators=65, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=65, learning_rate=0.1, score=0.633, total=  18.4s\n",
      "[CV] n_estimators=65, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=65, learning_rate=0.1, score=0.633, total=  20.2s\n",
      "[CV] n_estimators=65, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=65, learning_rate=0.1, score=0.629, total=  23.4s\n",
      "[CV] n_estimators=127, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=127, learning_rate=0.1, score=0.631, total=  35.5s\n",
      "[CV] n_estimators=127, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=127, learning_rate=0.1, score=0.643, total=  41.4s\n",
      "[CV] n_estimators=127, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=127, learning_rate=0.1, score=0.633, total=  38.7s\n",
      "[CV] n_estimators=127, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=127, learning_rate=0.1, score=0.630, total=  39.1s\n",
      "[CV] n_estimators=127, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=127, learning_rate=0.1, score=0.629, total=  38.7s\n",
      "[CV] n_estimators=11, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=11, learning_rate=0.1, score=0.625, total=   3.2s\n",
      "[CV] n_estimators=11, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=11, learning_rate=0.1, score=0.639, total=   3.3s\n",
      "[CV] n_estimators=11, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=11, learning_rate=0.1, score=0.631, total=   3.5s\n",
      "[CV] n_estimators=11, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=11, learning_rate=0.1, score=0.634, total=   3.2s\n",
      "[CV] n_estimators=11, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=11, learning_rate=0.1, score=0.629, total=   3.2s\n",
      "[CV] n_estimators=5, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=5, learning_rate=0.1, score=0.625, total=   1.4s\n",
      "[CV] n_estimators=5, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=5, learning_rate=0.1, score=0.638, total=   1.4s\n",
      "[CV] n_estimators=5, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=5, learning_rate=0.1, score=0.631, total=   1.4s\n",
      "[CV] n_estimators=5, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=5, learning_rate=0.1, score=0.633, total=   1.4s\n",
      "[CV] n_estimators=5, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=5, learning_rate=0.1, score=0.629, total=   1.5s\n",
      "[CV] n_estimators=69, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=69, learning_rate=0.1, score=0.629, total=  22.1s\n",
      "[CV] n_estimators=69, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=69, learning_rate=0.1, score=0.642, total=  20.2s\n",
      "[CV] n_estimators=69, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=69, learning_rate=0.1, score=0.633, total=  20.5s\n",
      "[CV] n_estimators=69, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=69, learning_rate=0.1, score=0.632, total=  23.5s\n",
      "[CV] n_estimators=69, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=69, learning_rate=0.1, score=0.629, total=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=AdaBoostClassifier(base_estimator=LogisticRegression(C=0.1,\n",
       "                                                                                  class_weight={0: 0.5,\n",
       "                                                                                                1: 0.5},\n",
       "                                                                                  l1_ratio=0,\n",
       "                                                                                  max_iter=7812,\n",
       "                                                                                  n_jobs=-1,\n",
       "                                                                                  penalty='elasticnet',\n",
       "                                                                                  random_state=0,\n",
       "                                                                                  solver='saga')),\n",
       "                   param_distributions={'learning_rate': array([0.1]),\n",
       "                                        'n_estimators': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  2...\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_boost = AdaBoostClassifier(base_estimator=best_log) \n",
    "\n",
    "param_grid5 = {'n_estimators':np.arange(1, 150),                \n",
    "              'learning_rate':np.arange(0.1, 1),                          \n",
    "             } \n",
    "grid5 = RandomizedSearchCV(clf_boost, param_grid5, verbose = 5) \n",
    "grid5.fit(X_smo_10, y_smo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 146, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_boost_model = grid5.best_params_\n",
    "best_boost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boost = AdaBoostClassifier(base_estimator=best_log, n_estimators = 146, learning_rate = 0.1) \n",
    "best_boost.fit(X_smo_10, y_smo)\n",
    "ye_pred5 = best_boost.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred5, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred5), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdaBoost is not as good as the best logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Ensemble: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsClassifier(n_jobs = -1, n_neighbors = 5, metric = 'manhattan', weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('bestlog', best_log), \n",
    "    ('bestknn', best_knn)]\n",
    "stack = StackingClassifier(estimators, final_estimator=LogisticRegression(), cv=5, \n",
    "                           stack_method='auto', n_jobs=-1, verbose=5)\n",
    "stack.fit(X_smo_10, y_smo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ye_pred6 = stack.predict(X_test_10)\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred6, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred6), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is also not as good as the logistic regression model and barely better than the basline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12 Decision Tree (5 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=7),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                                        'min_samples_split': [10, 30, 50, 70,\n",
       "                                                              90, 110, 130, 150,\n",
       "                                                              170, 190, 210,\n",
       "                                                              230, 250, 270,\n",
       "                                                              290, 310, 330,\n",
       "                                                              350, 370, 390,\n",
       "                                                              410, 430, 450,\n",
       "                                                              470, 490]},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "param_grid7 = {'criterion': ['gini','entropy'],\n",
    "             'max_depth': np.arange(1, 20),\n",
    "             'min_samples_split':list(range(10,500,20)),\n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid7 = RandomizedSearchCV(dt_clf, param_grid7, cv=5, verbose=5, n_jobs=-1)\n",
    "grid7.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 390,\n",
       " 'max_depth': 19,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': {0: 0.6, 1: 0.4}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_model_5 = grid7.best_params_\n",
    "best_dt_model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dt_model_5 = DecisionTreeClassifier(min_samples_split= 390, max_depth= 19, criterion ='gini', class_weight = {0: 0.6, 1: 0.4})\n",
    "best_dt_model_5.fit(X_smo_5, y_smo)\n",
    "ye_pred7 = best_dt_model_5.predict(X_test_5)\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred7, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred7), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree is even worse than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13 Decision Tree (10 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=7),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                                        'min_samples_split': [10, 30, 50, 70,\n",
       "                                                              90, 110, 130, 150,\n",
       "                                                              170, 190, 210,\n",
       "                                                              230, 250, 270,\n",
       "                                                              290, 310, 330,\n",
       "                                                              350, 370, 390,\n",
       "                                                              410, 430, 450,\n",
       "                                                              470, 490]},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "param_grid8 = {'criterion': ['gini','entropy'],\n",
    "             'max_depth': np.arange(1, 20),\n",
    "             'min_samples_split':list(range(10,500,20)),\n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid8 = RandomizedSearchCV(dt_clf, param_grid8, cv=5, verbose=5, n_jobs=-1)\n",
    "grid8.fit(X_smo_10, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 90,\n",
       " 'max_depth': 12,\n",
       " 'criterion': 'entropy',\n",
       " 'class_weight': {0: 0.5, 1: 0.5}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_model_10 = grid8.best_params_\n",
    "best_dt_model_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dt_model_10 = DecisionTreeClassifier(min_samples_split= 190, max_depth= 5, criterion ='entropy', class_weight = {0: 0.6, 1: 0.4})\n",
    "best_dt_model_10.fit(X_smo_10, y_smo)\n",
    "ye_pred8 = best_dt_model_10.predict(X_test_10)\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred8, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred8), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decision tree is nearly as good as the logistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14 Random Forest (5 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 904building tree 2 of 904building tree 3 of 904\n",
      "\n",
      "building tree 4 of 904\n",
      "\n",
      "building tree 5 of 904building tree 6 of 904\n",
      "\n",
      "building tree 7 of 904\n",
      "building tree 8 of 904\n",
      "building tree 9 of 904\n",
      "building tree 10 of 904\n",
      "building tree 11 of 904\n",
      "building tree 12 of 904\n",
      "building tree 13 of 904building tree 14 of 904\n",
      "\n",
      "building tree 15 of 904\n",
      "building tree 16 of 904\n",
      "building tree 17 of 904building tree 18 of 904\n",
      "\n",
      "building tree 19 of 904\n",
      "building tree 20 of 904\n",
      "building tree 21 of 904\n",
      "building tree 22 of 904\n",
      "building tree 23 of 904\n",
      "building tree 24 of 904\n",
      "building tree 25 of 904building tree 26 of 904\n",
      "\n",
      "building tree 27 of 904\n",
      "building tree 28 of 904\n",
      "building tree 29 of 904\n",
      "building tree 30 of 904\n",
      "building tree 31 of 904\n",
      "building tree 32 of 904\n",
      "building tree 33 of 904\n",
      "building tree 34 of 904\n",
      "building tree 35 of 904\n",
      "building tree 36 of 904\n",
      "building tree 37 of 904\n",
      "building tree 38 of 904building tree 39 of 904\n",
      "\n",
      "building tree 40 of 904\n",
      "building tree 41 of 904\n",
      "building tree 42 of 904\n",
      "building tree 43 of 904\n",
      "building tree 44 of 904\n",
      "building tree 45 of 904\n",
      "building tree 46 of 904\n",
      "building tree 47 of 904\n",
      "building tree 48 of 904\n",
      "building tree 49 of 904\n",
      "building tree 50 of 904building tree 51 of 904\n",
      "\n",
      "building tree 52 of 904\n",
      "building tree 53 of 904\n",
      "building tree 54 of 904\n",
      "building tree 55 of 904\n",
      "building tree 56 of 904\n",
      "building tree 57 of 904\n",
      "building tree 58 of 904\n",
      "building tree 59 of 904\n",
      "building tree 60 of 904\n",
      "building tree 61 of 904building tree 62 of 904\n",
      "\n",
      "building tree 63 of 904\n",
      "building tree 64 of 904\n",
      "building tree 65 of 904\n",
      "building tree 66 of 904\n",
      "building tree 67 of 904\n",
      "building tree 68 of 904\n",
      "building tree 69 of 904\n",
      "building tree 70 of 904\n",
      "building tree 71 of 904\n",
      "building tree 72 of 904\n",
      "building tree 73 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 74 of 904building tree 75 of 904\n",
      "\n",
      "building tree 76 of 904\n",
      "building tree 77 of 904\n",
      "building tree 78 of 904\n",
      "building tree 79 of 904\n",
      "building tree 80 of 904\n",
      "building tree 81 of 904\n",
      "building tree 82 of 904\n",
      "building tree 83 of 904\n",
      "building tree 84 of 904\n",
      "building tree 85 of 904\n",
      "building tree 86 of 904\n",
      "building tree 87 of 904\n",
      "building tree 88 of 904\n",
      "building tree 89 of 904\n",
      "building tree 90 of 904\n",
      "building tree 91 of 904\n",
      "building tree 92 of 904\n",
      "building tree 93 of 904\n",
      "building tree 94 of 904\n",
      "building tree 95 of 904\n",
      "building tree 96 of 904\n",
      "building tree 97 of 904\n",
      "building tree 98 of 904\n",
      "building tree 99 of 904\n",
      "building tree 100 of 904\n",
      "building tree 101 of 904\n",
      "building tree 102 of 904\n",
      "building tree 103 of 904\n",
      "building tree 104 of 904\n",
      "building tree 105 of 904\n",
      "building tree 106 of 904\n",
      "building tree 107 of 904\n",
      "building tree 108 of 904\n",
      "building tree 109 of 904building tree 110 of 904\n",
      "\n",
      "building tree 111 of 904\n",
      "building tree 112 of 904\n",
      "building tree 113 of 904\n",
      "building tree 114 of 904\n",
      "building tree 115 of 904\n",
      "building tree 116 of 904\n",
      "building tree 117 of 904\n",
      "building tree 118 of 904\n",
      "building tree 119 of 904\n",
      "building tree 120 of 904\n",
      "building tree 121 of 904\n",
      "building tree 122 of 904\n",
      "building tree 123 of 904\n",
      "building tree 124 of 904\n",
      "building tree 125 of 904\n",
      "building tree 126 of 904\n",
      "building tree 127 of 904\n",
      "building tree 128 of 904\n",
      "building tree 129 of 904\n",
      "building tree 130 of 904\n",
      "building tree 131 of 904\n",
      "building tree 132 of 904\n",
      "building tree 133 of 904\n",
      "building tree 134 of 904building tree 135 of 904\n",
      "\n",
      "building tree 136 of 904\n",
      "building tree 137 of 904\n",
      "building tree 138 of 904\n",
      "building tree 139 of 904\n",
      "building tree 140 of 904\n",
      "building tree 141 of 904\n",
      "building tree 142 of 904\n",
      "building tree 143 of 904\n",
      "building tree 144 of 904\n",
      "building tree 145 of 904\n",
      "building tree 146 of 904\n",
      "building tree 147 of 904\n",
      "building tree 148 of 904building tree 149 of 904\n",
      "\n",
      "building tree 150 of 904\n",
      "building tree 151 of 904\n",
      "building tree 152 of 904\n",
      "building tree 153 of 904\n",
      "building tree 154 of 904\n",
      "building tree 155 of 904\n",
      "building tree 156 of 904\n",
      "building tree 157 of 904\n",
      "building tree 158 of 904\n",
      "building tree 159 of 904\n",
      "building tree 160 of 904\n",
      "building tree 161 of 904\n",
      "building tree 162 of 904\n",
      "building tree 163 of 904\n",
      "building tree 164 of 904\n",
      "building tree 165 of 904\n",
      "building tree 166 of 904\n",
      "building tree 167 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 168 of 904building tree 169 of 904\n",
      "\n",
      "building tree 170 of 904\n",
      "building tree 171 of 904\n",
      "building tree 172 of 904\n",
      "building tree 173 of 904\n",
      "building tree 174 of 904\n",
      "building tree 175 of 904\n",
      "building tree 176 of 904\n",
      "building tree 177 of 904\n",
      "building tree 178 of 904\n",
      "building tree 179 of 904\n",
      "building tree 180 of 904\n",
      "building tree 181 of 904\n",
      "building tree 182 of 904\n",
      "building tree 183 of 904\n",
      "building tree 184 of 904\n",
      "building tree 185 of 904\n",
      "building tree 186 of 904\n",
      "building tree 187 of 904\n",
      "building tree 188 of 904\n",
      "building tree 189 of 904\n",
      "building tree 190 of 904building tree 191 of 904\n",
      "\n",
      "building tree 192 of 904\n",
      "building tree 193 of 904\n",
      "building tree 194 of 904\n",
      "building tree 195 of 904\n",
      "building tree 196 of 904\n",
      "building tree 197 of 904\n",
      "building tree 198 of 904\n",
      "building tree 199 of 904\n",
      "building tree 200 of 904\n",
      "building tree 201 of 904\n",
      "building tree 202 of 904\n",
      "building tree 203 of 904\n",
      "building tree 204 of 904\n",
      "building tree 205 of 904\n",
      "building tree 206 of 904\n",
      "building tree 207 of 904\n",
      "building tree 208 of 904\n",
      "building tree 209 of 904\n",
      "building tree 210 of 904\n",
      "building tree 211 of 904\n",
      "building tree 212 of 904\n",
      "building tree 213 of 904\n",
      "building tree 214 of 904\n",
      "building tree 215 of 904\n",
      "building tree 216 of 904\n",
      "building tree 217 of 904\n",
      "building tree 218 of 904\n",
      "building tree 219 of 904\n",
      "building tree 220 of 904\n",
      "building tree 221 of 904\n",
      "building tree 222 of 904\n",
      "building tree 223 of 904\n",
      "building tree 224 of 904\n",
      "building tree 225 of 904\n",
      "building tree 226 of 904\n",
      "building tree 227 of 904\n",
      "building tree 228 of 904\n",
      "building tree 229 of 904\n",
      "building tree 230 of 904\n",
      "building tree 231 of 904\n",
      "building tree 232 of 904\n",
      "building tree 233 of 904\n",
      "building tree 234 of 904\n",
      "building tree 235 of 904\n",
      "building tree 236 of 904\n",
      "building tree 237 of 904\n",
      "building tree 238 of 904\n",
      "building tree 239 of 904\n",
      "building tree 240 of 904\n",
      "building tree 241 of 904\n",
      "building tree 242 of 904\n",
      "building tree 243 of 904\n",
      "building tree 244 of 904\n",
      "building tree 245 of 904\n",
      "building tree 246 of 904\n",
      "building tree 247 of 904\n",
      "building tree 248 of 904building tree 249 of 904\n",
      "\n",
      "building tree 250 of 904\n",
      "building tree 251 of 904\n",
      "building tree 252 of 904\n",
      "building tree 253 of 904\n",
      "building tree 254 of 904\n",
      "building tree 255 of 904\n",
      "building tree 256 of 904building tree 257 of 904\n",
      "\n",
      "building tree 258 of 904\n",
      "building tree 259 of 904\n",
      "building tree 260 of 904\n",
      "building tree 261 of 904\n",
      "building tree 262 of 904\n",
      "building tree 263 of 904\n",
      "building tree 264 of 904\n",
      "building tree 265 of 904\n",
      "building tree 266 of 904\n",
      "building tree 267 of 904\n",
      "building tree 268 of 904\n",
      "building tree 269 of 904\n",
      "building tree 270 of 904\n",
      "building tree 271 of 904\n",
      "building tree 272 of 904\n",
      "building tree 273 of 904\n",
      "building tree 274 of 904\n",
      "building tree 275 of 904\n",
      "building tree 276 of 904\n",
      "building tree 277 of 904\n",
      "building tree 278 of 904\n",
      "building tree 279 of 904\n",
      "building tree 280 of 904\n",
      "building tree 281 of 904\n",
      "building tree 282 of 904\n",
      "building tree 283 of 904\n",
      "building tree 284 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 285 of 904\n",
      "building tree 286 of 904\n",
      "building tree 287 of 904\n",
      "building tree 288 of 904\n",
      "building tree 289 of 904\n",
      "building tree 290 of 904\n",
      "building tree 291 of 904\n",
      "building tree 292 of 904\n",
      "building tree 293 of 904\n",
      "building tree 294 of 904\n",
      "building tree 295 of 904\n",
      "building tree 296 of 904\n",
      "building tree 297 of 904\n",
      "building tree 298 of 904\n",
      "building tree 299 of 904\n",
      "building tree 300 of 904\n",
      "building tree 301 of 904\n",
      "building tree 302 of 904\n",
      "building tree 303 of 904\n",
      "building tree 304 of 904\n",
      "building tree 305 of 904\n",
      "building tree 306 of 904\n",
      "building tree 307 of 904\n",
      "building tree 308 of 904\n",
      "building tree 309 of 904\n",
      "building tree 310 of 904\n",
      "building tree 311 of 904\n",
      "building tree 312 of 904\n",
      "building tree 313 of 904\n",
      "building tree 314 of 904\n",
      "building tree 315 of 904\n",
      "building tree 316 of 904\n",
      "building tree 317 of 904\n",
      "building tree 318 of 904\n",
      "building tree 319 of 904\n",
      "building tree 320 of 904\n",
      "building tree 321 of 904\n",
      "building tree 322 of 904\n",
      "building tree 323 of 904\n",
      "building tree 324 of 904\n",
      "building tree 325 of 904\n",
      "building tree 326 of 904\n",
      "building tree 327 of 904\n",
      "building tree 328 of 904\n",
      "building tree 329 of 904\n",
      "building tree 330 of 904\n",
      "building tree 331 of 904\n",
      "building tree 332 of 904\n",
      "building tree 333 of 904\n",
      "building tree 334 of 904\n",
      "building tree 335 of 904\n",
      "building tree 336 of 904\n",
      "building tree 337 of 904\n",
      "building tree 338 of 904\n",
      "building tree 339 of 904\n",
      "building tree 340 of 904\n",
      "building tree 341 of 904\n",
      "building tree 342 of 904\n",
      "building tree 343 of 904\n",
      "building tree 344 of 904\n",
      "building tree 345 of 904building tree 346 of 904\n",
      "\n",
      "building tree 347 of 904\n",
      "building tree 348 of 904\n",
      "building tree 349 of 904\n",
      "building tree 350 of 904\n",
      "building tree 351 of 904\n",
      "building tree 352 of 904\n",
      "building tree 353 of 904building tree 354 of 904\n",
      "\n",
      "building tree 355 of 904\n",
      "building tree 356 of 904\n",
      "building tree 357 of 904\n",
      "building tree 358 of 904\n",
      "building tree 359 of 904\n",
      "building tree 360 of 904\n",
      "building tree 361 of 904\n",
      "building tree 362 of 904\n",
      "building tree 363 of 904\n",
      "building tree 364 of 904\n",
      "building tree 365 of 904\n",
      "building tree 366 of 904\n",
      "building tree 367 of 904\n",
      "building tree 368 of 904\n",
      "building tree 369 of 904\n",
      "building tree 370 of 904\n",
      "building tree 371 of 904\n",
      "building tree 372 of 904\n",
      "building tree 373 of 904\n",
      "building tree 374 of 904\n",
      "building tree 375 of 904\n",
      "building tree 376 of 904building tree 377 of 904\n",
      "\n",
      "building tree 378 of 904\n",
      "building tree 379 of 904\n",
      "building tree 380 of 904\n",
      "building tree 381 of 904\n",
      "building tree 382 of 904\n",
      "building tree 383 of 904\n",
      "building tree 384 of 904\n",
      "building tree 385 of 904\n",
      "building tree 386 of 904\n",
      "building tree 387 of 904\n",
      "building tree 388 of 904building tree 389 of 904\n",
      "\n",
      "building tree 390 of 904\n",
      "building tree 391 of 904\n",
      "building tree 392 of 904\n",
      "building tree 393 of 904\n",
      "building tree 394 of 904\n",
      "building tree 395 of 904\n",
      "building tree 396 of 904\n",
      "building tree 397 of 904\n",
      "building tree 398 of 904\n",
      "building tree 399 of 904\n",
      "building tree 400 of 904\n",
      "building tree 401 of 904\n",
      "building tree 402 of 904\n",
      "building tree 403 of 904\n",
      "building tree 404 of 904\n",
      "building tree 405 of 904\n",
      "building tree 406 of 904\n",
      "building tree 407 of 904\n",
      "building tree 408 of 904\n",
      "building tree 409 of 904\n",
      "building tree 410 of 904\n",
      "building tree 411 of 904building tree 412 of 904\n",
      "\n",
      "building tree 413 of 904\n",
      "building tree 414 of 904\n",
      "building tree 415 of 904\n",
      "building tree 416 of 904\n",
      "building tree 417 of 904\n",
      "building tree 418 of 904\n",
      "building tree 419 of 904\n",
      "building tree 420 of 904\n",
      "building tree 421 of 904\n",
      "building tree 422 of 904\n",
      "building tree 423 of 904\n",
      "building tree 424 of 904\n",
      "building tree 425 of 904\n",
      "building tree 426 of 904\n",
      "building tree 427 of 904\n",
      "building tree 428 of 904\n",
      "building tree 429 of 904\n",
      "building tree 430 of 904\n",
      "building tree 431 of 904\n",
      "building tree 432 of 904\n",
      "building tree 433 of 904\n",
      "building tree 434 of 904\n",
      "building tree 435 of 904\n",
      "building tree 436 of 904\n",
      "building tree 437 of 904\n",
      "building tree 438 of 904\n",
      "building tree 439 of 904\n",
      "building tree 440 of 904\n",
      "building tree 441 of 904\n",
      "building tree 442 of 904\n",
      "building tree 443 of 904\n",
      "building tree 444 of 904\n",
      "building tree 445 of 904\n",
      "building tree 446 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 447 of 904\n",
      "building tree 448 of 904\n",
      "building tree 449 of 904\n",
      "building tree 450 of 904\n",
      "building tree 451 of 904\n",
      "building tree 452 of 904\n",
      "building tree 453 of 904\n",
      "building tree 454 of 904\n",
      "building tree 455 of 904\n",
      "building tree 456 of 904\n",
      "building tree 457 of 904\n",
      "building tree 458 of 904\n",
      "building tree 459 of 904\n",
      "building tree 460 of 904\n",
      "building tree 461 of 904\n",
      "building tree 462 of 904\n",
      "building tree 463 of 904\n",
      "building tree 464 of 904\n",
      "building tree 465 of 904\n",
      "building tree 466 of 904\n",
      "building tree 467 of 904\n",
      "building tree 468 of 904building tree 469 of 904\n",
      "\n",
      "building tree 470 of 904\n",
      "building tree 471 of 904\n",
      "building tree 472 of 904\n",
      "building tree 473 of 904\n",
      "building tree 474 of 904\n",
      "building tree 475 of 904\n",
      "building tree 476 of 904\n",
      "building tree 477 of 904\n",
      "building tree 478 of 904\n",
      "building tree 479 of 904\n",
      "building tree 480 of 904\n",
      "building tree 481 of 904\n",
      "building tree 482 of 904\n",
      "building tree 483 of 904\n",
      "building tree 484 of 904\n",
      "building tree 485 of 904\n",
      "building tree 486 of 904\n",
      "building tree 487 of 904\n",
      "building tree 488 of 904\n",
      "building tree 489 of 904\n",
      "building tree 490 of 904\n",
      "building tree 491 of 904\n",
      "building tree 492 of 904\n",
      "building tree 493 of 904building tree 494 of 904\n",
      "\n",
      "building tree 495 of 904\n",
      "building tree 496 of 904\n",
      "building tree 497 of 904\n",
      "building tree 498 of 904\n",
      "building tree 499 of 904\n",
      "building tree 500 of 904\n",
      "building tree 501 of 904\n",
      "building tree 502 of 904\n",
      "building tree 503 of 904\n",
      "building tree 504 of 904\n",
      "building tree 505 of 904\n",
      "building tree 506 of 904\n",
      "building tree 507 of 904\n",
      "building tree 508 of 904\n",
      "building tree 509 of 904\n",
      "building tree 510 of 904\n",
      "building tree 511 of 904\n",
      "building tree 512 of 904\n",
      "building tree 513 of 904building tree 514 of 904\n",
      "\n",
      "building tree 515 of 904\n",
      "building tree 516 of 904\n",
      "building tree 517 of 904\n",
      "building tree 518 of 904\n",
      "building tree 519 of 904\n",
      "building tree 520 of 904\n",
      "building tree 521 of 904\n",
      "building tree 522 of 904\n",
      "building tree 523 of 904\n",
      "building tree 524 of 904\n",
      "building tree 525 of 904\n",
      "building tree 526 of 904\n",
      "building tree 527 of 904\n",
      "building tree 528 of 904\n",
      "building tree 529 of 904\n",
      "building tree 530 of 904\n",
      "building tree 531 of 904\n",
      "building tree 532 of 904\n",
      "building tree 533 of 904\n",
      "building tree 534 of 904\n",
      "building tree 535 of 904\n",
      "building tree 536 of 904\n",
      "building tree 537 of 904\n",
      "building tree 538 of 904\n",
      "building tree 539 of 904\n",
      "building tree 540 of 904\n",
      "building tree 541 of 904\n",
      "building tree 542 of 904\n",
      "building tree 543 of 904\n",
      "building tree 544 of 904\n",
      "building tree 545 of 904\n",
      "building tree 546 of 904\n",
      "building tree 547 of 904\n",
      "building tree 548 of 904\n",
      "building tree 549 of 904\n",
      "building tree 550 of 904\n",
      "building tree 551 of 904\n",
      "building tree 552 of 904\n",
      "building tree 553 of 904\n",
      "building tree 554 of 904\n",
      "building tree 555 of 904\n",
      "building tree 556 of 904\n",
      "building tree 557 of 904\n",
      "building tree 558 of 904\n",
      "building tree 559 of 904\n",
      "building tree 560 of 904\n",
      "building tree 561 of 904\n",
      "building tree 562 of 904\n",
      "building tree 563 of 904\n",
      "building tree 564 of 904\n",
      "building tree 565 of 904\n",
      "building tree 566 of 904\n",
      "building tree 567 of 904\n",
      "building tree 568 of 904\n",
      "building tree 569 of 904\n",
      "building tree 570 of 904\n",
      "building tree 571 of 904\n",
      "building tree 572 of 904building tree 573 of 904\n",
      "\n",
      "building tree 574 of 904\n",
      "building tree 575 of 904\n",
      "building tree 576 of 904\n",
      "building tree 577 of 904\n",
      "building tree 578 of 904\n",
      "building tree 579 of 904\n",
      "building tree 580 of 904\n",
      "building tree 581 of 904\n",
      "building tree 582 of 904\n",
      "building tree 583 of 904\n",
      "building tree 584 of 904\n",
      "building tree 585 of 904\n",
      "building tree 586 of 904\n",
      "building tree 587 of 904\n",
      "building tree 588 of 904\n",
      "building tree 589 of 904\n",
      "building tree 590 of 904\n",
      "building tree 591 of 904\n",
      "building tree 592 of 904\n",
      "building tree 593 of 904\n",
      "building tree 594 of 904\n",
      "building tree 595 of 904\n",
      "building tree 596 of 904\n",
      "building tree 597 of 904\n",
      "building tree 598 of 904\n",
      "building tree 599 of 904\n",
      "building tree 600 of 904\n",
      "building tree 601 of 904\n",
      "building tree 602 of 904\n",
      "building tree 603 of 904\n",
      "building tree 604 of 904\n",
      "building tree 605 of 904\n",
      "building tree 606 of 904\n",
      "building tree 607 of 904building tree 608 of 904\n",
      "\n",
      "building tree 609 of 904\n",
      "building tree 610 of 904\n",
      "building tree 611 of 904\n",
      "building tree 612 of 904\n",
      "building tree 613 of 904\n",
      "building tree 614 of 904\n",
      "building tree 615 of 904\n",
      "building tree 616 of 904\n",
      "building tree 617 of 904\n",
      "building tree 618 of 904\n",
      "building tree 619 of 904\n",
      "building tree 620 of 904\n",
      "building tree 621 of 904\n",
      "building tree 622 of 904\n",
      "building tree 623 of 904\n",
      "building tree 624 of 904\n",
      "building tree 625 of 904\n",
      "building tree 626 of 904\n",
      "building tree 627 of 904\n",
      "building tree 628 of 904\n",
      "building tree 629 of 904\n",
      "building tree 630 of 904\n",
      "building tree 631 of 904\n",
      "building tree 632 of 904building tree 633 of 904\n",
      "\n",
      "building tree 634 of 904\n",
      "building tree 635 of 904\n",
      "building tree 636 of 904\n",
      "building tree 637 of 904\n",
      "building tree 638 of 904\n",
      "building tree 639 of 904\n",
      "building tree 640 of 904\n",
      "building tree 641 of 904\n",
      "building tree 642 of 904\n",
      "building tree 643 of 904\n",
      "building tree 644 of 904\n",
      "building tree 645 of 904\n",
      "building tree 646 of 904\n",
      "building tree 647 of 904\n",
      "building tree 648 of 904\n",
      "building tree 649 of 904\n",
      "building tree 650 of 904\n",
      "building tree 651 of 904\n",
      "building tree 652 of 904\n",
      "building tree 653 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 654 of 904\n",
      "building tree 655 of 904\n",
      "building tree 656 of 904\n",
      "building tree 657 of 904\n",
      "building tree 658 of 904\n",
      "building tree 659 of 904\n",
      "building tree 660 of 904\n",
      "building tree 661 of 904\n",
      "building tree 662 of 904\n",
      "building tree 663 of 904\n",
      "building tree 664 of 904\n",
      "building tree 665 of 904\n",
      "building tree 666 of 904\n",
      "building tree 667 of 904\n",
      "building tree 668 of 904\n",
      "building tree 669 of 904\n",
      "building tree 670 of 904\n",
      "building tree 671 of 904\n",
      "building tree 672 of 904\n",
      "building tree 673 of 904\n",
      "building tree 674 of 904\n",
      "building tree 675 of 904\n",
      "building tree 676 of 904\n",
      "building tree 677 of 904\n",
      "building tree 678 of 904\n",
      "building tree 679 of 904\n",
      "building tree 680 of 904\n",
      "building tree 681 of 904\n",
      "building tree 682 of 904\n",
      "building tree 683 of 904\n",
      "building tree 684 of 904\n",
      "building tree 685 of 904\n",
      "building tree 686 of 904\n",
      "building tree 687 of 904\n",
      "building tree 688 of 904\n",
      "building tree 689 of 904\n",
      "building tree 690 of 904\n",
      "building tree 691 of 904\n",
      "building tree 692 of 904\n",
      "building tree 693 of 904\n",
      "building tree 694 of 904\n",
      "building tree 695 of 904\n",
      "building tree 696 of 904\n",
      "building tree 697 of 904\n",
      "building tree 698 of 904\n",
      "building tree 699 of 904\n",
      "building tree 700 of 904\n",
      "building tree 701 of 904\n",
      "building tree 702 of 904\n",
      "building tree 703 of 904\n",
      "building tree 704 of 904\n",
      "building tree 705 of 904\n",
      "building tree 706 of 904\n",
      "building tree 707 of 904\n",
      "building tree 708 of 904\n",
      "building tree 709 of 904\n",
      "building tree 710 of 904building tree 711 of 904\n",
      "\n",
      "building tree 712 of 904\n",
      "building tree 713 of 904\n",
      "building tree 714 of 904\n",
      "building tree 715 of 904building tree 716 of 904\n",
      "\n",
      "building tree 717 of 904\n",
      "building tree 718 of 904\n",
      "building tree 719 of 904\n",
      "building tree 720 of 904\n",
      "building tree 721 of 904\n",
      "building tree 722 of 904\n",
      "building tree 723 of 904\n",
      "building tree 724 of 904\n",
      "building tree 725 of 904\n",
      "building tree 726 of 904\n",
      "building tree 727 of 904\n",
      "building tree 728 of 904\n",
      "building tree 729 of 904\n",
      "building tree 730 of 904\n",
      "building tree 731 of 904building tree 732 of 904\n",
      "\n",
      "building tree 733 of 904\n",
      "building tree 734 of 904\n",
      "building tree 735 of 904\n",
      "building tree 736 of 904\n",
      "building tree 737 of 904\n",
      "building tree 738 of 904\n",
      "building tree 739 of 904\n",
      "building tree 740 of 904\n",
      "building tree 741 of 904\n",
      "building tree 742 of 904\n",
      "building tree 743 of 904\n",
      "building tree 744 of 904\n",
      "building tree 745 of 904\n",
      "building tree 746 of 904\n",
      "building tree 747 of 904\n",
      "building tree 748 of 904\n",
      "building tree 749 of 904\n",
      "building tree 750 of 904\n",
      "building tree 751 of 904\n",
      "building tree 752 of 904\n",
      "building tree 753 of 904\n",
      "building tree 754 of 904\n",
      "building tree 755 of 904\n",
      "building tree 756 of 904\n",
      "building tree 757 of 904\n",
      "building tree 758 of 904\n",
      "building tree 759 of 904\n",
      "building tree 760 of 904\n",
      "building tree 761 of 904\n",
      "building tree 762 of 904\n",
      "building tree 763 of 904\n",
      "building tree 764 of 904\n",
      "building tree 765 of 904\n",
      "building tree 766 of 904\n",
      "building tree 767 of 904\n",
      "building tree 768 of 904\n",
      "building tree 769 of 904\n",
      "building tree 770 of 904\n",
      "building tree 771 of 904\n",
      "building tree 772 of 904\n",
      "building tree 773 of 904\n",
      "building tree 774 of 904\n",
      "building tree 775 of 904\n",
      "building tree 776 of 904\n",
      "building tree 777 of 904\n",
      "building tree 778 of 904\n",
      "building tree 779 of 904\n",
      "building tree 780 of 904\n",
      "building tree 781 of 904\n",
      "building tree 782 of 904\n",
      "building tree 783 of 904\n",
      "building tree 784 of 904\n",
      "building tree 785 of 904\n",
      "building tree 786 of 904\n",
      "building tree 787 of 904\n",
      "building tree 788 of 904\n",
      "building tree 789 of 904\n",
      "building tree 790 of 904\n",
      "building tree 791 of 904\n",
      "building tree 792 of 904\n",
      "building tree 793 of 904\n",
      "building tree 794 of 904\n",
      "building tree 795 of 904\n",
      "building tree 796 of 904\n",
      "building tree 797 of 904\n",
      "building tree 798 of 904\n",
      "building tree 799 of 904\n",
      "building tree 800 of 904\n",
      "building tree 801 of 904\n",
      "building tree 802 of 904\n",
      "building tree 803 of 904building tree 804 of 904\n",
      "\n",
      "building tree 805 of 904\n",
      "building tree 806 of 904building tree 807 of 904\n",
      "\n",
      "building tree 808 of 904\n",
      "building tree 809 of 904\n",
      "building tree 810 of 904building tree 811 of 904\n",
      "\n",
      "building tree 812 of 904\n",
      "building tree 813 of 904\n",
      "building tree 814 of 904\n",
      "building tree 815 of 904\n",
      "building tree 816 of 904\n",
      "building tree 817 of 904\n",
      "building tree 818 of 904\n",
      "building tree 819 of 904\n",
      "building tree 820 of 904\n",
      "building tree 821 of 904\n",
      "building tree 822 of 904\n",
      "building tree 823 of 904\n",
      "building tree 824 of 904\n",
      "building tree 825 of 904\n",
      "building tree 826 of 904\n",
      "building tree 827 of 904\n",
      "building tree 828 of 904\n",
      "building tree 829 of 904\n",
      "building tree 830 of 904\n",
      "building tree 831 of 904\n",
      "building tree 832 of 904\n",
      "building tree 833 of 904\n",
      "building tree 834 of 904\n",
      "building tree 835 of 904\n",
      "building tree 836 of 904\n",
      "building tree 837 of 904\n",
      "building tree 838 of 904\n",
      "building tree 839 of 904\n",
      "building tree 840 of 904\n",
      "building tree 841 of 904\n",
      "building tree 842 of 904\n",
      "building tree 843 of 904\n",
      "building tree 844 of 904\n",
      "building tree 845 of 904\n",
      "building tree 846 of 904building tree 847 of 904\n",
      "\n",
      "building tree 848 of 904\n",
      "building tree 849 of 904\n",
      "building tree 850 of 904\n",
      "building tree 851 of 904\n",
      "building tree 852 of 904\n",
      "building tree 853 of 904\n",
      "building tree 854 of 904\n",
      "building tree 855 of 904building tree 856 of 904\n",
      "\n",
      "building tree 857 of 904\n",
      "building tree 858 of 904\n",
      "building tree 859 of 904\n",
      "building tree 860 of 904\n",
      "building tree 861 of 904\n",
      "building tree 862 of 904\n",
      "building tree 863 of 904\n",
      "building tree 864 of 904\n",
      "building tree 865 of 904\n",
      "building tree 866 of 904\n",
      "building tree 867 of 904\n",
      "building tree 868 of 904\n",
      "building tree 869 of 904\n",
      "building tree 870 of 904\n",
      "building tree 871 of 904\n",
      "building tree 872 of 904\n",
      "building tree 873 of 904\n",
      "building tree 874 of 904\n",
      "building tree 875 of 904\n",
      "building tree 876 of 904\n",
      "building tree 877 of 904\n",
      "building tree 878 of 904\n",
      "building tree 879 of 904\n",
      "building tree 880 of 904\n",
      "building tree 881 of 904\n",
      "building tree 882 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:   17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 883 of 904\n",
      "building tree 884 of 904\n",
      "building tree 885 of 904\n",
      "building tree 886 of 904\n",
      "building tree 887 of 904\n",
      "building tree 888 of 904\n",
      "building tree 889 of 904\n",
      "building tree 890 of 904\n",
      "building tree 891 of 904\n",
      "building tree 892 of 904building tree 893 of 904\n",
      "\n",
      "building tree 894 of 904\n",
      "building tree 895 of 904\n",
      "building tree 896 of 904\n",
      "building tree 897 of 904\n",
      "building tree 898 of 904\n",
      "building tree 899 of 904\n",
      "building tree 900 of 904\n",
      "building tree 901 of 904\n",
      "building tree 902 of 904\n",
      "building tree 903 of 904\n",
      "building tree 904 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 904 out of 904 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=8,\n",
       "                                                    verbose=5),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([ 1...\n",
       "       906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918,\n",
       "       919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931,\n",
       "       932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944,\n",
       "       945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957,\n",
       "       958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970,\n",
       "       971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983,\n",
       "       984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996,\n",
       "       997, 998, 999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf =RandomForestClassifier(n_jobs = -1, random_state = 8, verbose = 5, bootstrap = True)\n",
    "param_grid9 = {'n_estimators': np.arange(100, 1000),\n",
    "               'max_depth': np.arange(1, 20),\n",
    "               'criterion': ['gini','entropy'],\n",
    "               'min_samples_split':list(range(10,500,20)),\n",
    "               'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid9 = RandomizedSearchCV(rf_clf, param_grid9, cv=5, verbose=5, n_jobs=-1)\n",
    "grid9.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 904,\n",
       " 'min_samples_split': 10,\n",
       " 'max_depth': 17,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model_5 = grid9.best_params_\n",
    "best_rf_model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 904building tree 2 of 904building tree 3 of 904building tree 4 of 904\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 904\n",
      "building tree 6 of 904\n",
      "building tree 7 of 904\n",
      "building tree 8 of 904\n",
      "building tree 9 of 904\n",
      "building tree 10 of 904\n",
      "building tree 11 of 904\n",
      "building tree 12 of 904\n",
      "building tree 13 of 904building tree 14 of 904\n",
      "\n",
      "building tree 15 of 904\n",
      "building tree 16 of 904\n",
      "building tree 17 of 904\n",
      "building tree 18 of 904\n",
      "building tree 19 of 904building tree 20 of 904\n",
      "\n",
      "building tree 21 of 904\n",
      "building tree 22 of 904\n",
      "building tree 23 of 904\n",
      "building tree 24 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 904\n",
      "building tree 26 of 904\n",
      "building tree 27 of 904\n",
      "building tree 28 of 904\n",
      "building tree 29 of 904\n",
      "building tree 30 of 904\n",
      "building tree 31 of 904\n",
      "building tree 32 of 904\n",
      "building tree 33 of 904\n",
      "building tree 34 of 904\n",
      "building tree 35 of 904\n",
      "building tree 36 of 904\n",
      "building tree 37 of 904\n",
      "building tree 38 of 904\n",
      "building tree 39 of 904\n",
      "building tree 40 of 904\n",
      "building tree 41 of 904\n",
      "building tree 42 of 904\n",
      "building tree 43 of 904\n",
      "building tree 44 of 904\n",
      "building tree 45 of 904\n",
      "building tree 46 of 904\n",
      "building tree 47 of 904\n",
      "building tree 48 of 904\n",
      "building tree 49 of 904\n",
      "building tree 50 of 904building tree 51 of 904\n",
      "\n",
      "building tree 52 of 904\n",
      "building tree 53 of 904\n",
      "building tree 54 of 904\n",
      "building tree 55 of 904\n",
      "building tree 56 of 904\n",
      "building tree 57 of 904\n",
      "building tree 58 of 904\n",
      "building tree 59 of 904\n",
      "building tree 60 of 904\n",
      "building tree 61 of 904\n",
      "building tree 62 of 904\n",
      "building tree 63 of 904building tree 64 of 904\n",
      "\n",
      "building tree 65 of 904\n",
      "building tree 66 of 904\n",
      "building tree 67 of 904\n",
      "building tree 68 of 904\n",
      "building tree 69 of 904\n",
      "building tree 70 of 904\n",
      "building tree 71 of 904\n",
      "building tree 72 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 73 of 904\n",
      "building tree 74 of 904\n",
      "building tree 75 of 904\n",
      "building tree 76 of 904\n",
      "building tree 77 of 904\n",
      "building tree 78 of 904\n",
      "building tree 79 of 904\n",
      "building tree 80 of 904\n",
      "building tree 81 of 904\n",
      "building tree 82 of 904\n",
      "building tree 83 of 904building tree 84 of 904\n",
      "\n",
      "building tree 85 of 904\n",
      "building tree 86 of 904\n",
      "building tree 87 of 904\n",
      "building tree 88 of 904\n",
      "building tree 89 of 904\n",
      "building tree 90 of 904\n",
      "building tree 91 of 904\n",
      "building tree 92 of 904\n",
      "building tree 93 of 904\n",
      "building tree 94 of 904\n",
      "building tree 95 of 904\n",
      "building tree 96 of 904\n",
      "building tree 97 of 904\n",
      "building tree 98 of 904\n",
      "building tree 99 of 904\n",
      "building tree 100 of 904\n",
      "building tree 101 of 904\n",
      "building tree 102 of 904building tree 103 of 904\n",
      "\n",
      "building tree 104 of 904\n",
      "building tree 105 of 904\n",
      "building tree 106 of 904\n",
      "building tree 107 of 904\n",
      "building tree 108 of 904\n",
      "building tree 109 of 904\n",
      "building tree 110 of 904\n",
      "building tree 111 of 904\n",
      "building tree 112 of 904\n",
      "building tree 113 of 904\n",
      "building tree 114 of 904\n",
      "building tree 115 of 904\n",
      "building tree 116 of 904\n",
      "building tree 117 of 904\n",
      "building tree 118 of 904\n",
      "building tree 119 of 904building tree 120 of 904\n",
      "\n",
      "building tree 121 of 904\n",
      "building tree 122 of 904building tree 123 of 904building tree 124 of 904\n",
      "\n",
      "\n",
      "building tree 125 of 904\n",
      "building tree 126 of 904\n",
      "building tree 127 of 904\n",
      "building tree 128 of 904\n",
      "building tree 129 of 904\n",
      "building tree 130 of 904building tree 131 of 904\n",
      "\n",
      "building tree 132 of 904\n",
      "building tree 133 of 904\n",
      "building tree 134 of 904\n",
      "building tree 135 of 904building tree 136 of 904\n",
      "\n",
      "building tree 137 of 904\n",
      "building tree 138 of 904\n",
      "building tree 139 of 904\n",
      "building tree 140 of 904\n",
      "building tree 141 of 904\n",
      "building tree 142 of 904\n",
      "building tree 143 of 904\n",
      "building tree 144 of 904\n",
      "building tree 145 of 904\n",
      "building tree 146 of 904\n",
      "building tree 147 of 904\n",
      "building tree 148 of 904\n",
      "building tree 149 of 904\n",
      "building tree 150 of 904\n",
      "building tree 151 of 904\n",
      "building tree 152 of 904\n",
      "building tree 153 of 904\n",
      "building tree 154 of 904\n",
      "building tree 155 of 904\n",
      "building tree 156 of 904\n",
      "building tree 157 of 904\n",
      "building tree 158 of 904\n",
      "building tree 159 of 904\n",
      "building tree 160 of 904\n",
      "building tree 161 of 904\n",
      "building tree 162 of 904\n",
      "building tree 163 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 164 of 904\n",
      "building tree 165 of 904\n",
      "building tree 166 of 904\n",
      "building tree 167 of 904\n",
      "building tree 168 of 904\n",
      "building tree 169 of 904\n",
      "building tree 170 of 904\n",
      "building tree 171 of 904\n",
      "building tree 172 of 904\n",
      "building tree 173 of 904\n",
      "building tree 174 of 904\n",
      "building tree 175 of 904\n",
      "building tree 176 of 904building tree 177 of 904\n",
      "\n",
      "building tree 178 of 904\n",
      "building tree 179 of 904\n",
      "building tree 180 of 904\n",
      "building tree 181 of 904\n",
      "building tree 182 of 904\n",
      "building tree 183 of 904\n",
      "building tree 184 of 904building tree 185 of 904\n",
      "\n",
      "building tree 186 of 904\n",
      "building tree 187 of 904\n",
      "building tree 188 of 904\n",
      "building tree 189 of 904building tree 190 of 904building tree 191 of 904\n",
      "\n",
      "\n",
      "building tree 192 of 904\n",
      "building tree 193 of 904\n",
      "building tree 194 of 904\n",
      "building tree 195 of 904\n",
      "building tree 196 of 904\n",
      "building tree 197 of 904\n",
      "building tree 198 of 904\n",
      "building tree 199 of 904\n",
      "building tree 200 of 904\n",
      "building tree 201 of 904\n",
      "building tree 202 of 904\n",
      "building tree 203 of 904\n",
      "building tree 204 of 904\n",
      "building tree 205 of 904\n",
      "building tree 206 of 904\n",
      "building tree 207 of 904\n",
      "building tree 208 of 904\n",
      "building tree 209 of 904\n",
      "building tree 210 of 904\n",
      "building tree 211 of 904\n",
      "building tree 212 of 904\n",
      "building tree 213 of 904\n",
      "building tree 214 of 904\n",
      "building tree 215 of 904\n",
      "building tree 216 of 904\n",
      "building tree 217 of 904\n",
      "building tree 218 of 904\n",
      "building tree 219 of 904\n",
      "building tree 220 of 904\n",
      "building tree 221 of 904\n",
      "building tree 222 of 904\n",
      "building tree 223 of 904\n",
      "building tree 224 of 904building tree 225 of 904\n",
      "\n",
      "building tree 226 of 904\n",
      "building tree 227 of 904\n",
      "building tree 228 of 904\n",
      "building tree 229 of 904\n",
      "building tree 230 of 904\n",
      "building tree 231 of 904\n",
      "building tree 232 of 904\n",
      "building tree 233 of 904\n",
      "building tree 234 of 904\n",
      "building tree 235 of 904\n",
      "building tree 236 of 904\n",
      "building tree 237 of 904\n",
      "building tree 238 of 904\n",
      "building tree 239 of 904\n",
      "building tree 240 of 904\n",
      "building tree 241 of 904\n",
      "building tree 242 of 904\n",
      "building tree 243 of 904\n",
      "building tree 244 of 904\n",
      "building tree 245 of 904\n",
      "building tree 246 of 904\n",
      "building tree 247 of 904\n",
      "building tree 248 of 904\n",
      "building tree 249 of 904building tree 250 of 904\n",
      "\n",
      "building tree 251 of 904\n",
      "building tree 252 of 904\n",
      "building tree 253 of 904\n",
      "building tree 254 of 904\n",
      "building tree 255 of 904\n",
      "building tree 256 of 904\n",
      "building tree 257 of 904\n",
      "building tree 258 of 904\n",
      "building tree 259 of 904\n",
      "building tree 260 of 904\n",
      "building tree 261 of 904\n",
      "building tree 262 of 904\n",
      "building tree 263 of 904\n",
      "building tree 264 of 904building tree 265 of 904\n",
      "\n",
      "building tree 266 of 904\n",
      "building tree 267 of 904\n",
      "building tree 268 of 904\n",
      "building tree 269 of 904building tree 270 of 904\n",
      "\n",
      "building tree 271 of 904\n",
      "building tree 272 of 904\n",
      "building tree 273 of 904\n",
      "building tree 274 of 904\n",
      "building tree 275 of 904\n",
      "building tree 276 of 904\n",
      "building tree 277 of 904\n",
      "building tree 278 of 904\n",
      "building tree 279 of 904\n",
      "building tree 280 of 904\n",
      "building tree 281 of 904\n",
      "building tree 282 of 904\n",
      "building tree 283 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 284 of 904\n",
      "building tree 285 of 904\n",
      "building tree 286 of 904\n",
      "building tree 287 of 904\n",
      "building tree 288 of 904\n",
      "building tree 289 of 904\n",
      "building tree 290 of 904\n",
      "building tree 291 of 904\n",
      "building tree 292 of 904building tree 293 of 904\n",
      "\n",
      "building tree 294 of 904\n",
      "building tree 295 of 904\n",
      "building tree 296 of 904\n",
      "building tree 297 of 904\n",
      "building tree 298 of 904\n",
      "building tree 299 of 904\n",
      "building tree 300 of 904\n",
      "building tree 301 of 904\n",
      "building tree 302 of 904\n",
      "building tree 303 of 904\n",
      "building tree 304 of 904\n",
      "building tree 305 of 904\n",
      "building tree 306 of 904\n",
      "building tree 307 of 904\n",
      "building tree 308 of 904\n",
      "building tree 309 of 904\n",
      "building tree 310 of 904\n",
      "building tree 311 of 904\n",
      "building tree 312 of 904\n",
      "building tree 313 of 904\n",
      "building tree 314 of 904\n",
      "building tree 315 of 904\n",
      "building tree 316 of 904building tree 317 of 904\n",
      "\n",
      "building tree 318 of 904\n",
      "building tree 319 of 904\n",
      "building tree 320 of 904\n",
      "building tree 321 of 904\n",
      "building tree 322 of 904\n",
      "building tree 323 of 904\n",
      "building tree 324 of 904\n",
      "building tree 325 of 904\n",
      "building tree 326 of 904\n",
      "building tree 327 of 904\n",
      "building tree 328 of 904\n",
      "building tree 329 of 904\n",
      "building tree 330 of 904\n",
      "building tree 331 of 904\n",
      "building tree 332 of 904\n",
      "building tree 333 of 904\n",
      "building tree 334 of 904\n",
      "building tree 335 of 904\n",
      "building tree 336 of 904\n",
      "building tree 337 of 904\n",
      "building tree 338 of 904\n",
      "building tree 339 of 904\n",
      "building tree 340 of 904\n",
      "building tree 341 of 904\n",
      "building tree 342 of 904\n",
      "building tree 343 of 904\n",
      "building tree 344 of 904\n",
      "building tree 345 of 904\n",
      "building tree 346 of 904\n",
      "building tree 347 of 904\n",
      "building tree 348 of 904\n",
      "building tree 349 of 904\n",
      "building tree 350 of 904\n",
      "building tree 351 of 904\n",
      "building tree 352 of 904\n",
      "building tree 353 of 904\n",
      "building tree 354 of 904\n",
      "building tree 355 of 904\n",
      "building tree 356 of 904\n",
      "building tree 357 of 904\n",
      "building tree 358 of 904\n",
      "building tree 359 of 904\n",
      "building tree 360 of 904\n",
      "building tree 361 of 904\n",
      "building tree 362 of 904building tree 363 of 904\n",
      "\n",
      "building tree 364 of 904\n",
      "building tree 365 of 904\n",
      "building tree 366 of 904\n",
      "building tree 367 of 904\n",
      "building tree 368 of 904\n",
      "building tree 369 of 904\n",
      "building tree 370 of 904\n",
      "building tree 371 of 904\n",
      "building tree 372 of 904\n",
      "building tree 373 of 904\n",
      "building tree 374 of 904\n",
      "building tree 375 of 904\n",
      "building tree 376 of 904\n",
      "building tree 377 of 904building tree 378 of 904\n",
      "\n",
      "building tree 379 of 904\n",
      "building tree 380 of 904\n",
      "building tree 381 of 904\n",
      "building tree 382 of 904\n",
      "building tree 383 of 904\n",
      "building tree 384 of 904\n",
      "building tree 385 of 904building tree 386 of 904\n",
      "\n",
      "building tree 387 of 904\n",
      "building tree 388 of 904\n",
      "building tree 389 of 904\n",
      "building tree 390 of 904\n",
      "building tree 391 of 904\n",
      "building tree 392 of 904\n",
      "building tree 393 of 904\n",
      "building tree 394 of 904\n",
      "building tree 395 of 904\n",
      "building tree 396 of 904\n",
      "building tree 397 of 904\n",
      "building tree 398 of 904\n",
      "building tree 399 of 904\n",
      "building tree 400 of 904\n",
      "building tree 401 of 904\n",
      "building tree 402 of 904\n",
      "building tree 403 of 904\n",
      "building tree 404 of 904\n",
      "building tree 405 of 904\n",
      "building tree 406 of 904\n",
      "building tree 407 of 904\n",
      "building tree 408 of 904\n",
      "building tree 409 of 904\n",
      "building tree 410 of 904building tree 411 of 904\n",
      "\n",
      "building tree 412 of 904\n",
      "building tree 413 of 904\n",
      "building tree 414 of 904\n",
      "building tree 415 of 904\n",
      "building tree 416 of 904\n",
      "building tree 417 of 904\n",
      "building tree 418 of 904\n",
      "building tree 419 of 904\n",
      "building tree 420 of 904\n",
      "building tree 421 of 904\n",
      "building tree 422 of 904\n",
      "building tree 423 of 904\n",
      "building tree 424 of 904\n",
      "building tree 425 of 904\n",
      "building tree 426 of 904\n",
      "building tree 427 of 904building tree 428 of 904\n",
      "\n",
      "building tree 429 of 904\n",
      "building tree 430 of 904\n",
      "building tree 431 of 904\n",
      "building tree 432 of 904\n",
      "building tree 433 of 904\n",
      "building tree 434 of 904\n",
      "building tree 435 of 904\n",
      "building tree 436 of 904\n",
      "building tree 437 of 904\n",
      "building tree 438 of 904\n",
      "building tree 439 of 904building tree 440 of 904\n",
      "\n",
      "building tree 441 of 904\n",
      "building tree 442 of 904\n",
      "building tree 443 of 904\n",
      "building tree 444 of 904\n",
      "building tree 445 of 904\n",
      "building tree 446 of 904\n",
      "building tree 447 of 904\n",
      "building tree 448 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 449 of 904\n",
      "building tree 450 of 904\n",
      "building tree 451 of 904\n",
      "building tree 452 of 904\n",
      "building tree 453 of 904\n",
      "building tree 454 of 904\n",
      "building tree 455 of 904\n",
      "building tree 456 of 904building tree 457 of 904\n",
      "\n",
      "building tree 458 of 904\n",
      "building tree 459 of 904\n",
      "building tree 460 of 904\n",
      "building tree 461 of 904\n",
      "building tree 462 of 904\n",
      "building tree 463 of 904\n",
      "building tree 464 of 904\n",
      "building tree 465 of 904\n",
      "building tree 466 of 904\n",
      "building tree 467 of 904\n",
      "building tree 468 of 904\n",
      "building tree 469 of 904\n",
      "building tree 470 of 904building tree 471 of 904\n",
      "\n",
      "building tree 472 of 904\n",
      "building tree 473 of 904\n",
      "building tree 474 of 904\n",
      "building tree 475 of 904\n",
      "building tree 476 of 904\n",
      "building tree 477 of 904\n",
      "building tree 478 of 904\n",
      "building tree 479 of 904\n",
      "building tree 480 of 904\n",
      "building tree 481 of 904\n",
      "building tree 482 of 904\n",
      "building tree 483 of 904\n",
      "building tree 484 of 904\n",
      "building tree 485 of 904\n",
      "building tree 486 of 904\n",
      "building tree 487 of 904\n",
      "building tree 488 of 904\n",
      "building tree 489 of 904\n",
      "building tree 490 of 904\n",
      "building tree 491 of 904\n",
      "building tree 492 of 904\n",
      "building tree 493 of 904\n",
      "building tree 494 of 904\n",
      "building tree 495 of 904\n",
      "building tree 496 of 904\n",
      "building tree 497 of 904\n",
      "building tree 498 of 904\n",
      "building tree 499 of 904\n",
      "building tree 500 of 904\n",
      "building tree 501 of 904\n",
      "building tree 502 of 904\n",
      "building tree 503 of 904\n",
      "building tree 504 of 904\n",
      "building tree 505 of 904\n",
      "building tree 506 of 904\n",
      "building tree 507 of 904\n",
      "building tree 508 of 904\n",
      "building tree 509 of 904\n",
      "building tree 510 of 904\n",
      "building tree 511 of 904\n",
      "building tree 512 of 904\n",
      "building tree 513 of 904\n",
      "building tree 514 of 904\n",
      "building tree 515 of 904\n",
      "building tree 516 of 904\n",
      "building tree 517 of 904\n",
      "building tree 518 of 904\n",
      "building tree 519 of 904\n",
      "building tree 520 of 904\n",
      "building tree 521 of 904\n",
      "building tree 522 of 904\n",
      "building tree 523 of 904\n",
      "building tree 524 of 904\n",
      "building tree 525 of 904\n",
      "building tree 526 of 904\n",
      "building tree 527 of 904\n",
      "building tree 528 of 904\n",
      "building tree 529 of 904\n",
      "building tree 530 of 904\n",
      "building tree 531 of 904\n",
      "building tree 532 of 904\n",
      "building tree 533 of 904\n",
      "building tree 534 of 904\n",
      "building tree 535 of 904\n",
      "building tree 536 of 904\n",
      "building tree 537 of 904\n",
      "building tree 538 of 904\n",
      "building tree 539 of 904\n",
      "building tree 540 of 904\n",
      "building tree 541 of 904\n",
      "building tree 542 of 904\n",
      "building tree 543 of 904\n",
      "building tree 544 of 904\n",
      "building tree 545 of 904\n",
      "building tree 546 of 904\n",
      "building tree 547 of 904\n",
      "building tree 548 of 904\n",
      "building tree 549 of 904\n",
      "building tree 550 of 904\n",
      "building tree 551 of 904\n",
      "building tree 552 of 904\n",
      "building tree 553 of 904\n",
      "building tree 554 of 904\n",
      "building tree 555 of 904building tree 556 of 904\n",
      "\n",
      "building tree 557 of 904\n",
      "building tree 558 of 904\n",
      "building tree 559 of 904\n",
      "building tree 560 of 904\n",
      "building tree 561 of 904\n",
      "building tree 562 of 904\n",
      "building tree 563 of 904\n",
      "building tree 564 of 904\n",
      "building tree 565 of 904\n",
      "building tree 566 of 904\n",
      "building tree 567 of 904\n",
      "building tree 568 of 904\n",
      "building tree 569 of 904\n",
      "building tree 570 of 904\n",
      "building tree 571 of 904\n",
      "building tree 572 of 904\n",
      "building tree 573 of 904\n",
      "building tree 574 of 904\n",
      "building tree 575 of 904\n",
      "building tree 576 of 904\n",
      "building tree 577 of 904\n",
      "building tree 578 of 904\n",
      "building tree 579 of 904\n",
      "building tree 580 of 904\n",
      "building tree 581 of 904\n",
      "building tree 582 of 904\n",
      "building tree 583 of 904\n",
      "building tree 584 of 904\n",
      "building tree 585 of 904\n",
      "building tree 586 of 904\n",
      "building tree 587 of 904building tree 588 of 904\n",
      "\n",
      "building tree 589 of 904\n",
      "building tree 590 of 904\n",
      "building tree 591 of 904\n",
      "building tree 592 of 904\n",
      "building tree 593 of 904\n",
      "building tree 594 of 904\n",
      "building tree 595 of 904\n",
      "building tree 596 of 904\n",
      "building tree 597 of 904\n",
      "building tree 598 of 904\n",
      "building tree 599 of 904\n",
      "building tree 600 of 904\n",
      "building tree 601 of 904\n",
      "building tree 602 of 904\n",
      "building tree 603 of 904\n",
      "building tree 604 of 904\n",
      "building tree 605 of 904\n",
      "building tree 606 of 904\n",
      "building tree 607 of 904\n",
      "building tree 608 of 904\n",
      "building tree 609 of 904\n",
      "building tree 610 of 904\n",
      "building tree 611 of 904\n",
      "building tree 612 of 904\n",
      "building tree 613 of 904\n",
      "building tree 614 of 904\n",
      "building tree 615 of 904\n",
      "building tree 616 of 904\n",
      "building tree 617 of 904\n",
      "building tree 618 of 904\n",
      "building tree 619 of 904\n",
      "building tree 620 of 904\n",
      "building tree 621 of 904\n",
      "building tree 622 of 904\n",
      "building tree 623 of 904\n",
      "building tree 624 of 904\n",
      "building tree 625 of 904\n",
      "building tree 626 of 904\n",
      "building tree 627 of 904\n",
      "building tree 628 of 904\n",
      "building tree 629 of 904\n",
      "building tree 630 of 904\n",
      "building tree 631 of 904building tree 632 of 904\n",
      "\n",
      "building tree 633 of 904\n",
      "building tree 634 of 904\n",
      "building tree 635 of 904\n",
      "building tree 636 of 904\n",
      "building tree 637 of 904\n",
      "building tree 638 of 904\n",
      "building tree 639 of 904\n",
      "building tree 640 of 904\n",
      "building tree 641 of 904\n",
      "building tree 642 of 904\n",
      "building tree 643 of 904\n",
      "building tree 644 of 904\n",
      "building tree 645 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   12.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 646 of 904\n",
      "building tree 647 of 904\n",
      "building tree 648 of 904\n",
      "building tree 649 of 904\n",
      "building tree 650 of 904\n",
      "building tree 651 of 904\n",
      "building tree 652 of 904\n",
      "building tree 653 of 904\n",
      "building tree 654 of 904\n",
      "building tree 655 of 904\n",
      "building tree 656 of 904\n",
      "building tree 657 of 904\n",
      "building tree 658 of 904\n",
      "building tree 659 of 904\n",
      "building tree 660 of 904\n",
      "building tree 661 of 904\n",
      "building tree 662 of 904\n",
      "building tree 663 of 904\n",
      "building tree 664 of 904\n",
      "building tree 665 of 904\n",
      "building tree 666 of 904\n",
      "building tree 667 of 904\n",
      "building tree 668 of 904\n",
      "building tree 669 of 904\n",
      "building tree 670 of 904\n",
      "building tree 671 of 904\n",
      "building tree 672 of 904\n",
      "building tree 673 of 904\n",
      "building tree 674 of 904\n",
      "building tree 675 of 904\n",
      "building tree 676 of 904\n",
      "building tree 677 of 904\n",
      "building tree 678 of 904\n",
      "building tree 679 of 904\n",
      "building tree 680 of 904\n",
      "building tree 681 of 904\n",
      "building tree 682 of 904\n",
      "building tree 683 of 904\n",
      "building tree 684 of 904\n",
      "building tree 685 of 904\n",
      "building tree 686 of 904\n",
      "building tree 687 of 904\n",
      "building tree 688 of 904\n",
      "building tree 689 of 904\n",
      "building tree 690 of 904\n",
      "building tree 691 of 904\n",
      "building tree 692 of 904building tree 693 of 904\n",
      "\n",
      "building tree 694 of 904\n",
      "building tree 695 of 904\n",
      "building tree 696 of 904\n",
      "building tree 697 of 904\n",
      "building tree 698 of 904\n",
      "building tree 699 of 904building tree 700 of 904\n",
      "\n",
      "building tree 701 of 904\n",
      "building tree 702 of 904\n",
      "building tree 703 of 904\n",
      "building tree 704 of 904\n",
      "building tree 705 of 904\n",
      "building tree 706 of 904\n",
      "building tree 707 of 904\n",
      "building tree 708 of 904\n",
      "building tree 709 of 904\n",
      "building tree 710 of 904\n",
      "building tree 711 of 904\n",
      "building tree 712 of 904\n",
      "building tree 713 of 904\n",
      "building tree 714 of 904\n",
      "building tree 715 of 904\n",
      "building tree 716 of 904\n",
      "building tree 717 of 904\n",
      "building tree 718 of 904\n",
      "building tree 719 of 904\n",
      "building tree 720 of 904\n",
      "building tree 721 of 904\n",
      "building tree 722 of 904\n",
      "building tree 723 of 904\n",
      "building tree 724 of 904\n",
      "building tree 725 of 904\n",
      "building tree 726 of 904\n",
      "building tree 727 of 904\n",
      "building tree 728 of 904\n",
      "building tree 729 of 904\n",
      "building tree 730 of 904\n",
      "building tree 731 of 904\n",
      "building tree 732 of 904\n",
      "building tree 733 of 904\n",
      "building tree 734 of 904\n",
      "building tree 735 of 904\n",
      "building tree 736 of 904\n",
      "building tree 737 of 904\n",
      "building tree 738 of 904\n",
      "building tree 739 of 904\n",
      "building tree 740 of 904\n",
      "building tree 741 of 904\n",
      "building tree 742 of 904\n",
      "building tree 743 of 904\n",
      "building tree 744 of 904\n",
      "building tree 745 of 904\n",
      "building tree 746 of 904\n",
      "building tree 747 of 904\n",
      "building tree 748 of 904\n",
      "building tree 749 of 904\n",
      "building tree 750 of 904\n",
      "building tree 751 of 904\n",
      "building tree 752 of 904\n",
      "building tree 753 of 904\n",
      "building tree 754 of 904\n",
      "building tree 755 of 904\n",
      "building tree 756 of 904building tree 757 of 904\n",
      "\n",
      "building tree 758 of 904\n",
      "building tree 759 of 904\n",
      "building tree 760 of 904\n",
      "building tree 761 of 904\n",
      "building tree 762 of 904\n",
      "building tree 763 of 904\n",
      "building tree 764 of 904\n",
      "building tree 765 of 904\n",
      "building tree 766 of 904\n",
      "building tree 767 of 904\n",
      "building tree 768 of 904\n",
      "building tree 769 of 904\n",
      "building tree 770 of 904\n",
      "building tree 771 of 904\n",
      "building tree 772 of 904\n",
      "building tree 773 of 904building tree 774 of 904\n",
      "\n",
      "building tree 775 of 904\n",
      "building tree 776 of 904\n",
      "building tree 777 of 904building tree 778 of 904\n",
      "\n",
      "building tree 779 of 904\n",
      "building tree 780 of 904\n",
      "building tree 781 of 904\n",
      "building tree 782 of 904\n",
      "building tree 783 of 904\n",
      "building tree 784 of 904\n",
      "building tree 785 of 904\n",
      "building tree 786 of 904\n",
      "building tree 787 of 904\n",
      "building tree 788 of 904\n",
      "building tree 789 of 904\n",
      "building tree 790 of 904\n",
      "building tree 791 of 904\n",
      "building tree 792 of 904\n",
      "building tree 793 of 904\n",
      "building tree 794 of 904\n",
      "building tree 795 of 904\n",
      "building tree 796 of 904\n",
      "building tree 797 of 904\n",
      "building tree 798 of 904\n",
      "building tree 799 of 904\n",
      "building tree 800 of 904\n",
      "building tree 801 of 904\n",
      "building tree 802 of 904\n",
      "building tree 803 of 904\n",
      "building tree 804 of 904\n",
      "building tree 805 of 904\n",
      "building tree 806 of 904\n",
      "building tree 807 of 904\n",
      "building tree 808 of 904\n",
      "building tree 809 of 904\n",
      "building tree 810 of 904\n",
      "building tree 811 of 904\n",
      "building tree 812 of 904\n",
      "building tree 813 of 904\n",
      "building tree 814 of 904\n",
      "building tree 815 of 904\n",
      "building tree 816 of 904building tree 817 of 904\n",
      "\n",
      "building tree 818 of 904\n",
      "building tree 819 of 904\n",
      "building tree 820 of 904\n",
      "building tree 821 of 904\n",
      "building tree 822 of 904\n",
      "building tree 823 of 904\n",
      "building tree 824 of 904\n",
      "building tree 825 of 904\n",
      "building tree 826 of 904\n",
      "building tree 827 of 904\n",
      "building tree 828 of 904\n",
      "building tree 829 of 904\n",
      "building tree 830 of 904\n",
      "building tree 831 of 904\n",
      "building tree 832 of 904\n",
      "building tree 833 of 904\n",
      "building tree 834 of 904\n",
      "building tree 835 of 904\n",
      "building tree 836 of 904\n",
      "building tree 837 of 904\n",
      "building tree 838 of 904\n",
      "building tree 839 of 904\n",
      "building tree 840 of 904\n",
      "building tree 841 of 904\n",
      "building tree 842 of 904\n",
      "building tree 843 of 904\n",
      "building tree 844 of 904\n",
      "building tree 845 of 904\n",
      "building tree 846 of 904\n",
      "building tree 847 of 904\n",
      "building tree 848 of 904\n",
      "building tree 849 of 904\n",
      "building tree 850 of 904\n",
      "building tree 851 of 904\n",
      "building tree 852 of 904\n",
      "building tree 853 of 904\n",
      "building tree 854 of 904\n",
      "building tree 855 of 904\n",
      "building tree 856 of 904building tree 857 of 904\n",
      "\n",
      "building tree 858 of 904\n",
      "building tree 859 of 904\n",
      "building tree 860 of 904\n",
      "building tree 861 of 904\n",
      "building tree 862 of 904\n",
      "building tree 863 of 904\n",
      "building tree 864 of 904\n",
      "building tree 865 of 904\n",
      "building tree 866 of 904\n",
      "building tree 867 of 904\n",
      "building tree 868 of 904\n",
      "building tree 869 of 904\n",
      "building tree 870 of 904\n",
      "building tree 871 of 904\n",
      "building tree 872 of 904\n",
      "building tree 873 of 904\n",
      "building tree 874 of 904\n",
      "building tree 875 of 904\n",
      "building tree 876 of 904\n",
      "building tree 877 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:   16.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 878 of 904\n",
      "building tree 879 of 904\n",
      "building tree 880 of 904\n",
      "building tree 881 of 904\n",
      "building tree 882 of 904\n",
      "building tree 883 of 904\n",
      "building tree 884 of 904\n",
      "building tree 885 of 904\n",
      "building tree 886 of 904\n",
      "building tree 887 of 904\n",
      "building tree 888 of 904\n",
      "building tree 889 of 904\n",
      "building tree 890 of 904\n",
      "building tree 891 of 904\n",
      "building tree 892 of 904\n",
      "building tree 893 of 904\n",
      "building tree 894 of 904\n",
      "building tree 895 of 904\n",
      "building tree 896 of 904\n",
      "building tree 897 of 904\n",
      "building tree 898 of 904\n",
      "building tree 899 of 904\n",
      "building tree 900 of 904\n",
      "building tree 901 of 904\n",
      "building tree 902 of 904\n",
      "building tree 903 of 904\n",
      "building tree 904 of 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 904 out of 904 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 904 out of 904 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "best_rf_model_5 = RandomForestClassifier(n_jobs = -1, random_state = 8, verbose = 5, bootstrap = True, n_estimators = 904,\n",
    "                                         min_samples_split = 10, max_depth = 17, criterion = 'gini',\n",
    "                                         class_weight =  {0: 0.2, 1: 0.8})\n",
    "best_rf_model_5.fit(X_smo_5, y_smo);\n",
    "ye_pred9 = best_rf_model_5.predict(X_test_5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcuklEQVR4nO3deXxU9b3/8dcnISwKEZDFGKgihbZAFTekrQsqCqIVuFVJ7VW02Hgt1q11QeuGYmkVbamCP/xJgVZFbl1ABCuiuLQIoqJsoikihARCVQS8NZKZz/1jjrkDDJMJDMzJ8f308X3kzOd8z6b4yYfv+Z4z5u6IiEi45OX6BEREZGdKziIiIaTkLCISQkrOIiIhpOQsIhJCjfb6ARoXazqI7OSYNl1yfQoSQq9XzLM93ce2f63KOOcUtDlsj4+3t6hyFhEJob1eOYuI7FPxWK7PICuUnEUkWmI1uT6DrFByFpFIcY/n+hSyQslZRKIlruQsIhI+EamcNVtDRKIlHsu8pWFmTc1soZm9Y2bLzOz2IH6bma0zs8VBG5C0zQgzKzOzlWbWLyl+tJktCdaNNbM6p/CpchaRaMle5VwNnOLuW82sAHjNzGYH6+5z93uSO5tZN6AE6A4cDLxgZl3dPQaMB0qB14FZQH9gNmkoOYtIpHiWZmt44n3KW4OPBUFL94DLQGCqu1cDH5pZGdDLzFYDhe4+H8DMpgCDqCM5a1hDRKIlHs+4mVmpmS1KaqXJuzKzfDNbDFQBc9x9QbDqcjN718wmmlmrIFYMrE3avDyIFQfLO8bTUnIWkWjxeMbN3Se4+zFJbcJ2u3KPuXtPoAOJKrgHiSGKzkBPoBIYE3RPNY7saeJpKTmLSLRk6YZgMnffBMwD+rv7hiBpx4GHgF5Bt3KgY9JmHYCKIN4hRTwtJWcRiZZ6VM7pmFlbM2sZLDcD+gLvmVlRUrfBwNJgeQZQYmZNzKwT0AVY6O6VwBYz6x3M0rgQmF7XZeiGoIhES/Ye3y4CJptZPolCdpq7zzSzP5tZTxJDE6uBSwHcfZmZTQOWAzXA8GCmBsBlwCSgGYkbgWlvBoKSs4hETZaeEHT3d4EjU8QvSLPNKGBUivgioEd9jq/kLCKR8n/FasOm5Cwi0RKRx7eVnEUkWvTiIxGREFLlLCISQrFtuT6DrFByFpFo0bCGiEgIaVhDRCSEVDmLiISQkrOISPi4bgiKiISQxpxFREJIwxoiIiGkyllEJIRUOYuIhJAqZxGREKrJ2sv2c0rJWUSiRZWziEgIacxZRCSEVDmLiISQKmcRkRCKSOWcl+sTEBHJqpqazFsaZtbUzBaa2TtmtszMbg/irc1sjpl9EPxslbTNCDMrM7OVZtYvKX60mS0J1o01M6vrMpScRSRa3DNv6VUDp7j7EUBPoL+Z9QZuAOa6exdgbvAZM+sGlADdgf7AODPLD/Y1HigFugStf10HV3IWkWiJxzNvaXjC1uBjQdAcGAhMDuKTgUHB8kBgqrtXu/uHQBnQy8yKgEJ3n+/uDkxJ2maXlJxFJFqylJwBzCzfzBYDVcAcd18AtHf3SoDgZ7ugezGwNmnz8iBWHCzvGE9LyVlEosXjGTczKzWzRUmtdLtducfcvSfQgUQV3CPNkVONI3uaeFqarSEi0RKLZdzV3ScAEzLot8nM5pEYK95gZkXuXhkMWVQF3cqBjkmbdQAqgniHFPG0VDmLSLRkaVjDzNqaWctguRnQF3gPmAEMDboNBaYHyzOAEjNrYmadSNz4WxgMfWwxs97BLI0Lk7bZJVXOIhIt2XsIpQiYHMy4yAOmuftMM5sPTDOzYcAa4FwAd19mZtOA5UANMNzdvyrjLwMmAc2A2UFLS8lZRKIlSw+huPu7wJEp4h8Dp+5im1HAqBTxRUC68eqdKDmLSKR4vM57bQ2CkrOIRIverSEiEkL1mK0RZkrOIhItqpxFREJIyVnS6dq1M48+Mr7282GdvsFtt99D795H07VrZwBaHlDIps82c8yxp+fqNCVLmhc258Z7ruWwb3cCd+685rcsfXP5bu9vwLn9uPjKCwD40x/+zKz//hsAt99/E98+4lvUbIuxfPEKRl83hlhNNP4anzV1v9CoQVBy3kvef/+ftUk3Ly+PNavf5Onpsxn7x/9f2+fu397CZ5s35+oUJYuuHnk5r89byI2lt9KooBFNmzXNaLtxf/09d1w1msry9bWxwpYtGHbNUC4+41LcnUnPTeDV5//Ols+28tyTL3Dr5YmZWiPH3czA88/kySkz9so1NVhfl8rZzL5N4m1LxSSeB68AZrj7ir18bpFx6inHs2rVR6xZs267+Dnn/JDT+p2Xo7OSbNmv+X4c2fsI7rhqNAA122rYum0rxYcczK/uuopWBx7AF/+u5jfX3sNHZWvq3N9xfY5l4SuL2LxpCwALX1lE75N7MefpF5n/4oLafsvfXkG7orZ756IasohMpUv7+LaZXQ9MJfHijoXAG8HyY2Z2w94/vWg477yBTH386e1iJxx/HBuqNlJW9mFuTkqypviQg/n0403cfN8NTH7+IW6851qaNmvKDb/7Jff++g9c1P9S/jhyPNfedVVG+2t7UFuqKjbWfq6q3Ejbg7ZPwvmN8jnjnNOZ/9LCbF5KNMRimbcQq6tyHgZ0d/dtyUEzuxdYBoxOtVHwZqdSAMs/gLy8/bNwqg1TQUEBPzzrdG769W+2iw8ZMojHH6/z8XppAPLz8/nWd7ty76/HsuztFVw98nIuvX4Y3z2mB6Mm3F7br3HjAgDOHNKfIZecA0CHQ4u59y+j2bathoo1ldww7GZSfkfGDuOo1/3mat5+/V3eWbhkr11XQ+Vfk2GNOHAw8NEO8aJgXUrJb3pq1Lg4Gn/H2E39+5/M228voarqX7Wx/Px8Bg86g169z8jhmUm2VFVuZGPlRpa9nRjpe3Hmy5Re+1O2bt7KhaddslP/Zx9/jmcffw5IPeZcVbmRo77Xs/Zzu6K2vDV/ce3nYdcMpeWBLRl93c1754Iauq/DsAZwFTDXzGab2YSgPUfiq1mu3OtnFwElQwbtNKTR99QTWLmyjHXrKnNzUpJVn2z8hA0VVXyjc+JtkceecDQr3l1JxdpKTjnrpNp+3+zWOaP9LZj3BseddCwtDmhOiwOac9xJx7Jg3hsAnH3+mRzX51hu+flIPCKzErKuHu9zDrO0lbO7P2dmXYFeJG4IGol3k76R9LYl2YVmzZrS99QTuezn128XT4xBa0gjSsb8eiy33/9rCgoasW5NJXdePZrmhc25bvQ1XHzlBTQqaMSc6S9Stvyfde5r86YtTPz9FCbO+n8APHzf5Nqbg9eNvob15et56JlxAMyb9QoT75uy9y6sIYpI5Wx7+7fv131YQ1I7pk2XXJ+ChNDrFfPq/Fbqunx+S0nGOWf/kVP3+Hh7i+Y5i0i0hHy4IlNKziISLREZ1lByFpFI+bpMpRMRaVhUOYuIhJCSs4hICIX8sexMKTmLSKToOwRFRMIoIsm5rse3RUQalng885aGmXU0s5fMbIWZLTOzK4P4bWa2zswWB21A0jYjzKzMzFaaWb+k+NFmtiRYN9Ys5euttqPKWUSiJXuVcw3wS3d/y8xaAG+a2Zxg3X3ufk9yZzPrBpQA3Um8MO4FM+savOpiPIk3db4OzAL6A7PTHVyVs4hES9wzb2m4e6W7vxUsbwFWkHjH0K4MBKa6e7W7fwiUAb3MrAgodPf5nnhfxhRgUF2XoeQsIpHisXjGzcxKzWxRUitNtU8zOxQ4Evjqq2guN7N3zWyimbUKYsXA2qTNyoNYcbC8YzwtJWcRiZZ6VM7uPsHdj0lqE3bcnZk1B54ArnL3zSSGKDoDPYFKYMxXXVOcjaeJp6UxZxGJlGxOpTOzAhKJ+RF3fxLA3TckrX8ImBl8LAc6Jm3egcR3rpYHyzvG01LlLCLRkqUx52BGxcPACne/NylelNRtMLA0WJ4BlJhZEzPrBHQBFrp7JbDFzHoH+7wQqPOF7qqcRSRasvfeox8AFwBLzGxxELsR+LGZ9SQxNLEauBTA3ZeZ2TRgOYmZHsOTvpTkMmAS0IzELI20MzVAyVlEIsZrspOd3f01Uo8Xz0qzzShgVIr4IqBHfY6v5Cwi0RKNN4YqOYtItOjdGiIiYaTKWUQkfFQ5i4iEkSpnEZHw8Zpcn0F2KDmLSKS4KmcRkRBSchYRCR9VziIiIaTkLCISQh6r8xugGgQlZxGJFFXOIiIh5HFVziIioaPKWUQkhNxVOYuIhI4qZxGREIprtoaISPjohqCISAgpOYuIhJBH43XOSs4iEi1RqZzzcn0CIiLZ5G4Zt3TMrKOZvWRmK8xsmZldGcRbm9kcM/sg+NkqaZsRZlZmZivNrF9S/GgzWxKsG2tmdf4GUXIWkUiJxSzjVoca4Jfu/h2gNzDczLoBNwBz3b0LMDf4TLCuBOgO9AfGmVl+sK/xQCnQJWj96zq4krOIREq2Kmd3r3T3t4LlLcAKoBgYCEwOuk0GBgXLA4Gp7l7t7h8CZUAvMysCCt19vrs7MCVpm11SchaRSPG4ZdzMrNTMFiW10lT7NLNDgSOBBUB7d6+ERAIH2gXdioG1SZuVB7HiYHnHeFq6ISgikVKf2RruPgGYkK6PmTUHngCucvfNaYaLU63wNPG0lJxFJFKyOVvDzApIJOZH3P3JILzBzIrcvTIYsqgK4uVAx6TNOwAVQbxDinhaGtYQkUiJxfMybukEMyoeBla4+71Jq2YAQ4PlocD0pHiJmTUxs04kbvwtDIY+tphZ72CfFyZts0uqnEUkUrL4EMoPgAuAJWa2OIjdCIwGppnZMGANcG7iuL7MzKYBy0nM9Bju7rFgu8uASUAzYHbQ0lJyFpFIiWfplaHu/hqpx4sBTt3FNqOAUSnii4Ae9Tm+krOIRIre5ywiEkJ6t0aGvlHYru5O8rXz6rsTc30KElHZGtbINVXOIhIpdc3CaCiUnEUkUiIyqqHkLCLRomENEZEQ0mwNEZEQisiXbys5i0i0+C6fG2lYlJxFJFJqNKwhIhI+qpxFREJIY84iIiGkyllEJIRUOYuIhFBMlbOISPhk8VuqckrJWUQiJa7KWUQkfPTiIxGRENINQRGREIqbhjVEREInVneXBiEaXxkgIhKIW+atLmY20cyqzGxpUuw2M1tnZouDNiBp3QgzKzOzlWbWLyl+tJktCdaNNau7vFdyFpFIiWMZtwxMAvqniN/n7j2DNgvAzLoBJUD3YJtxZpYf9B8PlAJdgpZqn9tRchaRSPF6tDr35f4K8EmGhx4ITHX3anf/ECgDeplZEVDo7vPd3YEpwKC6dqbkLCKRks1hjTQuN7N3g2GPVkGsGFib1Kc8iBUHyzvG01JyFpFIidejmVmpmS1KaqUZHGI80BnoCVQCY4J4qnTvaeJpabaGiERKrB4VsbtPACbUZ//uvuGrZTN7CJgZfCwHOiZ17QBUBPEOKeJpqXIWkUipT+W8O4Ix5K8MBr6ayTEDKDGzJmbWicSNv4XuXglsMbPewSyNC4HpdR1HlbOIREo2nxA0s8eAPkAbMysHbgX6mFlPEkMTq4FLAdx9mZlNA5YDNcBwd/9q2vVlJGZ+NANmBy0tJWcRiZRsfoWgu/84RfjhNP1HAaNSxBcBPepzbCVnEYkUvVtDRCSEovL4tpKziESKXrYvIhJCGtYQEQkhJWcRkRDSN6GIiISQxpxFREJIszVEREIoHpGBDSVnEYkU3RAUEQmhaNTNSs4iEjGqnEVEQqjGolE7KzmLSKREIzUrOYtIxGhYQ0QkhDSVTkQkhKKRmpWcRSRiNKwhIhJCsYjUzkrOIhIpqpxFRELIVTmLiISPKueIa9ykMY8/8zCNGzcmv1E+zz3zAr//7YPb9Sk8oAW/HXsbhxzagerqL7n+itt4/71/7tlxGxdwz7g76HH4d9j06Wf84pLrWbe2ku/06Modd99E8xb7E4/FeOC+h3n26ef36FhSf9XVXzJ0+LV8uW0bsZoYp518PJdfcsF2fSY+8leeff4lAGKxGKs+Wsurz07lgMIWu33cL7/8khF3jGH5yg9oeUAh94wcQXFReyrWb+CqG+8kFotTU1PD+eeczZDBZ+7RNTZ02ZxKZ2YTgbOAKnfvEcRaA48DhwKrgfPc/dNg3QhgGIk3l17h7n8L4kcDk4BmwCzgSndPe6J5WbuKiPmy+kt+MriUM/sM4aw+JZx4yvfpefR3t+vz86uHsWLpSgacNIRf/vxmbrnr2oz3X9yxiEenP7RT/LyfDGLzpi2c0msgEx98hOtvvRKAL/79Bb8afjP9jz+Hi4Zczs2jfkWLwuZ7dpFSb40bFzBx7GienDyOv05+gL8veJN3lq7Yrs9Pf3IOT0x+gCcmP8BV/3URx/T8bsaJeV3lBi66/Lqd4k/OfJ7CFs2ZPW0iFwwZxL3jJgLQ9sDW/OXBMTwx+QEee+j3PPyXaVRt/HjPL7QB83q0DEwC+u8QuwGY6+5dgLnBZ8ysG1ACdA+2GWdm+cE244FSoEvQdtznTpSc0/ifz/8NQKOCRjQqaMSOv+i6fOsw/vHKQgBWla2muOPBtGnbGoCB5w7gqef/zMyXpnLnmJvIy8vsX3XfM/rwxNRnAJg94wW+f0IvAD785xpWr1oDQNX6jXy88VMObNN6zy9S6sXM2G+/ZgDU1NRQU1OD2a6/emPWCy8z4LSTaj8/87cXKbnkSn40dDi3/24ssVhmr4Z/8dX5DBzQF4DT+5zAgjcX4+4UFBTQuHFjAL7cto14+mLsa6EGz7jVxd1fAT7ZITwQmBwsTwYGJcWnunu1u38IlAG9zKwIKHT3+UG1PCVpm11Sck4jLy+PmS9N5Y0Vc/n7vNd5562l261fsfR9+p11KgCHH9md4o5FHHRwezp36cRZg07n3AEXc9bJJcRjcQaeMyCjY7YvakfluvVA4q/EWzZvpVXrltv1OfzI7hQ0bsRHH67d84uUeovFYvxo6HBOPOvHfO/YIzm8+7dT9vv3F1/w2uuLOK3P8QD8c/Uanpv7Mn8OKt28vDxmBsMfdana+DEHtWsDQKNG+TTffz82fbYZgMoNGxl84WX0HXwhw35yLu3aHpiFq2y4vB7/mFmpmS1KaqUZHKK9u1cCBD/bBfFiIPl/yvIgVhws7xhPa7fHnM3sYnf/0y7WlZIo4Tlw/w4UNm2zu4fJqXg8zlknl9CisDkPTrmXrt/uvN2Y8oN/+BO33HUtM1+aysoVH7B8yUpqamJ8/8Re9DiiG0/P+QsATZs14eN/JX75jp88ho7fKKagcQEHFx/EzJemAjBpwqP89bEZKauw5Iq9bfs23Dv+Tn41/JadKnnZN/Lz83li8gNs3rKVK0fcwQerVtPlsEN36jfvtQUceXi32iGNBYsWs/y9MkqGJYaqqqurad2qJQBXjBjJuooNbKvZRuWGjfxo6HAA/vO8gQw+8/SU/62/+rNS1L4tT00ZT9XGj7lixEhOO/l42rRutReuvGGozw1Bd58ATMjSoVP9FcrTxNPakxuCtwMpk3PyBR/W5sgGn0G2bN7Kgr8v4sRTv79dct669XOuu+K22s+vvPUs5R+to9f3juLJqc9w951/3Glflw39JZAYc777/pGcP/Bn261fX7GBouKDWF9ZRX5+Pi0Km7Pp088AaN58fx5+bCxj7nqAxW8u2QtXKvVR2KI5xx51OK+9vihlcp4992UG9O1T+9ndOfuMvlx92cU79R37m1uAxJjzTaPGMOn+3223vn27Nqyv+hcHtWtLTU2MrZ//z07j2O3aHsg3Ox3CW+8s5fSTT9jzC2yg9sFUug1mVuTulcGQRVUQLwc6JvXrAFQE8Q4p4mmlHdYws3d30ZYA7etzNQ1N6wNb1d5wa9K0CT848ThWfbB6uz4tCptTUJD4/TbkgsEsnP8WW7d+zj9eWcgZZ/flwDaJ6uWAloUc3KEoo+POfe5lflTyQwDOOLsv8199A4CCgkY8OGUMTz0+k9kzXsjGJcpu+OTTTWzeshWAL6qref2Nt+l0SMed+m3Z+jmL3l7CySd8rzbW+5iezJn3Gh9/ugmAzzZvoWL9hoyOe/LxvZk+K/Hf/fl5r3Lc0UdgZqyv2sgX1dW1+3t7yXIO/UaHdLuKvHg92m6aAQwNlocC05PiJWbWxMw6kbjxtzAY+thiZr0t8dedC5O22aW6Kuf2QD/g0x3iBvwjo8tooNq1b8Pd948kPz8Py8tj1vQ5vPj8q5x/0TkAPDrpr3yz62GMGXcHsViMspWruP7K2wEoe38VY+56gMn/PZ68PGNbTQ23XjeaivLKOo/7+CNPc++4O3lx4XQ+27SZK352AwADBp3Osd87ipatWvKjkrMBuPYXt7Bi6ft76d+ApLLx40+56c57iMXjeNzpd8oJ9PnBcTz+1LMAtdPY5r78D77f6yj2a9a0dtvOnQ7hFz+7kNKrbiLucQoaNeKma37OwQfVXef8x1n9GHHH3Zxx3k85oLAFd9+e+HOxavVa7r7/IcwMd+eiH/8HXTt32gtX3nDEsjjcZ2aPAX2ANmZWDtwKjAammdkwYA1wLoC7LzOzacByoAYY7u5f3fG9jP+bSjc7aOmPnW7c0sweBv7k7q+lWPeou59f1wGiMKwh2bfyvSdyfQoSQgVtDtv11JcMnX/I4IxzzqMfPbXHx9tb0lbO7j4szbo6E7OIyL6mx7dFREJIj2+LiISQvglFRCSENKwhIhJC2ZytkUtKziISKRrWEBEJId0QFBEJIY05i4iEkIY1RERCKCpva1RyFpFIialyFhEJHw1riIiEkIY1RERCSJWziEgIaSqdiEgI6fFtEZEQ0rCGiEgIKTmLiISQZmuIiISQKmcRkRCKymyNvFyfgIhINsU8nnGri5mtNrMlZrbYzBYFsdZmNsfMPgh+tkrqP8LMysxspZn125PrUHIWkUhx94xbhk52957ufkzw+QZgrrt3AeYGnzGzbkAJ0B3oD4wzs/zdvQ4lZxGJlDiecdtNA4HJwfJkYFBSfKq7V7v7h0AZ0Gt3D6LkLCKR4vX4x8xKzWxRUivdaXfwvJm9mbSuvbtXAgQ/2wXxYmBt0rblQWy36IagiERKvB5T6dx9AjAhTZcfuHuFmbUD5pjZe2n6WqpDZHwyO1DlLCKRUp/Kuc59uVcEP6uAp0gMU2wwsyKA4GdV0L0c6Ji0eQegYnevQ8lZRCIlW7M1zGx/M2vx1TJwOrAUmAEMDboNBaYHyzOAEjNrYmadgC7Awt29Dg1riEik1GdYow7tgafMDBK58lF3f87M3gCmmdkwYA1wLoC7LzOzacByoAYY7u6x3T24krOIREq2HkJx91XAESniHwOn7mKbUcCobBxfyVlEIiWLlXNOKTmLSKRE5fFtJWcRiZTY7g/zhoqSs4hEil4ZKiISQnplqIhICKlyFhEJIc3WEBEJIc3WEBEJoUxeot8QKDmLSKRozFlEJIQ05iwiEkKqnEVEQkjznEVEQkiVs4hICGm2hohICOmGoIhICGlYQ0QkhPSEoIhICKlyFhEJoaiMOVtUfss0BGZW6u4Tcn0eEi76cyGp5OX6BL5mSnN9AhJK+nMhO1FyFhEJISVnEZEQUnLetzSuKKnoz4XsRDcERURCSJWziEgIKTmLiISQkvM+Ymb9zWylmZWZ2Q25Ph/JPTObaGZVZrY01+ci4aPkvA+YWT7wAHAG0A34sZl1y+1ZSQhMAvrn+iQknJSc941eQJm7r3L3L4GpwMAcn5PkmLu/AnyS6/OQcFJy3jeKgbVJn8uDmIhISkrO+4aliGkOo4jskpLzvlEOdEz63AGoyNG5iEgDoOS8b7wBdDGzTmbWGCgBZuT4nEQkxJSc9wF3rwEuB/4GrACmufuy3J6V5JqZPQbMB75lZuVmNizX5yThoce3RURCSJWziEgIKTmLiISQkrOISAgpOYuIhJCSs4hICCk5i4iEkJKziEgI/S8n2or16GTwVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred9, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred9), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randon forest is not better than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15 Random Forest (10 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 588building tree 2 of 588building tree 3 of 588\n",
      "\n",
      "building tree 4 of 588\n",
      "\n",
      "building tree 5 of 588\n",
      "building tree 6 of 588\n",
      "building tree 7 of 588\n",
      "building tree 8 of 588\n",
      "building tree 9 of 588\n",
      "building tree 10 of 588building tree 11 of 588\n",
      "\n",
      "building tree 12 of 588\n",
      "building tree 13 of 588\n",
      "building tree 14 of 588\n",
      "building tree 15 of 588\n",
      "building tree 16 of 588\n",
      "building tree 17 of 588\n",
      "building tree 18 of 588\n",
      "building tree 19 of 588\n",
      "building tree 20 of 588\n",
      "building tree 21 of 588\n",
      "building tree 22 of 588\n",
      "building tree 23 of 588\n",
      "building tree 24 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 588\n",
      "building tree 26 of 588\n",
      "building tree 27 of 588\n",
      "building tree 28 of 588\n",
      "building tree 29 of 588\n",
      "building tree 30 of 588\n",
      "building tree 31 of 588\n",
      "building tree 32 of 588\n",
      "building tree 33 of 588\n",
      "building tree 34 of 588building tree 35 of 588\n",
      "\n",
      "building tree 36 of 588\n",
      "building tree 37 of 588\n",
      "building tree 38 of 588\n",
      "building tree 39 of 588\n",
      "building tree 40 of 588\n",
      "building tree 41 of 588\n",
      "building tree 42 of 588\n",
      "building tree 43 of 588\n",
      "building tree 44 of 588\n",
      "building tree 45 of 588\n",
      "building tree 46 of 588\n",
      "building tree 47 of 588\n",
      "building tree 48 of 588\n",
      "building tree 49 of 588\n",
      "building tree 50 of 588\n",
      "building tree 51 of 588\n",
      "building tree 52 of 588\n",
      "building tree 53 of 588\n",
      "building tree 54 of 588\n",
      "building tree 55 of 588\n",
      "building tree 56 of 588\n",
      "building tree 57 of 588\n",
      "building tree 58 of 588\n",
      "building tree 59 of 588\n",
      "building tree 60 of 588\n",
      "building tree 61 of 588\n",
      "building tree 62 of 588\n",
      "building tree 63 of 588\n",
      "building tree 64 of 588\n",
      "building tree 65 of 588building tree 66 of 588\n",
      "\n",
      "building tree 67 of 588\n",
      "building tree 68 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 69 of 588\n",
      "building tree 70 of 588\n",
      "building tree 71 of 588\n",
      "building tree 72 of 588\n",
      "building tree 73 of 588\n",
      "building tree 74 of 588\n",
      "building tree 75 of 588\n",
      "building tree 76 of 588\n",
      "building tree 77 of 588\n",
      "building tree 78 of 588building tree 79 of 588\n",
      "\n",
      "building tree 80 of 588\n",
      "building tree 81 of 588\n",
      "building tree 82 of 588\n",
      "building tree 83 of 588\n",
      "building tree 84 of 588\n",
      "building tree 85 of 588\n",
      "building tree 86 of 588\n",
      "building tree 87 of 588\n",
      "building tree 88 of 588\n",
      "building tree 89 of 588\n",
      "building tree 90 of 588\n",
      "building tree 91 of 588\n",
      "building tree 92 of 588\n",
      "building tree 93 of 588\n",
      "building tree 94 of 588\n",
      "building tree 95 of 588\n",
      "building tree 96 of 588\n",
      "building tree 97 of 588\n",
      "building tree 98 of 588\n",
      "building tree 99 of 588\n",
      "building tree 100 of 588\n",
      "building tree 101 of 588\n",
      "building tree 102 of 588\n",
      "building tree 103 of 588\n",
      "building tree 104 of 588\n",
      "building tree 105 of 588\n",
      "building tree 106 of 588\n",
      "building tree 107 of 588\n",
      "building tree 108 of 588\n",
      "building tree 109 of 588\n",
      "building tree 110 of 588\n",
      "building tree 111 of 588\n",
      "building tree 112 of 588\n",
      "building tree 113 of 588\n",
      "building tree 114 of 588\n",
      "building tree 115 of 588\n",
      "building tree 116 of 588\n",
      "building tree 117 of 588\n",
      "building tree 118 of 588\n",
      "building tree 119 of 588\n",
      "building tree 120 of 588\n",
      "building tree 121 of 588\n",
      "building tree 122 of 588\n",
      "building tree 123 of 588\n",
      "building tree 124 of 588\n",
      "building tree 125 of 588\n",
      "building tree 126 of 588\n",
      "building tree 127 of 588\n",
      "building tree 128 of 588\n",
      "building tree 129 of 588\n",
      "building tree 130 of 588\n",
      "building tree 131 of 588\n",
      "building tree 132 of 588\n",
      "building tree 133 of 588\n",
      "building tree 134 of 588\n",
      "building tree 135 of 588\n",
      "building tree 136 of 588\n",
      "building tree 137 of 588\n",
      "building tree 138 of 588\n",
      "building tree 139 of 588\n",
      "building tree 140 of 588\n",
      "building tree 141 of 588\n",
      "building tree 142 of 588\n",
      "building tree 143 of 588\n",
      "building tree 144 of 588\n",
      "building tree 145 of 588\n",
      "building tree 146 of 588\n",
      "building tree 147 of 588\n",
      "building tree 148 of 588\n",
      "building tree 149 of 588\n",
      "building tree 150 of 588\n",
      "building tree 151 of 588\n",
      "building tree 152 of 588\n",
      "building tree 153 of 588\n",
      "building tree 154 of 588\n",
      "building tree 155 of 588\n",
      "building tree 156 of 588\n",
      "building tree 157 of 588\n",
      "building tree 158 of 588\n",
      "building tree 159 of 588\n",
      "building tree 160 of 588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 161 of 588\n",
      "\n",
      "building tree 162 of 588\n",
      "building tree 163 of 588\n",
      "building tree 164 of 588\n",
      "building tree 165 of 588\n",
      "building tree 166 of 588\n",
      "building tree 167 of 588\n",
      "building tree 168 of 588\n",
      "building tree 169 of 588\n",
      "building tree 170 of 588\n",
      "building tree 171 of 588\n",
      "building tree 172 of 588\n",
      "building tree 173 of 588\n",
      "building tree 174 of 588\n",
      "building tree 175 of 588\n",
      "building tree 176 of 588\n",
      "building tree 177 of 588\n",
      "building tree 178 of 588\n",
      "building tree 179 of 588\n",
      "building tree 180 of 588\n",
      "building tree 181 of 588\n",
      "building tree 182 of 588\n",
      "building tree 183 of 588\n",
      "building tree 184 of 588\n",
      "building tree 185 of 588\n",
      "building tree 186 of 588\n",
      "building tree 187 of 588\n",
      "building tree 188 of 588\n",
      "building tree 189 of 588\n",
      "building tree 190 of 588\n",
      "building tree 191 of 588\n",
      "building tree 192 of 588\n",
      "building tree 193 of 588\n",
      "building tree 194 of 588\n",
      "building tree 195 of 588\n",
      "building tree 196 of 588\n",
      "building tree 197 of 588\n",
      "building tree 198 of 588\n",
      "building tree 199 of 588\n",
      "building tree 200 of 588\n",
      "building tree 201 of 588\n",
      "building tree 202 of 588\n",
      "building tree 203 of 588\n",
      "building tree 204 of 588\n",
      "building tree 205 of 588\n",
      "building tree 206 of 588\n",
      "building tree 207 of 588\n",
      "building tree 208 of 588\n",
      "building tree 209 of 588\n",
      "building tree 210 of 588\n",
      "building tree 211 of 588\n",
      "building tree 212 of 588\n",
      "building tree 213 of 588\n",
      "building tree 214 of 588\n",
      "building tree 215 of 588\n",
      "building tree 216 of 588\n",
      "building tree 217 of 588\n",
      "building tree 218 of 588\n",
      "building tree 219 of 588\n",
      "building tree 220 of 588\n",
      "building tree 221 of 588\n",
      "building tree 222 of 588\n",
      "building tree 223 of 588\n",
      "building tree 224 of 588\n",
      "building tree 225 of 588\n",
      "building tree 226 of 588\n",
      "building tree 227 of 588\n",
      "building tree 228 of 588\n",
      "building tree 229 of 588\n",
      "building tree 230 of 588\n",
      "building tree 231 of 588\n",
      "building tree 232 of 588\n",
      "building tree 233 of 588\n",
      "building tree 234 of 588\n",
      "building tree 235 of 588\n",
      "building tree 236 of 588\n",
      "building tree 237 of 588\n",
      "building tree 238 of 588\n",
      "building tree 239 of 588\n",
      "building tree 240 of 588\n",
      "building tree 241 of 588\n",
      "building tree 242 of 588\n",
      "building tree 243 of 588\n",
      "building tree 244 of 588\n",
      "building tree 245 of 588\n",
      "building tree 246 of 588\n",
      "building tree 247 of 588\n",
      "building tree 248 of 588\n",
      "building tree 249 of 588building tree 250 of 588\n",
      "\n",
      "building tree 251 of 588\n",
      "building tree 252 of 588\n",
      "building tree 253 of 588\n",
      "building tree 254 of 588\n",
      "building tree 255 of 588\n",
      "building tree 256 of 588\n",
      "building tree 257 of 588\n",
      "building tree 258 of 588\n",
      "building tree 259 of 588\n",
      "building tree 260 of 588\n",
      "building tree 261 of 588\n",
      "building tree 262 of 588\n",
      "building tree 263 of 588\n",
      "building tree 264 of 588\n",
      "building tree 265 of 588\n",
      "building tree 266 of 588\n",
      "building tree 267 of 588\n",
      "building tree 268 of 588\n",
      "building tree 269 of 588\n",
      "building tree 270 of 588\n",
      "building tree 271 of 588\n",
      "building tree 272 of 588\n",
      "building tree 273 of 588\n",
      "building tree 274 of 588\n",
      "building tree 275 of 588\n",
      "building tree 276 of 588\n",
      "building tree 277 of 588\n",
      "building tree 278 of 588\n",
      "building tree 279 of 588\n",
      "building tree 280 of 588\n",
      "building tree 281 of 588building tree 282 of 588\n",
      "\n",
      "building tree 283 of 588\n",
      "building tree 284 of 588\n",
      "building tree 285 of 588\n",
      "building tree 286 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    6.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 287 of 588\n",
      "building tree 288 of 588\n",
      "building tree 289 of 588\n",
      "building tree 290 of 588\n",
      "building tree 291 of 588\n",
      "building tree 292 of 588\n",
      "building tree 293 of 588\n",
      "building tree 294 of 588\n",
      "building tree 295 of 588\n",
      "building tree 296 of 588\n",
      "building tree 297 of 588\n",
      "building tree 298 of 588\n",
      "building tree 299 of 588\n",
      "building tree 300 of 588\n",
      "building tree 301 of 588\n",
      "building tree 302 of 588\n",
      "building tree 303 of 588\n",
      "building tree 304 of 588\n",
      "building tree 305 of 588\n",
      "building tree 306 of 588\n",
      "building tree 307 of 588\n",
      "building tree 308 of 588building tree 309 of 588\n",
      "building tree 310 of 588\n",
      "\n",
      "building tree 311 of 588\n",
      "building tree 312 of 588\n",
      "building tree 313 of 588\n",
      "building tree 314 of 588\n",
      "building tree 315 of 588\n",
      "building tree 316 of 588\n",
      "building tree 317 of 588\n",
      "building tree 318 of 588\n",
      "building tree 319 of 588\n",
      "building tree 320 of 588\n",
      "building tree 321 of 588\n",
      "building tree 322 of 588\n",
      "building tree 323 of 588\n",
      "building tree 324 of 588\n",
      "building tree 325 of 588\n",
      "building tree 326 of 588\n",
      "building tree 327 of 588\n",
      "building tree 328 of 588\n",
      "building tree 329 of 588\n",
      "building tree 330 of 588\n",
      "building tree 331 of 588\n",
      "building tree 332 of 588\n",
      "building tree 333 of 588\n",
      "building tree 334 of 588\n",
      "building tree 335 of 588\n",
      "building tree 336 of 588\n",
      "building tree 337 of 588\n",
      "building tree 338 of 588\n",
      "building tree 339 of 588\n",
      "building tree 340 of 588\n",
      "building tree 341 of 588\n",
      "building tree 342 of 588\n",
      "building tree 343 of 588\n",
      "building tree 344 of 588\n",
      "building tree 345 of 588\n",
      "building tree 346 of 588\n",
      "building tree 347 of 588\n",
      "building tree 348 of 588\n",
      "building tree 349 of 588building tree 350 of 588\n",
      "\n",
      "building tree 351 of 588building tree 352 of 588\n",
      "\n",
      "building tree 353 of 588\n",
      "building tree 354 of 588\n",
      "building tree 355 of 588\n",
      "building tree 356 of 588\n",
      "building tree 357 of 588\n",
      "building tree 358 of 588\n",
      "building tree 359 of 588\n",
      "building tree 360 of 588\n",
      "building tree 361 of 588\n",
      "building tree 362 of 588\n",
      "building tree 363 of 588\n",
      "building tree 364 of 588\n",
      "building tree 365 of 588\n",
      "building tree 366 of 588\n",
      "building tree 367 of 588\n",
      "building tree 368 of 588\n",
      "building tree 369 of 588building tree 370 of 588\n",
      "\n",
      "building tree 371 of 588\n",
      "building tree 372 of 588\n",
      "building tree 373 of 588\n",
      "building tree 374 of 588\n",
      "building tree 375 of 588\n",
      "building tree 376 of 588\n",
      "building tree 377 of 588\n",
      "building tree 378 of 588\n",
      "building tree 379 of 588\n",
      "building tree 380 of 588\n",
      "building tree 381 of 588\n",
      "building tree 382 of 588\n",
      "building tree 383 of 588\n",
      "building tree 384 of 588\n",
      "building tree 385 of 588\n",
      "building tree 386 of 588\n",
      "building tree 387 of 588\n",
      "building tree 388 of 588\n",
      "building tree 389 of 588\n",
      "building tree 390 of 588\n",
      "building tree 391 of 588\n",
      "building tree 392 of 588\n",
      "building tree 393 of 588\n",
      "building tree 394 of 588\n",
      "building tree 395 of 588\n",
      "building tree 396 of 588\n",
      "building tree 397 of 588\n",
      "building tree 398 of 588\n",
      "building tree 399 of 588\n",
      "building tree 400 of 588\n",
      "building tree 401 of 588\n",
      "building tree 402 of 588\n",
      "building tree 403 of 588\n",
      "building tree 404 of 588\n",
      "building tree 405 of 588\n",
      "building tree 406 of 588\n",
      "building tree 407 of 588\n",
      "building tree 408 of 588\n",
      "building tree 409 of 588\n",
      "building tree 410 of 588\n",
      "building tree 411 of 588\n",
      "building tree 412 of 588\n",
      "building tree 413 of 588\n",
      "building tree 414 of 588\n",
      "building tree 415 of 588\n",
      "building tree 416 of 588\n",
      "building tree 417 of 588\n",
      "building tree 418 of 588\n",
      "building tree 419 of 588\n",
      "building tree 420 of 588\n",
      "building tree 421 of 588\n",
      "building tree 422 of 588\n",
      "building tree 423 of 588\n",
      "building tree 424 of 588\n",
      "building tree 425 of 588\n",
      "building tree 426 of 588\n",
      "building tree 427 of 588building tree 428 of 588\n",
      "\n",
      "building tree 429 of 588\n",
      "building tree 430 of 588\n",
      "building tree 431 of 588\n",
      "building tree 432 of 588building tree 433 of 588\n",
      "\n",
      "building tree 434 of 588\n",
      "building tree 435 of 588building tree 436 of 588\n",
      "\n",
      "building tree 437 of 588\n",
      "building tree 438 of 588\n",
      "building tree 439 of 588\n",
      "building tree 440 of 588building tree 441 of 588\n",
      "\n",
      "building tree 442 of 588\n",
      "building tree 443 of 588\n",
      "building tree 444 of 588\n",
      "building tree 445 of 588\n",
      "building tree 446 of 588\n",
      "building tree 447 of 588\n",
      "building tree 448 of 588\n",
      "building tree 449 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 450 of 588\n",
      "building tree 451 of 588\n",
      "building tree 452 of 588\n",
      "building tree 453 of 588\n",
      "building tree 454 of 588building tree 455 of 588\n",
      "\n",
      "building tree 456 of 588building tree 457 of 588\n",
      "\n",
      "building tree 458 of 588\n",
      "building tree 459 of 588\n",
      "building tree 460 of 588\n",
      "building tree 461 of 588\n",
      "building tree 462 of 588\n",
      "building tree 463 of 588\n",
      "building tree 464 of 588\n",
      "building tree 465 of 588\n",
      "building tree 466 of 588\n",
      "building tree 467 of 588\n",
      "building tree 468 of 588\n",
      "building tree 469 of 588\n",
      "building tree 470 of 588\n",
      "building tree 471 of 588\n",
      "building tree 472 of 588\n",
      "building tree 473 of 588\n",
      "building tree 474 of 588\n",
      "building tree 475 of 588\n",
      "building tree 476 of 588\n",
      "building tree 477 of 588\n",
      "building tree 478 of 588\n",
      "building tree 479 of 588\n",
      "building tree 480 of 588\n",
      "building tree 481 of 588\n",
      "building tree 482 of 588\n",
      "building tree 483 of 588\n",
      "building tree 484 of 588\n",
      "building tree 485 of 588\n",
      "building tree 486 of 588\n",
      "building tree 487 of 588\n",
      "building tree 488 of 588\n",
      "building tree 489 of 588\n",
      "building tree 490 of 588\n",
      "building tree 491 of 588\n",
      "building tree 492 of 588\n",
      "building tree 493 of 588\n",
      "building tree 494 of 588\n",
      "building tree 495 of 588\n",
      "building tree 496 of 588\n",
      "building tree 497 of 588\n",
      "building tree 498 of 588\n",
      "building tree 499 of 588\n",
      "building tree 500 of 588\n",
      "building tree 501 of 588\n",
      "building tree 502 of 588\n",
      "building tree 503 of 588\n",
      "building tree 504 of 588\n",
      "building tree 505 of 588\n",
      "building tree 506 of 588\n",
      "building tree 507 of 588\n",
      "building tree 508 of 588\n",
      "building tree 509 of 588\n",
      "building tree 510 of 588\n",
      "building tree 511 of 588\n",
      "building tree 512 of 588\n",
      "building tree 513 of 588\n",
      "building tree 514 of 588\n",
      "building tree 515 of 588\n",
      "building tree 516 of 588\n",
      "building tree 517 of 588\n",
      "building tree 518 of 588\n",
      "building tree 519 of 588\n",
      "building tree 520 of 588\n",
      "building tree 521 of 588\n",
      "building tree 522 of 588\n",
      "building tree 523 of 588\n",
      "building tree 524 of 588\n",
      "building tree 525 of 588\n",
      "building tree 526 of 588\n",
      "building tree 527 of 588\n",
      "building tree 528 of 588\n",
      "building tree 529 of 588\n",
      "building tree 530 of 588\n",
      "building tree 531 of 588\n",
      "building tree 532 of 588\n",
      "building tree 533 of 588\n",
      "building tree 534 of 588\n",
      "building tree 535 of 588\n",
      "building tree 536 of 588\n",
      "building tree 537 of 588\n",
      "building tree 538 of 588\n",
      "building tree 539 of 588building tree 540 of 588\n",
      "\n",
      "building tree 541 of 588\n",
      "building tree 542 of 588\n",
      "building tree 543 of 588\n",
      "building tree 544 of 588\n",
      "building tree 545 of 588\n",
      "building tree 546 of 588\n",
      "building tree 547 of 588\n",
      "building tree 548 of 588\n",
      "building tree 549 of 588\n",
      "building tree 550 of 588\n",
      "building tree 551 of 588\n",
      "building tree 552 of 588\n",
      "building tree 553 of 588\n",
      "building tree 554 of 588\n",
      "building tree 555 of 588\n",
      "building tree 556 of 588\n",
      "building tree 557 of 588\n",
      "building tree 558 of 588\n",
      "building tree 559 of 588\n",
      "building tree 560 of 588\n",
      "building tree 561 of 588\n",
      "building tree 562 of 588\n",
      "building tree 563 of 588\n",
      "building tree 564 of 588\n",
      "building tree 565 of 588\n",
      "building tree 566 of 588building tree 567 of 588\n",
      "\n",
      "building tree 568 of 588\n",
      "building tree 569 of 588\n",
      "building tree 570 of 588\n",
      "building tree 571 of 588\n",
      "building tree 572 of 588\n",
      "building tree 573 of 588\n",
      "building tree 574 of 588\n",
      "building tree 575 of 588\n",
      "building tree 576 of 588\n",
      "building tree 577 of 588building tree 578 of 588\n",
      "\n",
      "building tree 579 of 588\n",
      "building tree 580 of 588\n",
      "building tree 581 of 588\n",
      "building tree 582 of 588\n",
      "building tree 583 of 588\n",
      "building tree 584 of 588\n",
      "building tree 585 of 588\n",
      "building tree 586 of 588\n",
      "building tree 587 of 588\n",
      "building tree 588 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 588 out of 588 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=8,\n",
       "                                                    verbose=5),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([ 1...\n",
       "       906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918,\n",
       "       919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931,\n",
       "       932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944,\n",
       "       945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957,\n",
       "       958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970,\n",
       "       971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983,\n",
       "       984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996,\n",
       "       997, 998, 999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf =RandomForestClassifier(n_jobs = -1, random_state = 8, verbose = 5, bootstrap = True)\n",
    "param_grid10 = {'n_estimators': np.arange(100, 1000),\n",
    "               'max_depth': np.arange(1, 20),\n",
    "               'criterion': ['gini','entropy'],\n",
    "               'min_samples_split':list(range(10,500,20)),\n",
    "               'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid10 = RandomizedSearchCV(rf_clf, param_grid10, cv=5, verbose=5, n_jobs=-1)\n",
    "grid10.fit(X_smo_10, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 588,\n",
       " 'min_samples_split': 250,\n",
       " 'max_depth': 16,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': {0: 0.5, 1: 0.5}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model_10 = grid10.best_params_\n",
    "best_rf_model_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 588building tree 2 of 588building tree 3 of 588building tree 4 of 588\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 588\n",
      "building tree 6 of 588\n",
      "building tree 7 of 588\n",
      "building tree 8 of 588\n",
      "building tree 9 of 588\n",
      "building tree 10 of 588\n",
      "building tree 11 of 588\n",
      "building tree 12 of 588\n",
      "building tree 13 of 588\n",
      "building tree 14 of 588\n",
      "building tree 15 of 588\n",
      "building tree 16 of 588\n",
      "building tree 17 of 588\n",
      "building tree 18 of 588\n",
      "building tree 19 of 588\n",
      "building tree 20 of 588\n",
      "building tree 21 of 588\n",
      "building tree 22 of 588\n",
      "building tree 23 of 588\n",
      "building tree 24 of 588\n",
      "building tree 25 of 588\n",
      "building tree 26 of 588\n",
      "building tree 27 of 588\n",
      "building tree 28 of 588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 29 of 588building tree 30 of 588\n",
      "\n",
      "building tree 31 of 588\n",
      "building tree 32 of 588\n",
      "building tree 33 of 588\n",
      "building tree 34 of 588\n",
      "building tree 35 of 588\n",
      "building tree 36 of 588\n",
      "building tree 37 of 588\n",
      "building tree 38 of 588\n",
      "building tree 39 of 588\n",
      "building tree 40 of 588\n",
      "building tree 41 of 588building tree 42 of 588\n",
      "\n",
      "building tree 43 of 588\n",
      "building tree 44 of 588\n",
      "building tree 45 of 588\n",
      "building tree 46 of 588\n",
      "building tree 47 of 588\n",
      "building tree 48 of 588\n",
      "building tree 49 of 588\n",
      "building tree 50 of 588\n",
      "building tree 51 of 588\n",
      "building tree 52 of 588\n",
      "building tree 53 of 588\n",
      "building tree 54 of 588\n",
      "building tree 55 of 588\n",
      "building tree 56 of 588\n",
      "building tree 57 of 588\n",
      "building tree 58 of 588\n",
      "building tree 59 of 588\n",
      "building tree 60 of 588\n",
      "building tree 61 of 588\n",
      "building tree 62 of 588\n",
      "building tree 63 of 588\n",
      "building tree 64 of 588\n",
      "building tree 65 of 588\n",
      "building tree 66 of 588\n",
      "building tree 67 of 588\n",
      "building tree 68 of 588\n",
      "building tree 69 of 588\n",
      "building tree 70 of 588\n",
      "building tree 71 of 588\n",
      "building tree 72 of 588\n",
      "building tree 73 of 588\n",
      "building tree 74 of 588\n",
      "building tree 75 of 588\n",
      "building tree 76 of 588\n",
      "building tree 77 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 78 of 588\n",
      "building tree 79 of 588\n",
      "building tree 80 of 588\n",
      "building tree 81 of 588\n",
      "building tree 82 of 588\n",
      "building tree 83 of 588\n",
      "building tree 84 of 588\n",
      "building tree 85 of 588\n",
      "building tree 86 of 588\n",
      "building tree 87 of 588\n",
      "building tree 88 of 588\n",
      "building tree 89 of 588\n",
      "building tree 90 of 588\n",
      "building tree 91 of 588\n",
      "building tree 92 of 588\n",
      "building tree 93 of 588\n",
      "building tree 94 of 588\n",
      "building tree 95 of 588\n",
      "building tree 96 of 588\n",
      "building tree 97 of 588\n",
      "building tree 98 of 588\n",
      "building tree 99 of 588\n",
      "building tree 100 of 588\n",
      "building tree 101 of 588\n",
      "building tree 102 of 588\n",
      "building tree 103 of 588\n",
      "building tree 104 of 588\n",
      "building tree 105 of 588\n",
      "building tree 106 of 588\n",
      "building tree 107 of 588\n",
      "building tree 108 of 588\n",
      "building tree 109 of 588\n",
      "building tree 110 of 588\n",
      "building tree 111 of 588\n",
      "building tree 112 of 588\n",
      "building tree 113 of 588\n",
      "building tree 114 of 588\n",
      "building tree 115 of 588building tree 116 of 588\n",
      "\n",
      "building tree 117 of 588\n",
      "building tree 118 of 588\n",
      "building tree 119 of 588\n",
      "building tree 120 of 588\n",
      "building tree 121 of 588\n",
      "building tree 122 of 588\n",
      "building tree 123 of 588\n",
      "building tree 124 of 588\n",
      "building tree 125 of 588\n",
      "building tree 126 of 588\n",
      "building tree 127 of 588\n",
      "building tree 128 of 588building tree 129 of 588\n",
      "\n",
      "building tree 130 of 588\n",
      "building tree 131 of 588\n",
      "building tree 132 of 588\n",
      "building tree 133 of 588\n",
      "building tree 134 of 588\n",
      "building tree 135 of 588\n",
      "building tree 136 of 588\n",
      "building tree 137 of 588\n",
      "building tree 138 of 588\n",
      "building tree 139 of 588\n",
      "building tree 140 of 588\n",
      "building tree 141 of 588\n",
      "building tree 142 of 588\n",
      "building tree 143 of 588\n",
      "building tree 144 of 588\n",
      "building tree 145 of 588\n",
      "building tree 146 of 588\n",
      "building tree 147 of 588\n",
      "building tree 148 of 588\n",
      "building tree 149 of 588building tree 150 of 588\n",
      "\n",
      "building tree 151 of 588\n",
      "building tree 152 of 588\n",
      "building tree 153 of 588\n",
      "building tree 154 of 588building tree 155 of 588\n",
      "\n",
      "building tree 156 of 588\n",
      "building tree 157 of 588\n",
      "building tree 158 of 588\n",
      "building tree 159 of 588\n",
      "building tree 160 of 588\n",
      "building tree 161 of 588\n",
      "building tree 162 of 588\n",
      "building tree 163 of 588\n",
      "building tree 164 of 588\n",
      "building tree 165 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 166 of 588building tree 167 of 588\n",
      "\n",
      "building tree 168 of 588\n",
      "building tree 169 of 588\n",
      "building tree 170 of 588\n",
      "building tree 171 of 588\n",
      "building tree 172 of 588\n",
      "building tree 173 of 588\n",
      "building tree 174 of 588\n",
      "building tree 175 of 588\n",
      "building tree 176 of 588\n",
      "building tree 177 of 588\n",
      "building tree 178 of 588\n",
      "building tree 179 of 588\n",
      "building tree 180 of 588\n",
      "building tree 181 of 588\n",
      "building tree 182 of 588\n",
      "building tree 183 of 588\n",
      "building tree 184 of 588\n",
      "building tree 185 of 588\n",
      "building tree 186 of 588\n",
      "building tree 187 of 588\n",
      "building tree 188 of 588\n",
      "building tree 189 of 588\n",
      "building tree 190 of 588\n",
      "building tree 191 of 588\n",
      "building tree 192 of 588\n",
      "building tree 193 of 588\n",
      "building tree 194 of 588building tree 195 of 588\n",
      "\n",
      "building tree 196 of 588\n",
      "building tree 197 of 588\n",
      "building tree 198 of 588\n",
      "building tree 199 of 588\n",
      "building tree 200 of 588\n",
      "building tree 201 of 588\n",
      "building tree 202 of 588\n",
      "building tree 203 of 588\n",
      "building tree 204 of 588\n",
      "building tree 205 of 588\n",
      "building tree 206 of 588\n",
      "building tree 207 of 588\n",
      "building tree 208 of 588\n",
      "building tree 209 of 588\n",
      "building tree 210 of 588\n",
      "building tree 211 of 588\n",
      "building tree 212 of 588\n",
      "building tree 213 of 588\n",
      "building tree 214 of 588\n",
      "building tree 215 of 588\n",
      "building tree 216 of 588\n",
      "building tree 217 of 588\n",
      "building tree 218 of 588\n",
      "building tree 219 of 588\n",
      "building tree 220 of 588\n",
      "building tree 221 of 588\n",
      "building tree 222 of 588\n",
      "building tree 223 of 588\n",
      "building tree 224 of 588\n",
      "building tree 225 of 588\n",
      "building tree 226 of 588\n",
      "building tree 227 of 588\n",
      "building tree 228 of 588\n",
      "building tree 229 of 588\n",
      "building tree 230 of 588\n",
      "building tree 231 of 588\n",
      "building tree 232 of 588\n",
      "building tree 233 of 588\n",
      "building tree 234 of 588\n",
      "building tree 235 of 588\n",
      "building tree 236 of 588\n",
      "building tree 237 of 588\n",
      "building tree 238 of 588\n",
      "building tree 239 of 588\n",
      "building tree 240 of 588\n",
      "building tree 241 of 588\n",
      "building tree 242 of 588\n",
      "building tree 243 of 588\n",
      "building tree 244 of 588\n",
      "building tree 245 of 588\n",
      "building tree 246 of 588\n",
      "building tree 247 of 588\n",
      "building tree 248 of 588\n",
      "building tree 249 of 588\n",
      "building tree 250 of 588\n",
      "building tree 251 of 588\n",
      "building tree 252 of 588\n",
      "building tree 253 of 588\n",
      "building tree 254 of 588\n",
      "building tree 255 of 588\n",
      "building tree 256 of 588\n",
      "building tree 257 of 588\n",
      "building tree 258 of 588\n",
      "building tree 259 of 588\n",
      "building tree 260 of 588\n",
      "building tree 261 of 588\n",
      "building tree 262 of 588\n",
      "building tree 263 of 588\n",
      "building tree 264 of 588\n",
      "building tree 265 of 588\n",
      "building tree 266 of 588\n",
      "building tree 267 of 588\n",
      "building tree 268 of 588\n",
      "building tree 269 of 588\n",
      "building tree 270 of 588\n",
      "building tree 271 of 588\n",
      "building tree 272 of 588\n",
      "building tree 273 of 588\n",
      "building tree 274 of 588\n",
      "building tree 275 of 588\n",
      "building tree 276 of 588\n",
      "building tree 277 of 588\n",
      "building tree 278 of 588\n",
      "building tree 279 of 588\n",
      "building tree 280 of 588\n",
      "building tree 281 of 588\n",
      "building tree 282 of 588\n",
      "building tree 283 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 284 of 588\n",
      "building tree 285 of 588\n",
      "building tree 286 of 588\n",
      "building tree 287 of 588\n",
      "building tree 288 of 588\n",
      "building tree 289 of 588\n",
      "building tree 290 of 588\n",
      "building tree 291 of 588\n",
      "building tree 292 of 588\n",
      "building tree 293 of 588\n",
      "building tree 294 of 588\n",
      "building tree 295 of 588\n",
      "building tree 296 of 588\n",
      "building tree 297 of 588\n",
      "building tree 298 of 588\n",
      "building tree 299 of 588\n",
      "building tree 300 of 588\n",
      "building tree 301 of 588\n",
      "building tree 302 of 588\n",
      "building tree 303 of 588\n",
      "building tree 304 of 588\n",
      "building tree 305 of 588\n",
      "building tree 306 of 588\n",
      "building tree 307 of 588\n",
      "building tree 308 of 588\n",
      "building tree 309 of 588\n",
      "building tree 310 of 588\n",
      "building tree 311 of 588\n",
      "building tree 312 of 588\n",
      "building tree 313 of 588\n",
      "building tree 314 of 588\n",
      "building tree 315 of 588\n",
      "building tree 316 of 588\n",
      "building tree 317 of 588\n",
      "building tree 318 of 588\n",
      "building tree 319 of 588\n",
      "building tree 320 of 588\n",
      "building tree 321 of 588\n",
      "building tree 322 of 588\n",
      "building tree 323 of 588\n",
      "building tree 324 of 588\n",
      "building tree 325 of 588\n",
      "building tree 326 of 588\n",
      "building tree 327 of 588\n",
      "building tree 328 of 588\n",
      "building tree 329 of 588\n",
      "building tree 330 of 588\n",
      "building tree 331 of 588\n",
      "building tree 332 of 588\n",
      "building tree 333 of 588\n",
      "building tree 334 of 588\n",
      "building tree 335 of 588\n",
      "building tree 336 of 588\n",
      "building tree 337 of 588\n",
      "building tree 338 of 588\n",
      "building tree 339 of 588\n",
      "building tree 340 of 588\n",
      "building tree 341 of 588\n",
      "building tree 342 of 588\n",
      "building tree 343 of 588\n",
      "building tree 344 of 588\n",
      "building tree 345 of 588\n",
      "building tree 346 of 588\n",
      "building tree 347 of 588\n",
      "building tree 348 of 588\n",
      "building tree 349 of 588\n",
      "building tree 350 of 588\n",
      "building tree 351 of 588\n",
      "building tree 352 of 588\n",
      "building tree 353 of 588\n",
      "building tree 354 of 588\n",
      "building tree 355 of 588\n",
      "building tree 356 of 588\n",
      "building tree 357 of 588\n",
      "building tree 358 of 588\n",
      "building tree 359 of 588\n",
      "building tree 360 of 588\n",
      "building tree 361 of 588\n",
      "building tree 362 of 588\n",
      "building tree 363 of 588\n",
      "building tree 364 of 588\n",
      "building tree 365 of 588\n",
      "building tree 366 of 588\n",
      "building tree 367 of 588\n",
      "building tree 368 of 588\n",
      "building tree 369 of 588\n",
      "building tree 370 of 588\n",
      "building tree 371 of 588\n",
      "building tree 372 of 588\n",
      "building tree 373 of 588\n",
      "building tree 374 of 588\n",
      "building tree 375 of 588\n",
      "building tree 376 of 588\n",
      "building tree 377 of 588\n",
      "building tree 378 of 588\n",
      "building tree 379 of 588\n",
      "building tree 380 of 588\n",
      "building tree 381 of 588building tree 382 of 588\n",
      "\n",
      "building tree 383 of 588\n",
      "building tree 384 of 588\n",
      "building tree 385 of 588\n",
      "building tree 386 of 588\n",
      "building tree 387 of 588\n",
      "building tree 388 of 588\n",
      "building tree 389 of 588\n",
      "building tree 390 of 588\n",
      "building tree 391 of 588\n",
      "building tree 392 of 588\n",
      "building tree 393 of 588\n",
      "building tree 394 of 588\n",
      "building tree 395 of 588\n",
      "building tree 396 of 588\n",
      "building tree 397 of 588\n",
      "building tree 398 of 588\n",
      "building tree 399 of 588\n",
      "building tree 400 of 588\n",
      "building tree 401 of 588\n",
      "building tree 402 of 588\n",
      "building tree 403 of 588\n",
      "building tree 404 of 588\n",
      "building tree 405 of 588\n",
      "building tree 406 of 588\n",
      "building tree 407 of 588\n",
      "building tree 408 of 588\n",
      "building tree 409 of 588\n",
      "building tree 410 of 588\n",
      "building tree 411 of 588\n",
      "building tree 412 of 588building tree 413 of 588\n",
      "\n",
      "building tree 414 of 588\n",
      "building tree 415 of 588\n",
      "building tree 416 of 588\n",
      "building tree 417 of 588\n",
      "building tree 418 of 588\n",
      "building tree 419 of 588\n",
      "building tree 420 of 588\n",
      "building tree 421 of 588\n",
      "building tree 422 of 588\n",
      "building tree 423 of 588\n",
      "building tree 424 of 588building tree 425 of 588\n",
      "\n",
      "building tree 426 of 588\n",
      "building tree 427 of 588\n",
      "building tree 428 of 588\n",
      "building tree 429 of 588\n",
      "building tree 430 of 588\n",
      "building tree 431 of 588\n",
      "building tree 432 of 588\n",
      "building tree 433 of 588\n",
      "building tree 434 of 588\n",
      "building tree 435 of 588\n",
      "building tree 436 of 588\n",
      "building tree 437 of 588\n",
      "building tree 438 of 588\n",
      "building tree 439 of 588\n",
      "building tree 440 of 588\n",
      "building tree 441 of 588\n",
      "building tree 442 of 588\n",
      "building tree 443 of 588\n",
      "building tree 444 of 588\n",
      "building tree 445 of 588\n",
      "building tree 446 of 588\n",
      "building tree 447 of 588\n",
      "building tree 448 of 588\n",
      "building tree 449 of 588\n",
      "building tree 450 of 588\n",
      "building tree 451 of 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 452 of 588\n",
      "building tree 453 of 588\n",
      "building tree 454 of 588\n",
      "building tree 455 of 588\n",
      "building tree 456 of 588\n",
      "building tree 457 of 588\n",
      "building tree 458 of 588\n",
      "building tree 459 of 588\n",
      "building tree 460 of 588building tree 461 of 588\n",
      "\n",
      "building tree 462 of 588\n",
      "building tree 463 of 588\n",
      "building tree 464 of 588\n",
      "building tree 465 of 588\n",
      "building tree 466 of 588\n",
      "building tree 467 of 588\n",
      "building tree 468 of 588\n",
      "building tree 469 of 588\n",
      "building tree 470 of 588\n",
      "building tree 471 of 588\n",
      "building tree 472 of 588\n",
      "building tree 473 of 588\n",
      "building tree 474 of 588\n",
      "building tree 475 of 588\n",
      "building tree 476 of 588\n",
      "building tree 477 of 588\n",
      "building tree 478 of 588\n",
      "building tree 479 of 588\n",
      "building tree 480 of 588\n",
      "building tree 481 of 588\n",
      "building tree 482 of 588\n",
      "building tree 483 of 588\n",
      "building tree 484 of 588\n",
      "building tree 485 of 588\n",
      "building tree 486 of 588\n",
      "building tree 487 of 588\n",
      "building tree 488 of 588\n",
      "building tree 489 of 588\n",
      "building tree 490 of 588\n",
      "building tree 491 of 588\n",
      "building tree 492 of 588\n",
      "building tree 493 of 588\n",
      "building tree 494 of 588\n",
      "building tree 495 of 588\n",
      "building tree 496 of 588\n",
      "building tree 497 of 588\n",
      "building tree 498 of 588\n",
      "building tree 499 of 588\n",
      "building tree 500 of 588\n",
      "building tree 501 of 588\n",
      "building tree 502 of 588\n",
      "building tree 503 of 588\n",
      "building tree 504 of 588\n",
      "building tree 505 of 588\n",
      "building tree 506 of 588\n",
      "building tree 507 of 588\n",
      "building tree 508 of 588\n",
      "building tree 509 of 588\n",
      "building tree 510 of 588\n",
      "building tree 511 of 588\n",
      "building tree 512 of 588\n",
      "building tree 513 of 588\n",
      "building tree 514 of 588\n",
      "building tree 515 of 588\n",
      "building tree 516 of 588\n",
      "building tree 517 of 588\n",
      "building tree 518 of 588\n",
      "building tree 519 of 588\n",
      "building tree 520 of 588\n",
      "building tree 521 of 588\n",
      "building tree 522 of 588\n",
      "building tree 523 of 588\n",
      "building tree 524 of 588\n",
      "building tree 525 of 588\n",
      "building tree 526 of 588\n",
      "building tree 527 of 588\n",
      "building tree 528 of 588\n",
      "building tree 529 of 588\n",
      "building tree 530 of 588\n",
      "building tree 531 of 588\n",
      "building tree 532 of 588\n",
      "building tree 533 of 588\n",
      "building tree 534 of 588\n",
      "building tree 535 of 588\n",
      "building tree 536 of 588\n",
      "building tree 537 of 588\n",
      "building tree 538 of 588\n",
      "building tree 539 of 588\n",
      "building tree 540 of 588\n",
      "building tree 541 of 588\n",
      "building tree 542 of 588\n",
      "building tree 543 of 588\n",
      "building tree 544 of 588\n",
      "building tree 545 of 588\n",
      "building tree 546 of 588\n",
      "building tree 547 of 588\n",
      "building tree 548 of 588\n",
      "building tree 549 of 588\n",
      "building tree 550 of 588\n",
      "building tree 551 of 588\n",
      "building tree 552 of 588\n",
      "building tree 553 of 588\n",
      "building tree 554 of 588\n",
      "building tree 555 of 588\n",
      "building tree 556 of 588\n",
      "building tree 557 of 588\n",
      "building tree 558 of 588\n",
      "building tree 559 of 588\n",
      "building tree 560 of 588\n",
      "building tree 561 of 588\n",
      "building tree 562 of 588\n",
      "building tree 563 of 588\n",
      "building tree 564 of 588\n",
      "building tree 565 of 588\n",
      "building tree 566 of 588\n",
      "building tree 567 of 588\n",
      "building tree 568 of 588\n",
      "building tree 569 of 588\n",
      "building tree 570 of 588\n",
      "building tree 571 of 588\n",
      "building tree 572 of 588\n",
      "building tree 573 of 588\n",
      "building tree 574 of 588\n",
      "building tree 575 of 588\n",
      "building tree 576 of 588\n",
      "building tree 577 of 588\n",
      "building tree 578 of 588\n",
      "building tree 579 of 588\n",
      "building tree 580 of 588\n",
      "building tree 581 of 588\n",
      "building tree 582 of 588\n",
      "building tree 583 of 588\n",
      "building tree 584 of 588\n",
      "building tree 585 of 588\n",
      "building tree 586 of 588\n",
      "building tree 587 of 588building tree 588 of 588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 588 out of 588 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 588 out of 588 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "best_rf_model_10 = RandomForestClassifier(n_jobs = -1, random_state = 8, verbose = 5, bootstrap = True, n_estimators= 588,\n",
    "                                          min_samples_split= 250, max_depth = 10, criterion = 'gini', class_weight= {0: 0.6, 1: 0.4})\n",
    "best_rf_model_10.fit(X_smo_10, y_smo)\n",
    "ye_pred10 = best_rf_model_10.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred10, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred10), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16 Ensemble: AdaBoost Part II (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=130, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=130, learning_rate=0.1, score=0.584, total=  15.6s\n",
      "[CV] n_estimators=130, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=130, learning_rate=0.1, score=0.969, total=  14.2s\n",
      "[CV] n_estimators=130, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   29.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=130, learning_rate=0.1, score=0.964, total=  14.3s\n",
      "[CV] n_estimators=130, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   44.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=130, learning_rate=0.1, score=0.973, total=  14.2s\n",
      "[CV] n_estimators=130, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   58.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=130, learning_rate=0.1, score=0.969, total=  14.2s\n",
      "[CV] n_estimators=102, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=102, learning_rate=0.1, score=0.583, total=  12.2s\n",
      "[CV] n_estimators=102, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=102, learning_rate=0.1, score=0.966, total=  11.2s\n",
      "[CV] n_estimators=102, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=102, learning_rate=0.1, score=0.963, total=  11.2s\n",
      "[CV] n_estimators=102, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=102, learning_rate=0.1, score=0.973, total=  11.2s\n",
      "[CV] n_estimators=102, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=102, learning_rate=0.1, score=0.965, total=  11.2s\n",
      "[CV] n_estimators=81, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=81, learning_rate=0.1, score=0.583, total=   9.7s\n",
      "[CV] n_estimators=81, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=81, learning_rate=0.1, score=0.967, total=   9.4s\n",
      "[CV] n_estimators=81, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=81, learning_rate=0.1, score=0.963, total=  10.1s\n",
      "[CV] n_estimators=81, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=81, learning_rate=0.1, score=0.972, total=   9.3s\n",
      "[CV] n_estimators=81, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=81, learning_rate=0.1, score=0.965, total=   9.0s\n",
      "[CV] n_estimators=68, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=68, learning_rate=0.1, score=0.583, total=   9.2s\n",
      "[CV] n_estimators=68, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=68, learning_rate=0.1, score=0.967, total=   8.6s\n",
      "[CV] n_estimators=68, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=68, learning_rate=0.1, score=0.963, total=  10.4s\n",
      "[CV] n_estimators=68, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=68, learning_rate=0.1, score=0.972, total=   9.0s\n",
      "[CV] n_estimators=68, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=68, learning_rate=0.1, score=0.963, total=   8.7s\n",
      "[CV] n_estimators=79, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=79, learning_rate=0.1, score=0.583, total=  10.5s\n",
      "[CV] n_estimators=79, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=79, learning_rate=0.1, score=0.967, total=   9.4s\n",
      "[CV] n_estimators=79, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=79, learning_rate=0.1, score=0.964, total=  10.3s\n",
      "[CV] n_estimators=79, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=79, learning_rate=0.1, score=0.972, total=   9.2s\n",
      "[CV] n_estimators=79, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=79, learning_rate=0.1, score=0.965, total=   9.1s\n",
      "[CV] n_estimators=135, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=135, learning_rate=0.1, score=0.584, total=  17.3s\n",
      "[CV] n_estimators=135, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=135, learning_rate=0.1, score=0.970, total=  15.5s\n",
      "[CV] n_estimators=135, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=135, learning_rate=0.1, score=0.964, total=  15.4s\n",
      "[CV] n_estimators=135, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=135, learning_rate=0.1, score=0.974, total=  15.4s\n",
      "[CV] n_estimators=135, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=135, learning_rate=0.1, score=0.968, total=  15.4s\n",
      "[CV] n_estimators=121, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=121, learning_rate=0.1, score=0.584, total=  15.3s\n",
      "[CV] n_estimators=121, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=121, learning_rate=0.1, score=0.966, total=  13.8s\n",
      "[CV] n_estimators=121, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=121, learning_rate=0.1, score=0.962, total=  13.8s\n",
      "[CV] n_estimators=121, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=121, learning_rate=0.1, score=0.973, total=  13.8s\n",
      "[CV] n_estimators=121, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=121, learning_rate=0.1, score=0.969, total=  14.6s\n",
      "[CV] n_estimators=66, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=66, learning_rate=0.1, score=0.583, total=   8.3s\n",
      "[CV] n_estimators=66, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=66, learning_rate=0.1, score=0.966, total=   7.6s\n",
      "[CV] n_estimators=66, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=66, learning_rate=0.1, score=0.962, total=   7.7s\n",
      "[CV] n_estimators=66, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=66, learning_rate=0.1, score=0.970, total=   7.8s\n",
      "[CV] n_estimators=66, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=66, learning_rate=0.1, score=0.964, total=   7.6s\n",
      "[CV] n_estimators=75, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=75, learning_rate=0.1, score=0.583, total=  12.0s\n",
      "[CV] n_estimators=75, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=75, learning_rate=0.1, score=0.967, total=   9.3s\n",
      "[CV] n_estimators=75, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=75, learning_rate=0.1, score=0.963, total=   9.1s\n",
      "[CV] n_estimators=75, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=75, learning_rate=0.1, score=0.972, total=   9.2s\n",
      "[CV] n_estimators=75, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=75, learning_rate=0.1, score=0.964, total=   9.1s\n",
      "[CV] n_estimators=30, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=30, learning_rate=0.1, score=0.582, total=   3.9s\n",
      "[CV] n_estimators=30, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=30, learning_rate=0.1, score=0.944, total=   3.6s\n",
      "[CV] n_estimators=30, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=30, learning_rate=0.1, score=0.936, total=   3.5s\n",
      "[CV] n_estimators=30, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=30, learning_rate=0.1, score=0.955, total=   3.6s\n",
      "[CV] n_estimators=30, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=30, learning_rate=0.1, score=0.951, total=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight={0: 0.6,\n",
       "                                                                                                    1: 0.4},\n",
       "                                                                                      criterion='entropy',\n",
       "                                                                                      max_depth=5,\n",
       "                                                                                      min_samples_split=190)),\n",
       "                   param_distributions={'learning_rate': array([0.1]),\n",
       "                                        'n_estimators': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        4...\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_boost = AdaBoostClassifier(base_estimator=best_dt_model_10) \n",
    "\n",
    "param_grid11 = {'n_estimators':np.arange(1, 150),                \n",
    "              'learning_rate':np.arange(0.1, 1),                          \n",
    "             } \n",
    "grid11 = RandomizedSearchCV(clf_boost, param_grid11, verbose = 5) \n",
    "grid11.fit(X_smo_10, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 135, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_boost_model = grid11.best_params_\n",
    "best_boost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boost = AdaBoostClassifier(base_estimator=best_dt_model_10, n_estimators = 135, learning_rate = 0.1) \n",
    "best_boost.fit(X_smo_10, y_smo)\n",
    "ye_pred11 = best_boost.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred11, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred11), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second adaboost is better than the baseline but not as good as random forest and logistic regression with 10 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
