{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lending Club Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Content__ <br>\n",
    "3.1 Data Import <br>\n",
    "3.2 Train-Test-Split for Training Data <br>\n",
    "3.3 SMOTE <br>\n",
    "3.4 Baseline Model: Dummy Classifier <br>\n",
    "3.5 Feature Selection <br>\n",
    "3.6 Logistic Regression (5 Features)<br>\n",
    "3.7 Logistic Regression (10 Features)<br>\n",
    "3.8 KNN (5 Features)<br>\n",
    "3.9 KNN (10 Features)<br>\n",
    "3.10 Ensemble: AdaBoost <br>\n",
    "3.11 Ensemble: Stacking <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "import re \n",
    "import math\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>term</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "      <th>emp_length_unknown</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>addr_state_AL</th>\n",
       "      <th>addr_state_AR</th>\n",
       "      <th>addr_state_AZ</th>\n",
       "      <th>addr_state_CA</th>\n",
       "      <th>addr_state_CO</th>\n",
       "      <th>addr_state_CT</th>\n",
       "      <th>addr_state_DC</th>\n",
       "      <th>addr_state_DE</th>\n",
       "      <th>addr_state_FL</th>\n",
       "      <th>addr_state_GA</th>\n",
       "      <th>addr_state_HI</th>\n",
       "      <th>addr_state_IA</th>\n",
       "      <th>addr_state_IL</th>\n",
       "      <th>addr_state_KS</th>\n",
       "      <th>addr_state_KY</th>\n",
       "      <th>addr_state_LA</th>\n",
       "      <th>addr_state_MA</th>\n",
       "      <th>addr_state_MD</th>\n",
       "      <th>addr_state_MI</th>\n",
       "      <th>addr_state_MN</th>\n",
       "      <th>addr_state_MO</th>\n",
       "      <th>addr_state_MS</th>\n",
       "      <th>addr_state_MT</th>\n",
       "      <th>addr_state_NC</th>\n",
       "      <th>addr_state_NH</th>\n",
       "      <th>addr_state_NJ</th>\n",
       "      <th>addr_state_NM</th>\n",
       "      <th>addr_state_NV</th>\n",
       "      <th>addr_state_NY</th>\n",
       "      <th>addr_state_OH</th>\n",
       "      <th>addr_state_OK</th>\n",
       "      <th>addr_state_OR</th>\n",
       "      <th>addr_state_PA</th>\n",
       "      <th>addr_state_RI</th>\n",
       "      <th>addr_state_SC</th>\n",
       "      <th>addr_state_SD</th>\n",
       "      <th>addr_state_TN</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.403061</td>\n",
       "      <td>-0.367347</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>-0.361449</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.7899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.546581</td>\n",
       "      <td>-0.123932</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.673469</td>\n",
       "      <td>0.894928</td>\n",
       "      <td>-0.663813</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.1799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.478905</td>\n",
       "      <td>1.057692</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.158163</td>\n",
       "      <td>-0.122449</td>\n",
       "      <td>-1.050725</td>\n",
       "      <td>-0.089012</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.566346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121236</td>\n",
       "      <td>-0.732906</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.124841</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6498</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.291346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.672444</td>\n",
       "      <td>-1.051282</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.505102</td>\n",
       "      <td>-0.469388</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>-0.412665</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0299</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.535577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393115</td>\n",
       "      <td>0.950855</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  loan_amnt  funded_amnt  int_rate  installment  grade  \\\n",
       "0           0  -0.403061    -0.367347 -0.891304    -0.361449   -0.5   \n",
       "1           1  -0.709184    -0.673469  0.894928    -0.663813    1.5   \n",
       "2           2  -0.158163    -0.122449 -1.050725    -0.089012   -0.5   \n",
       "3           3   0.005102     0.040816 -0.782609     0.124841   -0.5   \n",
       "4           4  -0.505102    -0.469388  0.456522    -0.412665    0.5   \n",
       "\n",
       "   annual_inc  issue_d       dti  delinq_2yrs  inq_last_6mths  open_acc  \\\n",
       "0     -0.7899      0.0 -0.400000          0.0            -1.0 -1.000000   \n",
       "1     -1.1799      0.0 -0.436538          0.0             0.0 -1.000000   \n",
       "2     -0.1999      0.0 -0.566346          0.0            -1.0  0.000000   \n",
       "3     -0.6498     -1.0 -1.291346          0.0            -1.0 -0.166667   \n",
       "4     -1.0299     -1.0 -0.535577          0.0             0.0 -0.833333   \n",
       "\n",
       "   pub_rec  revol_bal  revol_util  total_acc  term  emp_length_10+ years  \\\n",
       "0      0.0  -0.546581   -0.123932  -0.733333   0.0                     0   \n",
       "1      0.0  -0.478905    1.057692  -1.066667   0.0                     0   \n",
       "2      0.0  -0.121236   -0.732906  -0.266667   0.0                     1   \n",
       "3      0.0  -0.672444   -1.051282  -0.466667   0.0                     0   \n",
       "4      0.0  -0.393115    0.950855  -0.666667   0.0                     0   \n",
       "\n",
       "   emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "0                   0                   1                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    1   \n",
       "2                   0                   0                    0   \n",
       "3                   0                   1                    0   \n",
       "4                   0                   0                    1   \n",
       "\n",
       "   emp_length_unknown  home_ownership_OTHER  home_ownership_OWN  \\\n",
       "0                   0                     0                   0   \n",
       "1                   0                     0                   0   \n",
       "2                   0                     0                   0   \n",
       "3                   0                     0                   0   \n",
       "4                   0                     0                   0   \n",
       "\n",
       "   home_ownership_RENT  verification_status_Source Verified  \\\n",
       "0                    0                                    0   \n",
       "1                    1                                    0   \n",
       "2                    0                                    0   \n",
       "3                    0                                    0   \n",
       "4                    1                                    1   \n",
       "\n",
       "   verification_status_Verified  purpose_credit_card  \\\n",
       "0                             1                    0   \n",
       "1                             1                    0   \n",
       "2                             0                    0   \n",
       "3                             1                    0   \n",
       "4                             0                    0   \n",
       "\n",
       "   purpose_debt_consolidation  purpose_educational  purpose_home_improvement  \\\n",
       "0                           1                    0                         0   \n",
       "1                           1                    0                         0   \n",
       "2                           1                    0                         0   \n",
       "3                           0                    0                         0   \n",
       "4                           1                    0                         0   \n",
       "\n",
       "   purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  \\\n",
       "0              0                       0                0               0   \n",
       "1              0                       0                0               0   \n",
       "2              0                       0                0               0   \n",
       "3              0                       0                0               0   \n",
       "4              0                       0                0               0   \n",
       "\n",
       "   purpose_other  purpose_renewable_energy  purpose_small_business  \\\n",
       "0              0                         0                       0   \n",
       "1              0                         0                       0   \n",
       "2              0                         0                       0   \n",
       "3              1                         0                       0   \n",
       "4              0                         0                       0   \n",
       "\n",
       "   purpose_vacation  purpose_wedding  addr_state_AL  addr_state_AR  \\\n",
       "0                 0                0              0              0   \n",
       "1                 0                0              0              0   \n",
       "2                 0                0              0              0   \n",
       "3                 0                0              0              0   \n",
       "4                 0                0              0              0   \n",
       "\n",
       "   addr_state_AZ  addr_state_CA  addr_state_CO  addr_state_CT  addr_state_DC  \\\n",
       "0              0              1              0              0              0   \n",
       "1              0              1              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              1              0              0              0              0   \n",
       "4              0              1              0              0              0   \n",
       "\n",
       "   addr_state_DE  addr_state_FL  addr_state_GA  addr_state_HI  addr_state_IA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_IL  addr_state_KS  addr_state_KY  addr_state_LA  addr_state_MA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_MD  addr_state_MI  addr_state_MN  addr_state_MO  addr_state_MS  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_MT  addr_state_NC  addr_state_NH  addr_state_NJ  addr_state_NM  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_NV  addr_state_NY  addr_state_OH  addr_state_OK  addr_state_OR  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_PA  addr_state_RI  addr_state_SC  addr_state_SD  addr_state_TN  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_TX  addr_state_UT  addr_state_VA  addr_state_VT  addr_state_WA  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              1              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   addr_state_WI  addr_state_WV  addr_state_WY  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('train_data_rescaled.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Unnamed: 0'], inplace = True, axis = 1)\n",
    "y_train.drop('Unnamed: 0', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train-Test-Split for Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a large data set, the train data is split once again to have an evaluation dataset for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(X_train, y_train, test_size = .2, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very imbalanced so we use the SMOTE (Synthetic Minority Oversampling Technique) method to address this issue. SMOTE synthesizes new datasets from the existing examples, oversampling the minority class (0 = charged off). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from imbalanced-learn) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/nf/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 16227\n",
      "Before OverSampling, counts of label '0': 2698 \n",
      "\n",
      "After OverSampling, the shape of train_X: (32454, 90)\n",
      "After OverSampling, the shape of train_y: (32454,) \n",
      "\n",
      "After OverSampling, counts of label '1': 16227\n",
      "After OverSampling, counts of label '0': 16227\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(ye_train.loan_status==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(ye_train.loan_status==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_smo, y_smo = sm.fit_sample(Xe_train, ye_train.values.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_smo.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_smo.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_smo==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_smo==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Baseline Model: Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier uses simple classification rules and is therefore useful as a simple baseline to compare with other (real) classifiers. It is not used for 'real' modelling. Since it is a baseline model, the original data wihtout SMOTE are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.14      0.14       675\n",
      "         1.0       0.86      0.86      0.86      4057\n",
      "\n",
      "    accuracy                           0.76      4732\n",
      "   macro avg       0.50      0.50      0.50      4732\n",
      "weighted avg       0.76      0.76      0.76      4732\n",
      "\n",
      "F beta Score for both classes:\n",
      "0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "#Define the Classifier and fit it to the train data\n",
    "dummy_clf = DummyClassifier(random_state = 2, strategy = 'stratified')\n",
    "dummy_clf.fit(Xe_train, ye_train)\n",
    "cv_results = cross_validate(dummy_clf, Xe_train, ye_train, cv=5, return_estimator = True)\n",
    "\n",
    "\n",
    "#Make predictions using cross-validation\n",
    "ye_pred = cross_val_predict(dummy_clf, Xe_test, ye_test, cv = 5)\n",
    "\n",
    "# Printing evaluation scores for the Dummy Classifier \n",
    "print(classification_report(ye_test, ye_pred))\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .2, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is imbalanced, it does not make sense to interpret accuracy but to focus recall and precision (or the f1 score). Here one can see that the model is good at predicting whether a person will pay back. But, since this class is underrepresented, the model fails to predict incomplete paybacks which is bad since for an investor for he will lose his money. This results in a bad overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the best 5 resp. 10 features by using the SelectKBest tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit selector\n",
    "best_features = SelectKBest(mutual_info_classif, k=5)\n",
    "X_smo_5 = best_features.fit_transform(X_smo, np.array(y_smo).ravel())\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = best_features.get_support(indices=True)\n",
    "X_smo_5 = X_smo.iloc[:,cols]\n",
    "X_smo_5 = pd.DataFrame(X_smo_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.607143</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.688034</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.025510</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>-0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198980</td>\n",
       "      <td>-0.262681</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>-1.094203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.914530</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  open_acc  revol_util  total_acc\n",
       "0  -0.607143 -0.213768  0.833333    0.688034   0.466667\n",
       "1   1.025510 -0.891304  0.500000   -0.241453   0.666667\n",
       "2  -0.709184 -0.125000 -1.000000    0.108974  -0.533333\n",
       "3  -0.198980 -0.262681 -0.333333    0.230769  -0.600000\n",
       "4   0.387755 -1.094203  1.000000   -0.914530   1.066667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit selector\n",
    "best_features = SelectKBest(mutual_info_classif, k=12)\n",
    "X_smo_10 = best_features.fit_transform(X_smo, np.array(y_smo).ravel())\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = best_features.get_support(indices=True)\n",
    "X_smo_10 = X_smo.iloc[:,cols]\n",
    "X_smo_10 = pd.DataFrame(X_smo_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.607143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>-0.572486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.371154</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.688034</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.025510</td>\n",
       "      <td>1.061224</td>\n",
       "      <td>-0.891304</td>\n",
       "      <td>0.449072</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.2999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.131731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.241453</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.709184</td>\n",
       "      <td>-0.673469</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.695438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7749</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>-0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198980</td>\n",
       "      <td>-0.163265</td>\n",
       "      <td>-0.262681</td>\n",
       "      <td>-0.073933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6749</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.423469</td>\n",
       "      <td>-1.094203</td>\n",
       "      <td>0.533225</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.2501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.914530</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  int_rate  installment  grade  annual_inc  issue_d  \\\n",
       "0  -0.607143    -0.571429 -0.213768    -0.572486    0.0      0.8001      0.0   \n",
       "1   1.025510     1.061224 -0.891304     0.449072   -0.5     -0.2999     -1.0   \n",
       "2  -0.709184    -0.673469 -0.125000    -0.695438    0.0     -0.7749     -2.0   \n",
       "3  -0.198980    -0.163265 -0.262681    -0.073933    0.0     -0.6749     -1.0   \n",
       "4   0.387755     0.423469 -1.094203     0.533225   -0.5      1.2501      0.0   \n",
       "\n",
       "        dti  inq_last_6mths  open_acc  revol_util  total_acc  \n",
       "0 -0.371154            -1.0  0.833333    0.688034   0.466667  \n",
       "1 -1.131731             0.0  0.500000   -0.241453   0.666667  \n",
       "2  0.119231            -1.0 -1.000000    0.108974  -0.533333  \n",
       "3  0.975000             1.0 -0.333333    0.230769  -0.600000  \n",
       "4  0.604808             1.0  1.000000   -0.914530   1.066667  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue_d is dropped because it has no predictive value for the target taking into account that an investor will only know the current year a borrower begs for money.\n",
    "loan_amnt is dropped because it's redundant to funded_amnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smo_10.drop(['issue_d', 'loan_amnt'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amnt', 'int_rate', 'installment', 'grade', 'annual_inc', 'dti',\n",
       "       'inq_last_6mths', 'open_acc', 'revol_util', 'total_acc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smo_10.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt the test data with the corresponding variables\n",
    "X_test_5 = Xe_test[['int_rate', 'loan_amnt', 'open_acc', 'revol_util', 'total_acc']]\n",
    "X_test_10 = Xe_test[['funded_amnt', 'int_rate', 'installment', 'grade', 'annual_inc', 'dti',\n",
    "       'inq_last_6mths', 'open_acc', 'revol_util', 'total_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smo_5.to_csv('X_smo_5.csv')\n",
    "X_smo_10.to_csv('X_smo_10.csv')\n",
    "pd.DataFrame(y_smo).to_csv('y_smo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Logistic Regression Model 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(penalty = 'elasticnet', solver = 'saga', n_jobs = -1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GridSearchCV to identify the best logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.9s\n",
      "[CV] max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.5s\n",
      "[CV] max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=9168, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.5s\n",
      "[CV] max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.5s\n",
      "[CV] max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=8982, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=5196, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=1337, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.603, total=   0.1s\n",
      "[CV] max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.612, total=   0.1s\n",
      "[CV] max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.607, total=   0.1s\n",
      "[CV] max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.605, total=   0.1s\n",
      "[CV] max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1 .\n",
      "[CV]  max_iter=7114, l1_ratio=0, class_weight={0: 0.6, 1: 0.4}, C=0.1, score=0.605, total=   0.1s\n",
      "[CV] max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.545, total=   0.1s\n",
      "[CV] max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.539, total=   0.1s\n",
      "[CV] max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.545, total=   0.1s\n",
      "[CV] max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.542, total=   0.1s\n",
      "[CV] max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1 .\n",
      "[CV]  max_iter=8819, l1_ratio=0, class_weight={0: 0.3, 1: 0.7}, C=0.1, score=0.540, total=   0.1s\n",
      "[CV] max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.620, total=   0.1s\n",
      "[CV] max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.618, total=   0.1s\n",
      "[CV] max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.622, total=   0.1s\n",
      "[CV] max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.617, total=   0.1s\n",
      "[CV] max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8659, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.620, total=   0.1s\n",
      "[CV] max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.576, total=   0.1s\n",
      "[CV] max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.581, total=   0.1s\n",
      "[CV] max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.576, total=   0.1s\n",
      "[CV] max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.578, total=   0.1s\n",
      "[CV] max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=4091, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.577, total=   0.1s\n",
      "[CV] max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=8498, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.1s\n",
      "[CV] max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.505, total=   0.1s\n",
      "[CV] max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.501, total=   0.1s\n",
      "[CV] max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.503, total=   0.1s\n",
      "[CV] max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1 .\n",
      "[CV]  max_iter=1323, l1_ratio=0, class_weight={0: 0.2, 1: 0.8}, C=0.1, score=0.502, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                                random_state=0, solver='saga'),\n",
       "                   param_distributions={'C': array([0.1]),\n",
       "                                        'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'l1_ratio': array([0]),\n",
       "                                        'max_iter': array([1000, 1001, 1002, ..., 9997, 9998, 9999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'C': np.arange(0.1,1),\n",
    "             'max_iter': np.arange(1000, 10000),\n",
    "             'l1_ratio': np.arange(0, 1), \n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid = RandomizedSearchCV(log_clf, param_grid, cv = 5, verbose = 5)\n",
    "grid.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 8659, 'l1_ratio': 0, 'class_weight': {0: 0.5, 1: 0.5}, 'C': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_5 = grid.best_params_\n",
    "best_log_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the best model to the data with 5 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_5 = LogisticRegression(C=0.1, class_weight= {0: 0.3, 1: 0.7}, l1_ratio=0, max_iter=8322,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')\n",
    "best_log_5.fit(X_smo_5, y_smo)\n",
    "ye_pred = best_log_5.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Logistic Regression Model 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_iter=8071, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=2163, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.640, total=   0.2s\n",
      "[CV] max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.654, total=   0.2s\n",
      "[CV] max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.648, total=   0.2s\n",
      "[CV] max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=8897, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=4846, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.501, total=   0.2s\n",
      "[CV] max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1 \n",
      "[CV]  max_iter=8462, l1_ratio=0, class_weight={0: 0.95, 1: 0.05}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1 .\n",
      "[CV]  max_iter=6765, l1_ratio=0, class_weight={0: 0.9, 1: 0.1}, C=0.1, score=0.504, total=   0.2s\n",
      "[CV] max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.588, total=   0.2s\n",
      "[CV] max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.599, total=   0.2s\n",
      "[CV] max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.595, total=   0.2s\n",
      "[CV] max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.597, total=   0.2s\n",
      "[CV] max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1 .\n",
      "[CV]  max_iter=7815, l1_ratio=0, class_weight={0: 0.7, 1: 0.3}, C=0.1, score=0.600, total=   0.2s\n",
      "[CV] max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.640, total=   0.2s\n",
      "[CV] max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.654, total=   0.2s\n",
      "[CV] max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.648, total=   0.2s\n",
      "[CV] max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1 .\n",
      "[CV]  max_iter=1899, l1_ratio=0, class_weight={0: 0.5, 1: 0.5}, C=0.1, score=0.651, total=   0.2s\n",
      "[CV] max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1 .\n",
      "[CV]  max_iter=6535, l1_ratio=0, class_weight={0: 0.1, 1: 0.9}, C=0.1, score=0.500, total=   0.2s\n",
      "[CV] max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.623, total=   0.1s\n",
      "[CV] max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.621, total=   0.2s\n",
      "[CV] max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.623, total=   0.2s\n",
      "[CV] max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.619, total=   0.2s\n",
      "[CV] max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1 .\n",
      "[CV]  max_iter=3324, l1_ratio=0, class_weight={0: 0.4, 1: 0.6}, C=0.1, score=0.617, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LogisticRegression(n_jobs=-1, penalty='elasticnet',\n",
       "                                                random_state=0, solver='saga'),\n",
       "                   param_distributions={'C': array([0.1]),\n",
       "                                        'class_weight': [{0: 0.1, 1: 0.9},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         {0: 0.3, 1: 0.7},\n",
       "                                                         {0: 0.4, 1: 0.6},\n",
       "                                                         {0: 0.5, 1: 0.5},\n",
       "                                                         {0: 0.6, 1: 0.4},\n",
       "                                                         {0: 0.7, 1: 0.3},\n",
       "                                                         {0: 0.8, 1: 0.2},\n",
       "                                                         {0: 0.85, 1: 0.15},\n",
       "                                                         {0: 0.9, 1: 0.1},\n",
       "                                                         {0: 0.95, 1: 0.05}],\n",
       "                                        'l1_ratio': array([0]),\n",
       "                                        'max_iter': array([1000, 1001, 1002, ..., 9997, 9998, 9999])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'C': np.arange(0.1,1),\n",
    "             'max_iter': np.arange(1000, 10000),\n",
    "             'l1_ratio': np.arange(0, 1), \n",
    "             'class_weight': [{0: 0.1,1:0.9}, {0:0.2,1:0.8}, {0:0.3,1:0.7}, {0:0.4,1:0.6}, \n",
    "                              {0:0.5,1:0.5}, {0:0.6,1:0.4}, {0:0.7,1:0.3}, {0: 0.8, 1:0.2}, {0: 0.85, 1:0.15}, \n",
    "                              {0: 0.9, 1:0.10}, {0: 0.95, 1: 0.05}]}\n",
    "grid = RandomizedSearchCV(log_clf, param_grid, cv = 5, verbose = 5)\n",
    "grid.fit(X_smo_10, y_smo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 8897, 'l1_ratio': 0, 'class_weight': {0: 0.5, 1: 0.5}, 'C': 0.1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_10 = grid.best_params_\n",
    "best_log_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_10 = LogisticRegression(C=0.1, class_weight={0: 0.5, 1: 0.5}, l1_ratio=0, max_iter=7812,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')\n",
    "best_log_10.fit(X_smo_10, y_smo)\n",
    "ye_pred = best_log_10.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with more features is better. Next, we'll try a KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 K-Nearest-Neighbours 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use RandomizedSearchCV to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.730, total=   0.4s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.713, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.715, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.709, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.712, total=   0.3s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.770, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.755, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.756, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.750, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=manhattan ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=manhattan, score=0.758, total=   0.2s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.756, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.730, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.727, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=10, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=10, metric=euclidean, score=0.733, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.757, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.731, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.737, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.732, total=   0.1s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.731, total=   0.1s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.640, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.653, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.668, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.694, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.690, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.689, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.685, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.692, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.640, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.656, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.653, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.668, total=   0.3s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.730, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.713, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.715, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.709, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=euclidean ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=euclidean, score=0.712, total=   0.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.637, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.659, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.657, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.668, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.671, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.651, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.679, total=   0.4s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.677, total=   0.4s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.671, total=   0.4s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.690, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(n_jobs=-1),\n",
       "                   param_distributions={'metric': ['euclidean', 'manhattan',\n",
       "                                                   'minkowski'],\n",
       "                                        'n_neighbors': [5, 10, 50, 100],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "             'weights': ['uniform','distance'],\n",
    "            'n_neighbors': [5, 10, 50, 100],}\n",
    "\n",
    "grid = RandomizedSearchCV(knn_clf, param_grid, cv = 5, verbose = 5)\n",
    "grid.fit(X_smo_5, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 10, 'metric': 'manhattan'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_5 = grid.best_params_\n",
    "best_knn_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_5 = KNeighborsClassifier(n_jobs = -1, n_neighbors = 5, metric = 'manhattan', weights = 'uniform')\n",
    "best_knn_5.fit(X_smo_5, y_smo)\n",
    "ye_pred = best_knn_5.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .2, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's nothing. Let's try our best 10 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 K-Nearest-Neighbours 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.730, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.746, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.733, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.739, total=   0.6s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=minkowski ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=uniform, n_neighbors=10, metric=minkowski, score=0.738, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.782, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.793, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.786, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.793, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=5, metric=minkowski ................\n",
      "[CV]  weights=uniform, n_neighbors=5, metric=minkowski, score=0.782, total=   0.5s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.657, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.701, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.689, total=   1.4s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.691, total=   1.5s\n",
      "[CV] weights=uniform, n_neighbors=100, metric=manhattan ..............\n",
      "[CV]  weights=uniform, n_neighbors=100, metric=manhattan, score=0.691, total=   1.3s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=manhattan, score=0.752, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=manhattan, score=0.778, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=manhattan, score=0.763, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=manhattan, score=0.765, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=10, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=10, metric=manhattan, score=0.759, total=   0.8s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.723, total=   0.6s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.746, total=   0.6s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.729, total=   0.8s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.739, total=   0.6s\n",
      "[CV] weights=distance, n_neighbors=50, metric=euclidean ..............\n",
      "[CV]  weights=distance, n_neighbors=50, metric=euclidean, score=0.731, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.658, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.693, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.680, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.686, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=minkowski ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=minkowski, score=0.682, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.658, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.693, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.680, total=   0.8s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.686, total=   0.7s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=euclidean ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=euclidean, score=0.682, total=   0.8s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.722, total=   1.1s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.749, total=   1.2s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.736, total=   1.2s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.743, total=   1.1s\n",
      "[CV] weights=distance, n_neighbors=100, metric=manhattan .............\n",
      "[CV]  weights=distance, n_neighbors=100, metric=manhattan, score=0.743, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.676, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.713, total=   1.3s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.716, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.709, total=   1.2s\n",
      "[CV] weights=uniform, n_neighbors=50, metric=manhattan ...............\n",
      "[CV]  weights=uniform, n_neighbors=50, metric=manhattan, score=0.713, total=   1.2s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.805, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.809, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.796, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.806, total=   0.4s\n",
      "[CV] weights=distance, n_neighbors=5, metric=euclidean ...............\n",
      "[CV]  weights=distance, n_neighbors=5, metric=euclidean, score=0.794, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   40.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5, 'metric': 'euclidean'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "             'weights': ['uniform','distance'],\n",
    "            'n_neighbors': [5, 10, 50, 100],}\n",
    "\n",
    "grid = RandomizedSearchCV(knn_clf, param_grid, cv = 5, verbose= 5)\n",
    "grid.fit(X_smo_10, y_smo)\n",
    "best_knn_10 = grid.best_params_\n",
    "best_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5, 'metric': 'euclidean'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_10 = grid.best_params_\n",
    "best_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_10 = KNeighborsClassifier(n_jobs = -1, n_neighbors = 50, metric = 'manhattan', weights = 'distance')\n",
    "best_knn_10.fit(X_smo_10, y_smo)\n",
    "ye_pred = best_knn_10.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Ensemble: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best of the base models above, the logistic regression with 10 features are now boosted in the hope that this improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log = LogisticRegression(C=0.1, class_weight={0: 0.5, 1: 0.5}, l1_ratio=0, max_iter=7812,\n",
    "                   n_jobs=-1, penalty='elasticnet', random_state=0,\n",
    "                   solver='saga')\n",
    "best_log.fit(X_smo_10, y_smo)\n",
    "ye_pred = best_log.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=64, learning_rate=0.1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=64, learning_rate=0.1, score=0.629, total=  18.6s\n",
      "[CV] n_estimators=64, learning_rate=0.1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=64, learning_rate=0.1, score=0.642, total=  18.8s\n",
      "[CV] n_estimators=64, learning_rate=0.1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   37.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=64, learning_rate=0.1, score=0.633, total=  18.2s\n",
      "[CV] n_estimators=64, learning_rate=0.1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   55.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=64, learning_rate=0.1, score=0.634, total=  18.4s\n",
      "[CV] n_estimators=64, learning_rate=0.1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. n_estimators=64, learning_rate=0.1, score=0.629, total=  19.5s\n",
      "[CV] n_estimators=7, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=7, learning_rate=0.1, score=0.625, total=   2.1s\n",
      "[CV] n_estimators=7, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=7, learning_rate=0.1, score=0.638, total=   2.2s\n",
      "[CV] n_estimators=7, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=7, learning_rate=0.1, score=0.631, total=   2.1s\n",
      "[CV] n_estimators=7, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=7, learning_rate=0.1, score=0.634, total=   2.1s\n",
      "[CV] n_estimators=7, learning_rate=0.1 ...............................\n",
      "[CV] ... n_estimators=7, learning_rate=0.1, score=0.629, total=   2.0s\n",
      "[CV] n_estimators=35, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=35, learning_rate=0.1, score=0.627, total=  10.5s\n",
      "[CV] n_estimators=35, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=35, learning_rate=0.1, score=0.641, total=  10.6s\n",
      "[CV] n_estimators=35, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=35, learning_rate=0.1, score=0.632, total=  10.6s\n",
      "[CV] n_estimators=35, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=35, learning_rate=0.1, score=0.636, total=  10.3s\n",
      "[CV] n_estimators=35, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=35, learning_rate=0.1, score=0.629, total=  10.6s\n",
      "[CV] n_estimators=47, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=47, learning_rate=0.1, score=0.628, total=  14.0s\n",
      "[CV] n_estimators=47, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=47, learning_rate=0.1, score=0.642, total=  13.7s\n",
      "[CV] n_estimators=47, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=47, learning_rate=0.1, score=0.633, total=  14.0s\n",
      "[CV] n_estimators=47, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=47, learning_rate=0.1, score=0.635, total=  13.3s\n",
      "[CV] n_estimators=47, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=47, learning_rate=0.1, score=0.628, total=  13.1s\n",
      "[CV] n_estimators=46, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=46, learning_rate=0.1, score=0.628, total=  12.2s\n",
      "[CV] n_estimators=46, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=46, learning_rate=0.1, score=0.642, total=  12.7s\n",
      "[CV] n_estimators=46, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=46, learning_rate=0.1, score=0.633, total=  12.6s\n",
      "[CV] n_estimators=46, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=46, learning_rate=0.1, score=0.635, total=  12.7s\n",
      "[CV] n_estimators=46, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=46, learning_rate=0.1, score=0.628, total=  12.9s\n",
      "[CV] n_estimators=87, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=87, learning_rate=0.1, score=0.629, total=  24.2s\n",
      "[CV] n_estimators=87, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=87, learning_rate=0.1, score=0.641, total=  24.1s\n",
      "[CV] n_estimators=87, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=87, learning_rate=0.1, score=0.633, total=  24.2s\n",
      "[CV] n_estimators=87, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=87, learning_rate=0.1, score=0.632, total=  24.2s\n",
      "[CV] n_estimators=87, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=87, learning_rate=0.1, score=0.630, total=  24.3s\n",
      "[CV] n_estimators=67, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=67, learning_rate=0.1, score=0.629, total=  18.5s\n",
      "[CV] n_estimators=67, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=67, learning_rate=0.1, score=0.642, total=  18.7s\n",
      "[CV] n_estimators=67, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=67, learning_rate=0.1, score=0.633, total=  18.5s\n",
      "[CV] n_estimators=67, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=67, learning_rate=0.1, score=0.632, total=  18.6s\n",
      "[CV] n_estimators=67, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=67, learning_rate=0.1, score=0.629, total=  19.6s\n",
      "[CV] n_estimators=138, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=138, learning_rate=0.1, score=0.632, total=  49.2s\n",
      "[CV] n_estimators=138, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=138, learning_rate=0.1, score=0.643, total=  42.4s\n",
      "[CV] n_estimators=138, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=138, learning_rate=0.1, score=0.633, total=  41.9s\n",
      "[CV] n_estimators=138, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=138, learning_rate=0.1, score=0.630, total=  40.8s\n",
      "[CV] n_estimators=138, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=138, learning_rate=0.1, score=0.630, total=  41.3s\n",
      "[CV] n_estimators=10, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=10, learning_rate=0.1, score=0.625, total=   3.0s\n",
      "[CV] n_estimators=10, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=10, learning_rate=0.1, score=0.638, total=   3.2s\n",
      "[CV] n_estimators=10, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=10, learning_rate=0.1, score=0.631, total=   3.2s\n",
      "[CV] n_estimators=10, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=10, learning_rate=0.1, score=0.635, total=   3.2s\n",
      "[CV] n_estimators=10, learning_rate=0.1 ..............................\n",
      "[CV] .. n_estimators=10, learning_rate=0.1, score=0.629, total=   2.8s\n",
      "[CV] n_estimators=113, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=113, learning_rate=0.1, score=0.630, total=  31.5s\n",
      "[CV] n_estimators=113, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=113, learning_rate=0.1, score=0.641, total=  31.8s\n",
      "[CV] n_estimators=113, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=113, learning_rate=0.1, score=0.633, total=  34.0s\n",
      "[CV] n_estimators=113, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=113, learning_rate=0.1, score=0.631, total=  34.8s\n",
      "[CV] n_estimators=113, learning_rate=0.1 .............................\n",
      "[CV] . n_estimators=113, learning_rate=0.1, score=0.629, total=  35.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=AdaBoostClassifier(base_estimator=LogisticRegression(C=0.1,\n",
       "                                                                                  class_weight={0: 0.5,\n",
       "                                                                                                1: 0.5},\n",
       "                                                                                  l1_ratio=0,\n",
       "                                                                                  max_iter=7812,\n",
       "                                                                                  n_jobs=-1,\n",
       "                                                                                  penalty='elasticnet',\n",
       "                                                                                  random_state=0,\n",
       "                                                                                  solver='saga')),\n",
       "                   param_distributions={'learning_rate': array([0.1]),\n",
       "                                        'n_estimators': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  2...\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer \n",
    "\n",
    "clf_boost = AdaBoostClassifier(base_estimator=best_log) \n",
    "\n",
    "param_grid = {'n_estimators':np.arange(1, 150),                \n",
    "              'learning_rate':np.arange(0.1, 1),                          \n",
    "             } \n",
    "grid = RandomizedSearchCV(clf_boost, param_grid, verbose = 5) \n",
    "grid.fit(X_smo_10, y_smo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 138, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_boost_model = grid.best_params_\n",
    "best_boost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boost = AdaBoostClassifier(base_estimator=best_log, n_estimators = 43, learning_rate = 0.1) \n",
    "best_boost.fit(X_smo_10, y_smo)\n",
    "ye_pred = best_boost.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdaBoost is worse than the best logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Ensemble: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsClassifier(n_jobs = -1, n_neighbors = 50, metric = 'manhattan', weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('bestlog', best_log), \n",
    "    ('bestknn', best_knn)]\n",
    "model = StackingClassifier(estimators, final_estimator=LogisticRegression(), cv=5, \n",
    "                           stack_method='auto', n_jobs=-1, verbose=5)\n",
    "model.fit(X_smo_10, y_smo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F beta Score for both classes:\n",
      "0.78\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd90lEQVR4nO3de7xNdf7H8dfn3CIckUsckkoXFE2l+tGMbuiKSqkpKqUpuk9Tut80TYVGF41SqFyTIVFJmi4jUpGQnEnlctzlUo2cvT+/P/bKbBz77MPhLKv3s8f3sff+ru9a37U4fc7HZ3333ubuiIhIuGSU9QmIiMi2FJxFREJIwVlEJIQUnEVEQkjBWUQkhLJ2+QQ5eVoOItuoW6laWZ+ChNCCVTNtZ4+xaeU3acec7GoH7vR8u4oyZxGRENrlmbOIyG4Vj5X1GZQKBWcRiZZYYVmfQalQcBaRSHGPl/UplAoFZxGJlriCs4hI+ChzFhEJId0QFBEJIWXOIiLh41qtISISQhG5Iah3CIpItHg8/ZaCmZUzs2lmNtPMZpvZ/UF/VTObaGbzg8cqSfv0MLN8M5tnZq2T+o82s1nBtr5mVuzbxhWcRSRa4rH0W2obgZPdvQnQFGhjZscDtwOT3L0BMCl4jZk1BDoCjYA2wDNmlhkcqx/QFWgQtDbFTa7gLCLRUkqZsydsCF5mB82BtsCgoH8Q0C543hYY5u4b3X0BkA80M7NaQK67T/HE9wIOTtpnu1RzFpFoKcUbgkHm+ylwMPC0u081s5ruXgDg7gVmViMYngd8nLT7oqBvU/B86/6UlDmLSLTE42k3M+tqZtOTWtfkQ7l7zN2bAnVIZMGNU8xcVB3ZU/SnpMxZRCLFPf03obh7f6B/GuN+MLP3SNSKl5lZrSBrrgUsD4YtAuom7VYHWBL01ymiPyVlziISLaW3WqO6me0TPC8PnAp8BYwFOgfDOgNjgudjgY5mtpeZ1Sdx429aUAJZb2bHB6s0OiXts13KnEUkWkpvnXMtYFBQd84ARrj7ODObAowwsy7A90AHAHefbWYjgDlAIdDN/5fGXwMMBMoDE4KWkiVuHu46+poqKYq+pkqKUhpfU/XfT/+Zdswpd3S70H5NlTJnEYmW2KayPoNSoeAsItESkbdvKziLSLToU+lEREJImbOISAgpOIuIhI/rhqCISAip5iwiEkIqa4iIhJAyZxGREFLmLCISQsqcRURCqFDfvi0iEj7KnEVEQkg1ZxGREFLmLCISQsqcRURCSJmziEgIabWGiEgI7eKv3ttdFJxFJFpUcxYRCSEFZxGRENINQRGREIrFyvoMSoWCs4hEi8oaIiIhpOAsIhJCqjmLiISPx7XOWUQkfCJS1sgo6xMQESlVsVj6LQUzq2tmk81srpnNNrMbgv77zGyxmc0I2hlJ+/Qws3wzm2dmrZP6jzazWcG2vmZmxV2GMmcRiZbSy5wLgVvc/TMzqwR8amYTg2193P3x5MFm1hDoCDQCagPvmNkh7h4D+gFdgY+B8UAbYEKqyZU5i0i0xOPptxTcvcDdPwuerwfmAnkpdmkLDHP3je6+AMgHmplZLSDX3ae4uwODgXbFXYaC83bUqVObd94eyawv3mPmjHe5rnuXbcYceuhBfPj+WH5c/w0333R1qcybk5PDkFf68dWcD/n3h69Tr14dAJo0acSH749l5ox3+ezTiXTocE6pzCc7JiMjg3GTh/P8kCeL3H5c82N4473hvPXRawwbO2Cn58vJyebJ5x9l8ievM/rtl8mrWxuAwxsfyqg3B/PWR68x4f2RnNmudTFH+g1wT7uZWVczm57UuhZ1SDM7ADgKmBp0dTezL8zsBTOrEvTlAQuTdlsU9OUFz7fuT0nBeTsKCwu59S/3c8SRLWne4myuueYyDj+8wRZjVq/+gRtvupveff5R4uPXq1eHSRNHbtN/xeUXsWbNWg5r2IIn+j7HXx++E4CffvqZy664gSZNT+bMsy6h9+P3Ubly7o5dnOy0y6/+I/lff1Pktkq5lXjwsTu46o830Lr5uXS74ta0j5tXtzZDxzy/Tf8Fl7Rn7Q/rOOnYsxnQ72Vuv/dGAP7783+55dq7aN38XDpfcC339LyVSrmVduiaIqMEmbO793f3Y5Ja/60PZ2YVgVHAje6+jkSJ4iCgKVAA9Pp1aBFn4yn6Uyo2OJvZYWZ2W1DE/nvw/PDi9tvTLV26nM9nfAnAhg0/8tVX88mrvd8WY1asWMX0T2eyadOmbfa/+OJzmfLROKZ/8jbPPP03MjLS+z14ztmteOmlRNAeNeoNTj6pBQDz539Dfv4CAAoKlrF8xSqqV993h69Pdtx+tWtwUqsTGf7y6CK3tz3/dN4aN4kli5cCsGrl6s3b2nU4k39OfIU33htOz153p/1zcdrpJzFq2FgAJoydyP/9vhkAC/7zHd9+8z0Ay5euYNXK1exbrcp2j/ObEPf0WzHMLJtEYH7F3V8DcPdl7h5z9zjwHNAsGL4IqJu0ex1gSdBfp4j+lFL+ZJjZbcAwEpF/GvBJ8Hyomd1e7JVFRL16dWjapDFTp32e1vjDDjuYCzqcw4l/aMcxx7YiFotx8cXnprVv7bz9WLgo8fcWi8VYu3Yd++675f9sxx7TlJycbP7zn29LdB1SOu7p+Rceua8P8e3ULOsfVI/K++QydMzzjJ00lHMvPAuAgw6pz1ntWnP+6Z05s+WFxOIx2nU4o8hjbK1mrRoULEkE+1gsxvp1G6hSdZ8txjT5XWOyc7L5bsHCIo7wG1J6qzUMGADMdffeSf21koa1B74Mno8FOprZXmZWH2gATHP3AmC9mR0fHLMTMKa4yyhutUYXoJG7b5EamllvYDbwyHYuqiuJO5NYZmUyMioUdx6hVaHC3owY/hw3//le1q/fkNY+J5/Ugt8ddQQfTxkPQPny5VixYiUAr458ngMO2J+cnGz2r5vH9E/eBuDJJ59n0OARFLXCJvmzw/fbrwYDB/bliituxCPyoeJ7kpNb/Z6VK1fz5cy5HNf8mCLHZGVl0bhJQ/7Yvivlyu3FqDcH8/n0WTT//XE0bno4Y955BYBy5cuxakUiq352cB/q7l+b7JxsaufV4o33hgPwYv8hvDpkzHZ+Lv7391+9ZjV69+vJLd3u+s3/XHjprdZoDlwKzDKzGUHfHcBFZtaURGniW+BqAHefbWYjgDkkVnp0C1ZqAFwDDATKk1ilkXKlBhQfnOMkloR8t1V/rWBbkYK6TX+ArJy8PfYnJSsri5HDn2Po0NH885/F/lluZma89PJI7rxr299d53e4Ekhk4y8834dTTuuwxfbFiwqoW6c2ixcXkJmZSeXKuaxevQaASpUqMnbMYO6591GmTvtsJ65MdtTRxzXl1DYtOenUFuy1115UrFSBPs8+zE1/umPzmIIly1i9ag0///QzP//0M9OmfMbhjQ7BzBg17HUee7DvNsf9U6ebgETN+fGnHuCitldusX3pkmXUqr0fS5csJzMzk0q5FflhzVoAKlaqwAtDn6JXz6eYMX3WLrz6PUQpvUPQ3T+k6Hrx+BT79AR6FtE/HWhckvmLK3jdCEwyswlm1j9obwKTgBtKMtGe6Ln+vZj7VT5P/H2bewQpvTv5Q85tf9bmmnCVKvuw//7F3pwF4PVxb3PppYmAfd55ZzL5vY8AyM7OZtTIAbz88quMGjWuROcjpeexB/vyf0e04sSjzuC6q27j3x98skVgBpg4YTLHnvA7MjMzKVe+HE2PPoL8rxfw0ftTOf3sU9m3WlUAKu+TS16dWkVNs4133nyP8zomVuicfs5pTPlgGgDZ2Vk8O7gPrw1/nfFjJ6Y6xG+Hx9NvIZYyc3b3N83sEBIF7zwSv0UWAZ8kpeuR1Pz/juXSS87ni1lzNpce7r77EerWTQTZ/s+9RM2a1Zk6ZQK5uRWJx+Ncf91VHNGkJXPnzuee+x5lwvihZGQYmzYVcv31d/L994uLnfeFF4cxaGBfvprzIWvW/MDFl1wLQIcOZ3PiicdRdd8qdOp0AQBdrryJmTNn76I/ASmJiy9L/EIdMnAk//l6Ae9P+ogJH4wkHneGv/QaX3+VD0Cvh59m8Kv9yMjIYNOmQu657WEWLyoo9vjDXx5Nn349mfzJ66z9YR3XXfkXAM5s15pmJ/yOKlUqc/5FieD95+73MPfLebvoSvcAEflsDdvV9ak9uawhu07dStXK+hQkhBasmlns25qL8+M9HdOOORUeGLbT8+0qevu2iERLyMsV6VJwFpFoiUhZQ8FZRCKlFJfSlSkFZxGJFmXOIiIhpOAsIhJCxbwte0+h4CwikaLvEBQRCSMFZxGRENJqDRGREFLmLCISQgrOIiLh4zGVNUREwkeZs4hI+GgpnYhIGCk4i4iEUDRKzgrOIhItXhiN6KzgLCLREo3YrOAsItGiG4IiImGkzFlEJHyUOYuIhJEyZxGR8PHCsj6D0qHgLCKR4hHJnDPK+gREREpVvAQtBTOra2aTzWyumc02sxuC/qpmNtHM5gePVZL26WFm+WY2z8xaJ/UfbWazgm19zcyKuwwFZxGJFI+n34pRCNzi7ocDxwPdzKwhcDswyd0bAJOC1wTbOgKNgDbAM2aWGRyrH9AVaBC0NsVNruAsIpFSWsHZ3Qvc/bPg+XpgLpAHtAUGBcMGAe2C522BYe6+0d0XAPlAMzOrBeS6+xR3d2Bw0j7bpZqziESKx4qtGGxmZl1JZLS/6u/u/YsYdwBwFDAVqOnuBZAI4GZWIxiWB3yctNuioG9T8Hzr/pQUnEUkUkpyQzAIxNsE42RmVhEYBdzo7utSlIuL2uAp+lNScBaRSPF4+plzccwsm0RgfsXdXwu6l5lZrSBrrgUsD/oXAXWTdq8DLAn66xTRn5JqziISKaVVcw5WVAwA5rp776RNY4HOwfPOwJik/o5mtpeZ1Sdx429aUAJZb2bHB8fslLTPdilzFpFIcS+1zLk5cCkwy8xmBH13AI8AI8ysC/A90CExr882sxHAHBIrPbq5eyzY7xpgIFAemBC0lBScRSRSSutNKO7+IUXXiwFO2c4+PYGeRfRPBxqXZH4FZxGJlHgJVmuEmYKziERKad4QLEsKziISKQrOIiIh5NH4OGcFZxGJFmXOIiIhVIpL6cqUgrOIREpMqzVERMJHmbOISAip5iwiEkJarSEiEkLKnEVEQigWj8aHbSo4i0ikqKwhIhJCca3WEBEJHy2lExEJIZU10tSu1tG7egrZAw399ImyPgWJKJU1RERCSKs1RERCKCJVDQVnEYkWlTVEREJIqzVEREKolL58u8wpOItIpDjKnEVEQqdQZQ0RkfBR5iwiEkKqOYuIhJAyZxGREIpK5hyN9zmKiARiWNqtOGb2gpktN7Mvk/ruM7PFZjYjaGckbethZvlmNs/MWif1H21ms4Jtfc2s2MkVnEUkUuKWfkvDQKBNEf193L1p0MYDmFlDoCPQKNjnGTPLDMb3A7oCDYJW1DG3oOAsIpESx9JuxXH394HVaU7dFhjm7hvdfQGQDzQzs1pArrtPcXcHBgPtijuYgrOIRIqXoJlZVzObntS6pjlNdzP7Iih7VAn68oCFSWMWBX15wfOt+1NScBaRSImXoLl7f3c/Jqn1T2OKfsBBQFOgAOgV9BeVinuK/pS0WkNEIiVe/L22neLuy359bmbPAeOCl4uAuklD6wBLgv46RfSnpMxZRCIlVoK2I4Ia8q/aA7+u5BgLdDSzvcysPokbf9PcvQBYb2bHB6s0OgFjiptHmbOIREqaqzDSYmZDgZZANTNbBNwLtDSzpiRKE98CVwO4+2wzGwHMAQqBbu7+6++Aa0is/CgPTAhaSgrOIhIp6azCSJe7X1RE94AU43sCPYvonw40LsncCs4iEin6mioRkRAqzbJGWVJwFpFIicpnayg4i0ikxJQ5i4iEjzJnEZEQUnAWEQmhiHyFoIKziESLMmcRkRDa0bdlh42Cs4hEitY5i4iEkMoaIiIhpOAsIhJC+mwNEZEQUs1ZRCSEtFpDRCSE4hEpbCg4i0ik6IagiEgIRSNvVnAWkYhR5iwiEkKFFo3cWcFZRCIlGqFZwVlEIkZlDRGRENJSOhGREIpGaFZwFpGIUVlDRCSEYhHJnRWcRSRSopI5Z5T1CYiIlCYvwX/FMbMXzGy5mX2Z1FfVzCaa2fzgsUrSth5mlm9m88ysdVL/0WY2K9jW18yK/ew8BWcRiZR4CVoaBgJttuq7HZjk7g2AScFrzKwh0BFoFOzzjJllBvv0A7oCDYK29TG3obJGCmd1OYdTOrbC3fn+q+94+ta/s2njpi3GNDq+MZfdcyVZ2VmsW72Oey+8Y6fmzMrJ4rreN3HgEQezYc06end/jBWLlnNAw/pc1fMa9q64N/FYnFFPjeDf4z7cqbmk5DZu/IXO3W7ll02biBXGOO2kFnS/8tItxox7610GvDISgL3Ll+fuP3fnsAYH7tS8v/zyCz0e7MWcefPZp3Iujz/Qg7xaNVmydBk33vEQsVicwsJCLj7/HC5sf+ZOzbWnK82ldO7+vpkdsFV3W6Bl8HwQ8B5wW9A/zN03AgvMLB9oZmbfArnuPgXAzAYD7YAJqeZW5rwdVWtW5fTLz+a2s27m5lbXkZGZQfOzT9xizN65FbjyoT/xtysf4qbTutPr2r+lffzqdWpw/7Ce2/SfcuFp/Lh2A9f94WrGDRjLJbd3BmDjzxt58qY+3HRadx7qdB+X33sle+dW2LmLlBLLycnmhb6P8NqgZ3h10NN8NPVTZn45d4sxebX3Y+BTjzJ6cD/+dNlF3P9o37SPv7hgGZd1/8s2/a+Ne5vcShWZMOIFLr2wHb2feQGA6vtW5eVnezFq0NMMfe4JBrw8guUrVu3cRe7hvATNzLqa2fSk1jWNKWq6ewFA8Fgj6M8DFiaNWxT05QXPt+5PSZlzCpmZGeSUy6GwsJC9yu/FmmWrt9h+YtvfM/XNKaxcshKAdavW/m9b+5accdlZZGVnMX/G1zx/17PE48X/Q+rY045jxBNDAZgy/iO6PHA1AAULlmwes2b5atauXEtu1Vx+Wvfjzl6mlICZsffe5QEoLCyksLCQrcuHRx3RcPPzIxsdxrLlKze/fv2td3ll5Bg2bSrkyEaHctct3cjMzKQ4734whWu7XAJAq5Yn8nDvfrg72dnZm8f8smkTcY/GSoWdUViCzNnd+wP9S2nqourInqI/JWXO27F62WrG9v8n/aYM4LlPBvHT+h+Z+cGMLcbUqp9HxcoVuX9YT/42rjd/OPckAPIOrkPzs1pw13m3cesZNxKPxzmx3R/SmrfqfvtuDvbxWJyf1v9IpSqVthhzcJMGZOVksey7pTt/oVJisViM8zp34/dnXcQJxx7FkY0O2+7Y18a9RYvjjwHgP99+z5uT/sVLQaabkZHBuLcnpzXn8hWr2K9GNQCysjKpWGFvfli7DoCCZSto3+kaTm3fiS5/7ECN6vvu5BXu2UrzhuB2LDOzWgDB4/KgfxFQN2lcHWBJ0F+niP6UdjhzNrPL3f3F7WzrSqL4zVFVj+TAivV2dJoyUyG3Ase2Oo5uLa7ix3U/csszt3Fi+5Z8MPq9zWMyszI5sPHB3H/xXeSUy+Hh0Y/x9efzOKJ5Ew484iAeGdsLgJxyOaxbmciqb/1HD2rUrUlWThbValfnsfFPADD+xdeZPHLSNlkYQHIytE+NKlzX5yaeuuXvuLKkMpGZmcmoQU+zbv0GbujxIPO/+ZYGBx6wzbhpn87ktXFv81K/xwGYOn0Gc77Kp2OXGwDYuHEjVavsA8D1PR5g8ZJlbCrcRMGyFZzXuRsAl1zQlvZntiry7/rXn5VaNaszenA/lq9YxfU9HuC0k1pQrWqVbcb/VuyGpXRjgc7AI8HjmKT+IWbWG6hN4sbfNHePmdl6MzsemAp0Ap4sbpKdKWvcDxQZnJP/qXB+vXP2yAhyZIumLF+4jHWrE9nJ1DencOjRh20RnFcVrGT96nVs/HkjG3/eyJxpszng8PqYwXuvTmbIo4O3Oe5jV/8VSNScuz9+A/d2vHOL7asKVlKtdjVWL11FRmYGe1eqwIYf1gNQvmJ57njxHoY9/grzP5+3i65c0pVbqSLH/u5IPvx4+jbBeV7+Au555Ame7fUg+1TOBcDdOef0U7npmsu3OVbfv94DJGrOd/bsxcCnHt1ie80a1Vi6fCX71ahOYWGMDT/+ROXcLf9FVaP6vhxcvx6fzfySVidteX/kt2QnMuJtmNlQEjf/qpnZIuBeEkF5hJl1Ab4HOgC4+2wzGwHMAQqBbu7+61caXkNi5Ud5EjcCU94MhGLKGmb2xXbaLKBmyS91z7FyyQoOOepQcsrlAHBE8yYszl+4xZhPJk7l8GYNyQhq0w2aHsKi/IXM+ugLTjjj/8jdtzIAFStXpFpe9bTmnf7ONFqedzIAJ5zRnC///QUAWdlZ/KX/Hfxr1GSmjP+otC5TSmj1mh9Yt34DAP/duJGPP/mc+vXqbjGmYOlybrzjQf56z60csP///jV7/DFNmfjeh6xa8wMAa9etZ8nSZWnNe1KL4xkz/h0A3n7vA447uglmxtLlK/jvxo2bj/f5rDlbzPlbVJpL6dz9Inev5e7Z7l7H3Qe4+yp3P8XdGwSPq5PG93T3g9z9UHefkNQ/3d0bB9u6exr/7C0uc64JtAbWbNVvwL/TuLY91vwZXzNl/Ec89sYTxGIxFsz+holD3qLVHxPLE99+5U0W5y/i8399Rq+3+uJxZ9KwiSz8+nsAhj7+Mne/dD8ZGRkUFhby/N3/YOXiFcXOO2n4RK7vczNP/usfbPhhPX26PwbACWe14PBmjai4TyVanp8I3k//+e98O2fBLvoTkKKsWLWGOx96nFg8jsed1iefSMvmxzF89BsAXNj+TPq9OIS169bz0ONPA4kyyIgX+nJQ/Xpcd1Unut54J3GPk52VxZ03X0vt/YrPc849qzU9HnyM0y+4gsq5lXjs/tsB+ObbhTz21HOYGe7OZRedyyEH1d91fwB7gFhEyn2WKoCb2QDgRXffZkGtmQ1x94uLm2BPLWvIrjX00yfK+hQkhLKrHVjsO+eKc3G99mnHnCHfjd7p+XaVlJmzu3dJsa3YwCwisruVZs25LGmds4hESlQ++EjBWUQiRd+EIiISQipriIiEUFRWayg4i0ikqKwhIhJCuiEoIhJCqjmLiISQyhoiIiEUlU9rVHAWkUiJKXMWEQkflTVEREJIZQ0RkRBS5iwiEkJaSiciEkJ6+7aISAiprCEiEkIKziIiIaTVGiIiIaTMWUQkhLRaQ0QkhGIejQ8NVXAWkUhRzVlEJIRUcxYRCSHVnEVEQigekbJGRlmfgIhIafIS/FccM/vWzGaZ2Qwzmx70VTWziWY2P3iskjS+h5nlm9k8M2u9M9eh4CwikRLzeNotTSe5e1N3PyZ4fTswyd0bAJOC15hZQ6Aj0AhoAzxjZpk7eh0KziISKXH3tNsOagsMCp4PAtol9Q9z943uvgDIB5rt6CQKziISKSUpa5hZVzObntS6bnM4eNvMPk3aVtPdCwCCxxpBfx6wMGnfRUHfDtENQRGJlJJkxO7eH+ifYkhzd19iZjWAiWb2VYqxVtQUaZ/MVpQ5i0iklOYNQXdfEjwuB0aTKFMsM7NaAMHj8mD4IqBu0u51gCU7eh0KziISKTGPpd1SMbMKZlbp1+dAK+BLYCzQORjWGRgTPB8LdDSzvcysPtAAmLaj16GyhohESim+fbsmMNrMIBErh7j7m2b2CTDCzLoA3wMdgnlnm9kIYA5QCHRzL+Y3QAoKziISKaX19m13/wZoUkT/KuCU7ezTE+hZGvMrOItIpOiDj0REQigqb99WcBaRSNEHH4mIhJA+bF9EJIRUcxYRCSHVnEVEQkiZs4hICOlrqkREQkiZs4hICGm1hohICOmGoIhICKmsISISQnqHoIhICClzFhEJoajUnC0qv2X2BGbWNfjOMpHN9HMhRdHXVO1eW3+zrwjo50KKoOAsIhJCCs4iIiGk4Lx7qa4oRdHPhWxDNwRFREJImbOISAgpOIuIhJCC825iZm3MbJ6Z5ZvZ7WV9PlL2zOwFM1tuZl+W9blI+Cg47wZmlgk8DZwONAQuMrOGZXtWEgIDgTZlfRISTgrOu0czIN/dv3H3X4BhQNsyPicpY+7+PrC6rM9DwknBeffIAxYmvV4U9ImIFEnBefewIvq0hlFEtkvBefdYBNRNel0HWFJG5yIiewAF593jE6CBmdU3sxygIzC2jM9JREJMwXk3cPdCoDvwFjAXGOHus8v2rKSsmdlQYApwqJktMrMuZX1OEh56+7aISAgpcxYRCSEFZxGREFJwFhEJIQVnEZEQUnAWEQkhBWcRkRBScBYRCaH/B+iCfMvJ5wbgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ye_pred = model.predict(X_test_10)\n",
    "print('F beta Score for both classes:')\n",
    "print(fbeta_score(ye_test, ye_pred, beta = .1, average = 'weighted').round(2))\n",
    "sns.heatmap(confusion_matrix(ye_test, ye_pred), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is also not as good as the logistic regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
